// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: caffe2.proto

package com.github.neuralnetworks.builder.designio.protobuf;

@SuppressWarnings("unused") 
public final class ProtoBufWrapper
{
	private ProtoBufWrapper()
	{
	}

	public static void registerAllExtensions(
			com.google.protobuf.ExtensionRegistry registry)
	{
	}

	/**
	 * Protobuf enum {@code caffe.Phase}
	 */
	public enum Phase
			implements com.google.protobuf.ProtocolMessageEnum
	{
		/**
		 * <code>TRAIN = 0;</code>
		 */
		TRAIN(0, 0),
		/**
		 * <code>TEST = 1;</code>
		 */
		TEST(1, 1), ;

		/**
		 * <code>TRAIN = 0;</code>
		 */
		public static final int TRAIN_VALUE = 0;
		/**
		 * <code>TEST = 1;</code>
		 */
		public static final int TEST_VALUE = 1;


		@Override
		public final int getNumber()
		{
			return value;
		}

		public static Phase valueOf(int value)
		{
			switch (value) {
			case 0:
				return TRAIN;
			case 1:
				return TEST;
			default:
				return null;
			}
		}

		public static com.google.protobuf.Internal.EnumLiteMap<Phase>
				internalGetValueMap()
		{
			return internalValueMap;
		}

		private static com.google.protobuf.Internal.EnumLiteMap<Phase> internalValueMap =
				new com.google.protobuf.Internal.EnumLiteMap<Phase>()
				{
					@Override
					public Phase findValueByNumber(int number)
					{
						return Phase.valueOf(number);
					}
				};

		@Override
		public final com.google.protobuf.Descriptors.EnumValueDescriptor
				getValueDescriptor()
		{
			return getDescriptor().getValues().get(index);
		}

		@Override
		public final com.google.protobuf.Descriptors.EnumDescriptor
				getDescriptorForType()
		{
			return getDescriptor();
		}

		public static final com.google.protobuf.Descriptors.EnumDescriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.getDescriptor().getEnumTypes().get(0);
		}

		private static final Phase[] VALUES = values();

		public static Phase valueOf(
				com.google.protobuf.Descriptors.EnumValueDescriptor desc)
		{
			if (desc.getType() != getDescriptor())
			{
				throw new java.lang.IllegalArgumentException(
						"EnumValueDescriptor is not for this type.");
			}
			return VALUES[desc.getIndex()];
		}

		private final int index;
		private final int value;

		private Phase(int index, int value)
		{
			this.index = index;
			this.value = value;
		}

		// @@protoc_insertion_point(enum_scope:caffe.Phase)
	}

	public interface BlobProtoOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.BlobProto)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional int32 num = 1 [default = 0];</code>
		 */
		boolean hasNum();

		/**
		 * <code>optional int32 num = 1 [default = 0];</code>
		 */
		int getNum();

		/**
		 * <code>optional int32 channels = 2 [default = 0];</code>
		 */
		boolean hasChannels();

		/**
		 * <code>optional int32 channels = 2 [default = 0];</code>
		 */
		int getChannels();

		/**
		 * <code>optional int32 height = 3 [default = 0];</code>
		 */
		boolean hasHeight();

		/**
		 * <code>optional int32 height = 3 [default = 0];</code>
		 */
		int getHeight();

		/**
		 * <code>optional int32 width = 4 [default = 0];</code>
		 */
		boolean hasWidth();

		/**
		 * <code>optional int32 width = 4 [default = 0];</code>
		 */
		int getWidth();

		/**
		 * <code>repeated float data = 5 [packed = true];</code>
		 */
		java.util.List<java.lang.Float> getDataList();

		/**
		 * <code>repeated float data = 5 [packed = true];</code>
		 */
		int getDataCount();

		/**
		 * <code>repeated float data = 5 [packed = true];</code>
		 */
		float getData(int index);

		/**
		 * <code>repeated float diff = 6 [packed = true];</code>
		 */
		java.util.List<java.lang.Float> getDiffList();

		/**
		 * <code>repeated float diff = 6 [packed = true];</code>
		 */
		int getDiffCount();

		/**
		 * <code>repeated float diff = 6 [packed = true];</code>
		 */
		float getDiff(int index);
	}

	/**
	 * Protobuf type {@code caffe.BlobProto}
	 */
	public static final class BlobProto extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.BlobProto)
			BlobProtoOrBuilder
	{
		// Use BlobProto.newBuilder() to construct.
		private BlobProto(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private BlobProto(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final BlobProto defaultInstance;

		public static BlobProto getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public BlobProto getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private BlobProto(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						num_ = input.readInt32();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						channels_ = input.readInt32();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						height_ = input.readInt32();
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000008;
						width_ = input.readInt32();
						break;
					}
					case 45:
					{
						if (!((mutable_bitField0_ & 0x00000010) == 0x00000010))
						{
							data_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000010;
						}
						data_.add(input.readFloat());
						break;
					}
					case 42:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000010) == 0x00000010) && input.getBytesUntilLimit() > 0)
						{
							data_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000010;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							data_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 53:
					{
						if (!((mutable_bitField0_ & 0x00000020) == 0x00000020))
						{
							diff_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000020;
						}
						diff_.add(input.readFloat());
						break;
					}
					case 50:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000020) == 0x00000020) && input.getBytesUntilLimit() > 0)
						{
							diff_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000020;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							diff_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000010) == 0x00000010))
				{
					data_ = java.util.Collections.unmodifiableList(data_);
				}
				if (((mutable_bitField0_ & 0x00000020) == 0x00000020))
				{
					diff_ = java.util.Collections.unmodifiableList(diff_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProto_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProto_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder.class);
		}

		public static com.google.protobuf.Parser<BlobProto> PARSER =
				new com.google.protobuf.AbstractParser<BlobProto>()
				{
					@Override
					public BlobProto parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new BlobProto(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<BlobProto> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int NUM_FIELD_NUMBER = 1;
		private int num_;

		/**
		 * <code>optional int32 num = 1 [default = 0];</code>
		 */
		@Override
		public boolean hasNum()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional int32 num = 1 [default = 0];</code>
		 */
		@Override
		public int getNum()
		{
			return num_;
		}

		public static final int CHANNELS_FIELD_NUMBER = 2;
		private int channels_;

		/**
		 * <code>optional int32 channels = 2 [default = 0];</code>
		 */
		@Override
		public boolean hasChannels()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional int32 channels = 2 [default = 0];</code>
		 */
		@Override
		public int getChannels()
		{
			return channels_;
		}

		public static final int HEIGHT_FIELD_NUMBER = 3;
		private int height_;

		/**
		 * <code>optional int32 height = 3 [default = 0];</code>
		 */
		@Override
		public boolean hasHeight()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional int32 height = 3 [default = 0];</code>
		 */
		@Override
		public int getHeight()
		{
			return height_;
		}

		public static final int WIDTH_FIELD_NUMBER = 4;
		private int width_;

		/**
		 * <code>optional int32 width = 4 [default = 0];</code>
		 */
		@Override
		public boolean hasWidth()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional int32 width = 4 [default = 0];</code>
		 */
		@Override
		public int getWidth()
		{
			return width_;
		}

		public static final int DATA_FIELD_NUMBER = 5;
		private java.util.List<java.lang.Float> data_;

		/**
		 * <code>repeated float data = 5 [packed = true];</code>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getDataList()
		{
			return data_;
		}

		/**
		 * <code>repeated float data = 5 [packed = true];</code>
		 */
		@Override
		public int getDataCount()
		{
			return data_.size();
		}

		/**
		 * <code>repeated float data = 5 [packed = true];</code>
		 */
		@Override
		public float getData(int index)
		{
			return data_.get(index);
		}

		private int dataMemoizedSerializedSize = -1;

		public static final int DIFF_FIELD_NUMBER = 6;
		private java.util.List<java.lang.Float> diff_;

		/**
		 * <code>repeated float diff = 6 [packed = true];</code>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getDiffList()
		{
			return diff_;
		}

		/**
		 * <code>repeated float diff = 6 [packed = true];</code>
		 */
		@Override
		public int getDiffCount()
		{
			return diff_.size();
		}

		/**
		 * <code>repeated float diff = 6 [packed = true];</code>
		 */
		@Override
		public float getDiff(int index)
		{
			return diff_.get(index);
		}

		private int diffMemoizedSerializedSize = -1;

		private void initFields()
		{
			num_ = 0;
			channels_ = 0;
			height_ = 0;
			width_ = 0;
			data_ = java.util.Collections.emptyList();
			diff_ = java.util.Collections.emptyList();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeInt32(1, num_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeInt32(2, channels_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeInt32(3, height_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeInt32(4, width_);
			}
			if (getDataList().size() > 0)
			{
				output.writeRawVarint32(42);
				output.writeRawVarint32(dataMemoizedSerializedSize);
			}
			for (int i = 0; i < data_.size(); i++)
			{
				output.writeFloatNoTag(data_.get(i));
			}
			if (getDiffList().size() > 0)
			{
				output.writeRawVarint32(50);
				output.writeRawVarint32(diffMemoizedSerializedSize);
			}
			for (int i = 0; i < diff_.size(); i++)
			{
				output.writeFloatNoTag(diff_.get(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(1, num_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(2, channels_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(3, height_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(4, width_);
			}
			{
				int dataSize = 0;
				dataSize = 4 * getDataList().size();
				size += dataSize;
				if (!getDataList().isEmpty())
				{
					size += 1;
					size += com.google.protobuf.CodedOutputStream
							.computeInt32SizeNoTag(dataSize);
				}
				dataMemoizedSerializedSize = dataSize;
			}
			{
				int dataSize = 0;
				dataSize = 4 * getDiffList().size();
				size += dataSize;
				if (!getDiffList().isEmpty())
				{
					size += 1;
					size += com.google.protobuf.CodedOutputStream
							.computeInt32SizeNoTag(dataSize);
				}
				diffMemoizedSerializedSize = dataSize;
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.BlobProto}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.BlobProto)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProto_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProto_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				num_ = 0;
				bitField0_ = (bitField0_ & ~0x00000001);
				channels_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				height_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				width_ = 0;
				bitField0_ = (bitField0_ & ~0x00000008);
				data_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000010);
				diff_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000020);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProto_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.num_ = num_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.channels_ = channels_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.height_ = height_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.width_ = width_;
				if (((bitField0_ & 0x00000010) == 0x00000010))
				{
					data_ = java.util.Collections.unmodifiableList(data_);
					bitField0_ = (bitField0_ & ~0x00000010);
				}
				result.data_ = data_;
				if (((bitField0_ & 0x00000020) == 0x00000020))
				{
					diff_ = java.util.Collections.unmodifiableList(diff_);
					bitField0_ = (bitField0_ & ~0x00000020);
				}
				result.diff_ = diff_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance())
					return this;
				if (other.hasNum())
				{
					setNum(other.getNum());
				}
				if (other.hasChannels())
				{
					setChannels(other.getChannels());
				}
				if (other.hasHeight())
				{
					setHeight(other.getHeight());
				}
				if (other.hasWidth())
				{
					setWidth(other.getWidth());
				}
				if (!other.data_.isEmpty())
				{
					if (data_.isEmpty())
					{
						data_ = other.data_;
						bitField0_ = (bitField0_ & ~0x00000010);
					} else
					{
						ensureDataIsMutable();
						data_.addAll(other.data_);
					}
					onChanged();
				}
				if (!other.diff_.isEmpty())
				{
					if (diff_.isEmpty())
					{
						diff_ = other.diff_;
						bitField0_ = (bitField0_ & ~0x00000020);
					} else
					{
						ensureDiffIsMutable();
						diff_.addAll(other.diff_);
					}
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int num_;

			/**
			 * <code>optional int32 num = 1 [default = 0];</code>
			 */
			@Override
			public boolean hasNum()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional int32 num = 1 [default = 0];</code>
			 */
			@Override
			public int getNum()
			{
				return num_;
			}

			/**
			 * <code>optional int32 num = 1 [default = 0];</code>
			 */
			public Builder setNum(int value)
			{
				bitField0_ |= 0x00000001;
				num_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 num = 1 [default = 0];</code>
			 */
			public Builder clearNum()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				num_ = 0;
				onChanged();
				return this;
			}

			private int channels_;

			/**
			 * <code>optional int32 channels = 2 [default = 0];</code>
			 */
			@Override
			public boolean hasChannels()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional int32 channels = 2 [default = 0];</code>
			 */
			@Override
			public int getChannels()
			{
				return channels_;
			}

			/**
			 * <code>optional int32 channels = 2 [default = 0];</code>
			 */
			public Builder setChannels(int value)
			{
				bitField0_ |= 0x00000002;
				channels_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 channels = 2 [default = 0];</code>
			 */
			public Builder clearChannels()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				channels_ = 0;
				onChanged();
				return this;
			}

			private int height_;

			/**
			 * <code>optional int32 height = 3 [default = 0];</code>
			 */
			@Override
			public boolean hasHeight()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional int32 height = 3 [default = 0];</code>
			 */
			@Override
			public int getHeight()
			{
				return height_;
			}

			/**
			 * <code>optional int32 height = 3 [default = 0];</code>
			 */
			public Builder setHeight(int value)
			{
				bitField0_ |= 0x00000004;
				height_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 height = 3 [default = 0];</code>
			 */
			public Builder clearHeight()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				height_ = 0;
				onChanged();
				return this;
			}

			private int width_;

			/**
			 * <code>optional int32 width = 4 [default = 0];</code>
			 */
			@Override
			public boolean hasWidth()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional int32 width = 4 [default = 0];</code>
			 */
			@Override
			public int getWidth()
			{
				return width_;
			}

			/**
			 * <code>optional int32 width = 4 [default = 0];</code>
			 */
			public Builder setWidth(int value)
			{
				bitField0_ |= 0x00000008;
				width_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 width = 4 [default = 0];</code>
			 */
			public Builder clearWidth()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				width_ = 0;
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> data_ = java.util.Collections.emptyList();

			private void ensureDataIsMutable()
			{
				if (!((bitField0_ & 0x00000010) == 0x00000010))
				{
					data_ = new java.util.ArrayList<java.lang.Float>(data_);
					bitField0_ |= 0x00000010;
				}
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getDataList()
			{
				return java.util.Collections.unmodifiableList(data_);
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			@Override
			public int getDataCount()
			{
				return data_.size();
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			@Override
			public float getData(int index)
			{
				return data_.get(index);
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			public Builder setData(
					int index, float value)
			{
				ensureDataIsMutable();
				data_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			public Builder addData(float value)
			{
				ensureDataIsMutable();
				data_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			public Builder addAllData(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureDataIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, data_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float data = 5 [packed = true];</code>
			 */
			public Builder clearData()
			{
				data_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000010);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> diff_ = java.util.Collections.emptyList();

			private void ensureDiffIsMutable()
			{
				if (!((bitField0_ & 0x00000020) == 0x00000020))
				{
					diff_ = new java.util.ArrayList<java.lang.Float>(diff_);
					bitField0_ |= 0x00000020;
				}
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getDiffList()
			{
				return java.util.Collections.unmodifiableList(diff_);
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			@Override
			public int getDiffCount()
			{
				return diff_.size();
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			@Override
			public float getDiff(int index)
			{
				return diff_.get(index);
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			public Builder setDiff(
					int index, float value)
			{
				ensureDiffIsMutable();
				diff_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			public Builder addDiff(float value)
			{
				ensureDiffIsMutable();
				diff_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			public Builder addAllDiff(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureDiffIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, diff_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float diff = 6 [packed = true];</code>
			 */
			public Builder clearDiff()
			{
				diff_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000020);
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.BlobProto)
		}

		static
		{
			defaultInstance = new BlobProto(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.BlobProto)
	}

	public interface BlobProtoVectorOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.BlobProtoVector)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>
				getBlobsList();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index);

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		int getBlobsCount();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getBlobsOrBuilderList();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
				int index);
	}

	/**
	 * Protobuf type {@code caffe.BlobProtoVector}
	 *
	 * <pre>
	 * The BlobProtoVector is simply a way to pass multiple blobproto instances
	 * around.
	 * </pre>
	 */
	public static final class BlobProtoVector extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.BlobProtoVector)
			BlobProtoVectorOrBuilder
	{
		// Use BlobProtoVector.newBuilder() to construct.
		private BlobProtoVector(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private BlobProtoVector(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final BlobProtoVector defaultInstance;

		public static BlobProtoVector getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public BlobProtoVector getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private BlobProtoVector(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						if (!((mutable_bitField0_ & 0x00000001) == 0x00000001))
						{
							blobs_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>();
							mutable_bitField0_ |= 0x00000001;
						}
						blobs_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.PARSER, extensionRegistry));
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000001) == 0x00000001))
				{
					blobs_ = java.util.Collections.unmodifiableList(blobs_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProtoVector_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProtoVector_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.Builder.class);
		}

		public static com.google.protobuf.Parser<BlobProtoVector> PARSER =
				new com.google.protobuf.AbstractParser<BlobProtoVector>()
				{
					@Override
					public BlobProtoVector parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new BlobProtoVector(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<BlobProtoVector> getParserForType()
		{
			return PARSER;
		}

		public static final int BLOBS_FIELD_NUMBER = 1;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> blobs_;

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getBlobsList()
		{
			return blobs_;
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getBlobsOrBuilderList()
		{
			return blobs_;
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		@Override
		public int getBlobsCount()
		{
			return blobs_.size();
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index)
		{
			return blobs_.get(index);
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 1;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
				int index)
		{
			return blobs_.get(index);
		}

		private void initFields()
		{
			blobs_ = java.util.Collections.emptyList();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			for (int i = 0; i < blobs_.size(); i++)
			{
				output.writeMessage(1, blobs_.get(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			for (int i = 0; i < blobs_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(1, blobs_.get(i));
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.BlobProtoVector}
		 *
		 * <pre>
		 * The BlobProtoVector is simply a way to pass multiple blobproto instances
		 * around.
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.BlobProtoVector)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVectorOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProtoVector_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProtoVector_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getBlobsFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				if (blobsBuilder_ == null)
				{
					blobs_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000001);
				} else
				{
					blobsBuilder_.clear();
				}
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_BlobProtoVector_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector(this);
				int from_bitField0_ = bitField0_;
				if (blobsBuilder_ == null)
				{
					if (((bitField0_ & 0x00000001) == 0x00000001))
					{
						blobs_ = java.util.Collections.unmodifiableList(blobs_);
						bitField0_ = (bitField0_ & ~0x00000001);
					}
					result.blobs_ = blobs_;
				} else
				{
					result.blobs_ = blobsBuilder_.build();
				}
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector.getDefaultInstance())
					return this;
				if (blobsBuilder_ == null)
				{
					if (!other.blobs_.isEmpty())
					{
						if (blobs_.isEmpty())
						{
							blobs_ = other.blobs_;
							bitField0_ = (bitField0_ & ~0x00000001);
						} else
						{
							ensureBlobsIsMutable();
							blobs_.addAll(other.blobs_);
						}
						onChanged();
					}
				} else
				{
					if (!other.blobs_.isEmpty())
					{
						if (blobsBuilder_.isEmpty())
						{
							blobsBuilder_.dispose();
							blobsBuilder_ = null;
							blobs_ = other.blobs_;
							bitField0_ = (bitField0_ & ~0x00000001);
							blobsBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getBlobsFieldBuilder() : null;
						} else
						{
							blobsBuilder_.addAllMessages(other.blobs_);
						}
					}
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoVector) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> blobs_ =
					java.util.Collections.emptyList();

			private void ensureBlobsIsMutable()
			{
				if (!((bitField0_ & 0x00000001) == 0x00000001))
				{
					blobs_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>(blobs_);
					bitField0_ |= 0x00000001;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder> blobsBuilder_;

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getBlobsList()
			{
				if (blobsBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(blobs_);
				} else
				{
					return blobsBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			@Override
			public int getBlobsCount()
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.size();
				} else
				{
					return blobsBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index)
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.get(index);
				} else
				{
					return blobsBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder setBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.set(index, value);
					onChanged();
				} else
				{
					blobsBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder setBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder addBlobs(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.add(value);
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder addBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.add(index, value);
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder addBlobs(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.add(builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder addBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder addAllBlobs(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> values)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, blobs_);
					onChanged();
				} else
				{
					blobsBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder clearBlobs()
			{
				if (blobsBuilder_ == null)
				{
					blobs_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000001);
					onChanged();
				} else
				{
					blobsBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public Builder removeBlobs(int index)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.remove(index);
					onChanged();
				} else
				{
					blobsBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder getBlobsBuilder(
					int index)
			{
				return getBlobsFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
					int index)
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.get(index);
				} else
				{
					return blobsBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getBlobsOrBuilderList()
			{
				if (blobsBuilder_ != null)
				{
					return blobsBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(blobs_);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addBlobsBuilder()
			{
				return getBlobsFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addBlobsBuilder(
					int index)
			{
				return getBlobsFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 1;</code>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder>
					getBlobsBuilderList()
			{
				return getBlobsFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getBlobsFieldBuilder()
			{
				if (blobsBuilder_ == null)
				{
					blobsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>(
									blobs_,
									((bitField0_ & 0x00000001) == 0x00000001),
									getParentForChildren(),
									isClean());
					blobs_ = null;
				}
				return blobsBuilder_;
			}

			// @@protoc_insertion_point(builder_scope:caffe.BlobProtoVector)
		}

		static
		{
			defaultInstance = new BlobProtoVector(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)
	}

	public interface DatumOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.Datum)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional int32 channels = 1;</code>
		 */
		boolean hasChannels();

		/**
		 * <code>optional int32 channels = 1;</code>
		 */
		int getChannels();

		/**
		 * <code>optional int32 height = 2;</code>
		 */
		boolean hasHeight();

		/**
		 * <code>optional int32 height = 2;</code>
		 */
		int getHeight();

		/**
		 * <code>optional int32 width = 3;</code>
		 */
		boolean hasWidth();

		/**
		 * <code>optional int32 width = 3;</code>
		 */
		int getWidth();

		/**
		 * <code>optional bytes data = 4;</code>
		 *
		 * <pre>
		 * the actual image data, in bytes
		 * </pre>
		 */
		boolean hasData();

		/**
		 * <code>optional bytes data = 4;</code>
		 *
		 * <pre>
		 * the actual image data, in bytes
		 * </pre>
		 */
		com.google.protobuf.ByteString getData();

		/**
		 * <code>optional int32 label = 5;</code>
		 */
		boolean hasLabel();

		/**
		 * <code>optional int32 label = 5;</code>
		 */
		int getLabel();

		/**
		 * <code>repeated float float_data = 6;</code>
		 *
		 * <pre>
		 * Optionally, the datum could also hold float data.
		 * </pre>
		 */
		java.util.List<java.lang.Float> getFloatDataList();

		/**
		 * <code>repeated float float_data = 6;</code>
		 *
		 * <pre>
		 * Optionally, the datum could also hold float data.
		 * </pre>
		 */
		int getFloatDataCount();

		/**
		 * <code>repeated float float_data = 6;</code>
		 *
		 * <pre>
		 * Optionally, the datum could also hold float data.
		 * </pre>
		 */
		float getFloatData(int index);
	}

	/**
	 * Protobuf type {@code caffe.Datum}
	 */
	public static final class Datum extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.Datum)
			DatumOrBuilder
	{
		// Use Datum.newBuilder() to construct.
		private Datum(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private Datum(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final Datum defaultInstance;

		public static Datum getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public Datum getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private Datum(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						channels_ = input.readInt32();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						height_ = input.readInt32();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						width_ = input.readInt32();
						break;
					}
					case 34:
					{
						bitField0_ |= 0x00000008;
						data_ = input.readBytes();
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000010;
						label_ = input.readInt32();
						break;
					}
					case 53:
					{
						if (!((mutable_bitField0_ & 0x00000020) == 0x00000020))
						{
							floatData_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000020;
						}
						floatData_.add(input.readFloat());
						break;
					}
					case 50:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000020) == 0x00000020) && input.getBytesUntilLimit() > 0)
						{
							floatData_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000020;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							floatData_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000020) == 0x00000020))
				{
					floatData_ = java.util.Collections.unmodifiableList(floatData_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_Datum_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_Datum_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.Builder.class);
		}

		public static com.google.protobuf.Parser<Datum> PARSER =
				new com.google.protobuf.AbstractParser<Datum>()
				{
					@Override
					public Datum parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new Datum(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<Datum> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int CHANNELS_FIELD_NUMBER = 1;
		private int channels_;

		/**
		 * <code>optional int32 channels = 1;</code>
		 */
		@Override
		public boolean hasChannels()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional int32 channels = 1;</code>
		 */
		@Override
		public int getChannels()
		{
			return channels_;
		}

		public static final int HEIGHT_FIELD_NUMBER = 2;
		private int height_;

		/**
		 * <code>optional int32 height = 2;</code>
		 */
		@Override
		public boolean hasHeight()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional int32 height = 2;</code>
		 */
		@Override
		public int getHeight()
		{
			return height_;
		}

		public static final int WIDTH_FIELD_NUMBER = 3;
		private int width_;

		/**
		 * <code>optional int32 width = 3;</code>
		 */
		@Override
		public boolean hasWidth()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional int32 width = 3;</code>
		 */
		@Override
		public int getWidth()
		{
			return width_;
		}

		public static final int DATA_FIELD_NUMBER = 4;
		private com.google.protobuf.ByteString data_;

		/**
		 * <code>optional bytes data = 4;</code>
		 *
		 * <pre>
		 * the actual image data, in bytes
		 * </pre>
		 */
		@Override
		public boolean hasData()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional bytes data = 4;</code>
		 *
		 * <pre>
		 * the actual image data, in bytes
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString getData()
		{
			return data_;
		}

		public static final int LABEL_FIELD_NUMBER = 5;
		private int label_;

		/**
		 * <code>optional int32 label = 5;</code>
		 */
		@Override
		public boolean hasLabel()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional int32 label = 5;</code>
		 */
		@Override
		public int getLabel()
		{
			return label_;
		}

		public static final int FLOAT_DATA_FIELD_NUMBER = 6;
		private java.util.List<java.lang.Float> floatData_;

		/**
		 * <code>repeated float float_data = 6;</code>
		 *
		 * <pre>
		 * Optionally, the datum could also hold float data.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getFloatDataList()
		{
			return floatData_;
		}

		/**
		 * <code>repeated float float_data = 6;</code>
		 *
		 * <pre>
		 * Optionally, the datum could also hold float data.
		 * </pre>
		 */
		@Override
		public int getFloatDataCount()
		{
			return floatData_.size();
		}

		/**
		 * <code>repeated float float_data = 6;</code>
		 *
		 * <pre>
		 * Optionally, the datum could also hold float data.
		 * </pre>
		 */
		@Override
		public float getFloatData(int index)
		{
			return floatData_.get(index);
		}

		private void initFields()
		{
			channels_ = 0;
			height_ = 0;
			width_ = 0;
			data_ = com.google.protobuf.ByteString.EMPTY;
			label_ = 0;
			floatData_ = java.util.Collections.emptyList();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeInt32(1, channels_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeInt32(2, height_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeInt32(3, width_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeBytes(4, data_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeInt32(5, label_);
			}
			for (int i = 0; i < floatData_.size(); i++)
			{
				output.writeFloat(6, floatData_.get(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(1, channels_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(2, height_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(3, width_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(4, data_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(5, label_);
			}
			{
				int dataSize = 0;
				dataSize = 4 * getFloatDataList().size();
				size += dataSize;
				size += 1 * getFloatDataList().size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.Datum}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.Datum)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DatumOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_Datum_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_Datum_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				channels_ = 0;
				bitField0_ = (bitField0_ & ~0x00000001);
				height_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				width_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				data_ = com.google.protobuf.ByteString.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000008);
				label_ = 0;
				bitField0_ = (bitField0_ & ~0x00000010);
				floatData_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000020);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_Datum_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.channels_ = channels_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.height_ = height_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.width_ = width_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.data_ = data_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.label_ = label_;
				if (((bitField0_ & 0x00000020) == 0x00000020))
				{
					floatData_ = java.util.Collections.unmodifiableList(floatData_);
					bitField0_ = (bitField0_ & ~0x00000020);
				}
				result.floatData_ = floatData_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum.getDefaultInstance())
					return this;
				if (other.hasChannels())
				{
					setChannels(other.getChannels());
				}
				if (other.hasHeight())
				{
					setHeight(other.getHeight());
				}
				if (other.hasWidth())
				{
					setWidth(other.getWidth());
				}
				if (other.hasData())
				{
					setData(other.getData());
				}
				if (other.hasLabel())
				{
					setLabel(other.getLabel());
				}
				if (!other.floatData_.isEmpty())
				{
					if (floatData_.isEmpty())
					{
						floatData_ = other.floatData_;
						bitField0_ = (bitField0_ & ~0x00000020);
					} else
					{
						ensureFloatDataIsMutable();
						floatData_.addAll(other.floatData_);
					}
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Datum) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int channels_;

			/**
			 * <code>optional int32 channels = 1;</code>
			 */
			@Override
			public boolean hasChannels()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional int32 channels = 1;</code>
			 */
			@Override
			public int getChannels()
			{
				return channels_;
			}

			/**
			 * <code>optional int32 channels = 1;</code>
			 */
			public Builder setChannels(int value)
			{
				bitField0_ |= 0x00000001;
				channels_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 channels = 1;</code>
			 */
			public Builder clearChannels()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				channels_ = 0;
				onChanged();
				return this;
			}

			private int height_;

			/**
			 * <code>optional int32 height = 2;</code>
			 */
			@Override
			public boolean hasHeight()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional int32 height = 2;</code>
			 */
			@Override
			public int getHeight()
			{
				return height_;
			}

			/**
			 * <code>optional int32 height = 2;</code>
			 */
			public Builder setHeight(int value)
			{
				bitField0_ |= 0x00000002;
				height_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 height = 2;</code>
			 */
			public Builder clearHeight()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				height_ = 0;
				onChanged();
				return this;
			}

			private int width_;

			/**
			 * <code>optional int32 width = 3;</code>
			 */
			@Override
			public boolean hasWidth()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional int32 width = 3;</code>
			 */
			@Override
			public int getWidth()
			{
				return width_;
			}

			/**
			 * <code>optional int32 width = 3;</code>
			 */
			public Builder setWidth(int value)
			{
				bitField0_ |= 0x00000004;
				width_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 width = 3;</code>
			 */
			public Builder clearWidth()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				width_ = 0;
				onChanged();
				return this;
			}

			private com.google.protobuf.ByteString data_ = com.google.protobuf.ByteString.EMPTY;

			/**
			 * <code>optional bytes data = 4;</code>
			 *
			 * <pre>
			 * the actual image data, in bytes
			 * </pre>
			 */
			@Override
			public boolean hasData()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional bytes data = 4;</code>
			 *
			 * <pre>
			 * the actual image data, in bytes
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString getData()
			{
				return data_;
			}

			/**
			 * <code>optional bytes data = 4;</code>
			 *
			 * <pre>
			 * the actual image data, in bytes
			 * </pre>
			 */
			public Builder setData(com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000008;
				data_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bytes data = 4;</code>
			 *
			 * <pre>
			 * the actual image data, in bytes
			 * </pre>
			 */
			public Builder clearData()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				data_ = getDefaultInstance().getData();
				onChanged();
				return this;
			}

			private int label_;

			/**
			 * <code>optional int32 label = 5;</code>
			 */
			@Override
			public boolean hasLabel()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional int32 label = 5;</code>
			 */
			@Override
			public int getLabel()
			{
				return label_;
			}

			/**
			 * <code>optional int32 label = 5;</code>
			 */
			public Builder setLabel(int value)
			{
				bitField0_ |= 0x00000010;
				label_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 label = 5;</code>
			 */
			public Builder clearLabel()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				label_ = 0;
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> floatData_ = java.util.Collections.emptyList();

			private void ensureFloatDataIsMutable()
			{
				if (!((bitField0_ & 0x00000020) == 0x00000020))
				{
					floatData_ = new java.util.ArrayList<java.lang.Float>(floatData_);
					bitField0_ |= 0x00000020;
				}
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getFloatDataList()
			{
				return java.util.Collections.unmodifiableList(floatData_);
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			@Override
			public int getFloatDataCount()
			{
				return floatData_.size();
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			@Override
			public float getFloatData(int index)
			{
				return floatData_.get(index);
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			public Builder setFloatData(
					int index, float value)
			{
				ensureFloatDataIsMutable();
				floatData_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			public Builder addFloatData(float value)
			{
				ensureFloatDataIsMutable();
				floatData_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			public Builder addAllFloatData(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureFloatDataIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, floatData_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float float_data = 6;</code>
			 *
			 * <pre>
			 * Optionally, the datum could also hold float data.
			 * </pre>
			 */
			public Builder clearFloatData()
			{
				floatData_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000020);
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.Datum)
		}

		static
		{
			defaultInstance = new Datum(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.Datum)
	}

	public interface FillerParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.FillerParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string type = 1 [default = "constant"];</code>
		 *
		 * <pre>
		 * The filler type.
		 * </pre>
		 */
		boolean hasType();

		/**
		 * <code>optional string type = 1 [default = "constant"];</code>
		 *
		 * <pre>
		 * The filler type.
		 * </pre>
		 */
		java.lang.String getType();

		/**
		 * <code>optional string type = 1 [default = "constant"];</code>
		 *
		 * <pre>
		 * The filler type.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getTypeBytes();

		/**
		 * <code>optional float value = 2 [default = 0];</code>
		 *
		 * <pre>
		 * the value in constant filler
		 * </pre>
		 */
		boolean hasValue();

		/**
		 * <code>optional float value = 2 [default = 0];</code>
		 *
		 * <pre>
		 * the value in constant filler
		 * </pre>
		 */
		float getValue();

		/**
		 * <code>optional float min = 3 [default = 0];</code>
		 *
		 * <pre>
		 * the min value in uniform filler
		 * </pre>
		 */
		boolean hasMin();

		/**
		 * <code>optional float min = 3 [default = 0];</code>
		 *
		 * <pre>
		 * the min value in uniform filler
		 * </pre>
		 */
		float getMin();

		/**
		 * <code>optional float max = 4 [default = 1];</code>
		 *
		 * <pre>
		 * the max value in uniform filler
		 * </pre>
		 */
		boolean hasMax();

		/**
		 * <code>optional float max = 4 [default = 1];</code>
		 *
		 * <pre>
		 * the max value in uniform filler
		 * </pre>
		 */
		float getMax();

		/**
		 * <code>optional float mean = 5 [default = 0];</code>
		 *
		 * <pre>
		 * the mean value in Gaussian filler
		 * </pre>
		 */
		boolean hasMean();

		/**
		 * <code>optional float mean = 5 [default = 0];</code>
		 *
		 * <pre>
		 * the mean value in Gaussian filler
		 * </pre>
		 */
		float getMean();

		/**
		 * <code>optional float std = 6 [default = 1];</code>
		 *
		 * <pre>
		 * the std value in Gaussian filler
		 * </pre>
		 */
		boolean hasStd();

		/**
		 * <code>optional float std = 6 [default = 1];</code>
		 *
		 * <pre>
		 * the std value in Gaussian filler
		 * </pre>
		 */
		float getStd();

		/**
		 * <code>optional int32 sparse = 7 [default = -1];</code>
		 *
		 * <pre>
		 * The expected number of non-zero input weights for a given output in
		 * Gaussian filler -- the default -1 means don't perform sparsification.
		 * </pre>
		 */
		boolean hasSparse();

		/**
		 * <code>optional int32 sparse = 7 [default = -1];</code>
		 *
		 * <pre>
		 * The expected number of non-zero input weights for a given output in
		 * Gaussian filler -- the default -1 means don't perform sparsification.
		 * </pre>
		 */
		int getSparse();
	}

	/**
	 * Protobuf type {@code caffe.FillerParameter}
	 */
	public static final class FillerParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.FillerParameter)
			FillerParameterOrBuilder
	{
		// Use FillerParameter.newBuilder() to construct.
		private FillerParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private FillerParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final FillerParameter defaultInstance;

		public static FillerParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public FillerParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private FillerParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						type_ = bs;
						break;
					}
					case 21:
					{
						bitField0_ |= 0x00000002;
						value_ = input.readFloat();
						break;
					}
					case 29:
					{
						bitField0_ |= 0x00000004;
						min_ = input.readFloat();
						break;
					}
					case 37:
					{
						bitField0_ |= 0x00000008;
						max_ = input.readFloat();
						break;
					}
					case 45:
					{
						bitField0_ |= 0x00000010;
						mean_ = input.readFloat();
						break;
					}
					case 53:
					{
						bitField0_ |= 0x00000020;
						std_ = input.readFloat();
						break;
					}
					case 56:
					{
						bitField0_ |= 0x00000040;
						sparse_ = input.readInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_FillerParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_FillerParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<FillerParameter> PARSER =
				new com.google.protobuf.AbstractParser<FillerParameter>()
				{
					@Override
					public FillerParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new FillerParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<FillerParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int TYPE_FIELD_NUMBER = 1;
		private java.lang.Object type_;

		/**
		 * <code>optional string type = 1 [default = "constant"];</code>
		 *
		 * <pre>
		 * The filler type.
		 * </pre>
		 */
		@Override
		public boolean hasType()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string type = 1 [default = "constant"];</code>
		 *
		 * <pre>
		 * The filler type.
		 * </pre>
		 */
		@Override
		public java.lang.String getType()
		{
			java.lang.Object ref = type_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					type_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string type = 1 [default = "constant"];</code>
		 *
		 * <pre>
		 * The filler type.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getTypeBytes()
		{
			java.lang.Object ref = type_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				type_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int VALUE_FIELD_NUMBER = 2;
		private float value_;

		/**
		 * <code>optional float value = 2 [default = 0];</code>
		 *
		 * <pre>
		 * the value in constant filler
		 * </pre>
		 */
		@Override
		public boolean hasValue()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional float value = 2 [default = 0];</code>
		 *
		 * <pre>
		 * the value in constant filler
		 * </pre>
		 */
		@Override
		public float getValue()
		{
			return value_;
		}

		public static final int MIN_FIELD_NUMBER = 3;
		private float min_;

		/**
		 * <code>optional float min = 3 [default = 0];</code>
		 *
		 * <pre>
		 * the min value in uniform filler
		 * </pre>
		 */
		@Override
		public boolean hasMin()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional float min = 3 [default = 0];</code>
		 *
		 * <pre>
		 * the min value in uniform filler
		 * </pre>
		 */
		@Override
		public float getMin()
		{
			return min_;
		}

		public static final int MAX_FIELD_NUMBER = 4;
		private float max_;

		/**
		 * <code>optional float max = 4 [default = 1];</code>
		 *
		 * <pre>
		 * the max value in uniform filler
		 * </pre>
		 */
		@Override
		public boolean hasMax()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional float max = 4 [default = 1];</code>
		 *
		 * <pre>
		 * the max value in uniform filler
		 * </pre>
		 */
		@Override
		public float getMax()
		{
			return max_;
		}

		public static final int MEAN_FIELD_NUMBER = 5;
		private float mean_;

		/**
		 * <code>optional float mean = 5 [default = 0];</code>
		 *
		 * <pre>
		 * the mean value in Gaussian filler
		 * </pre>
		 */
		@Override
		public boolean hasMean()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional float mean = 5 [default = 0];</code>
		 *
		 * <pre>
		 * the mean value in Gaussian filler
		 * </pre>
		 */
		@Override
		public float getMean()
		{
			return mean_;
		}

		public static final int STD_FIELD_NUMBER = 6;
		private float std_;

		/**
		 * <code>optional float std = 6 [default = 1];</code>
		 *
		 * <pre>
		 * the std value in Gaussian filler
		 * </pre>
		 */
		@Override
		public boolean hasStd()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional float std = 6 [default = 1];</code>
		 *
		 * <pre>
		 * the std value in Gaussian filler
		 * </pre>
		 */
		@Override
		public float getStd()
		{
			return std_;
		}

		public static final int SPARSE_FIELD_NUMBER = 7;
		private int sparse_;

		/**
		 * <code>optional int32 sparse = 7 [default = -1];</code>
		 *
		 * <pre>
		 * The expected number of non-zero input weights for a given output in
		 * Gaussian filler -- the default -1 means don't perform sparsification.
		 * </pre>
		 */
		@Override
		public boolean hasSparse()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional int32 sparse = 7 [default = -1];</code>
		 *
		 * <pre>
		 * The expected number of non-zero input weights for a given output in
		 * Gaussian filler -- the default -1 means don't perform sparsification.
		 * </pre>
		 */
		@Override
		public int getSparse()
		{
			return sparse_;
		}

		private void initFields()
		{
			type_ = "constant";
			value_ = 0F;
			min_ = 0F;
			max_ = 1F;
			mean_ = 0F;
			std_ = 1F;
			sparse_ = -1;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getTypeBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeFloat(2, value_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeFloat(3, min_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeFloat(4, max_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeFloat(5, mean_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeFloat(6, std_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeInt32(7, sparse_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getTypeBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(2, value_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(3, min_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(4, max_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(5, mean_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(6, std_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(7, sparse_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.FillerParameter}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.FillerParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_FillerParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_FillerParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				type_ = "constant";
				bitField0_ = (bitField0_ & ~0x00000001);
				value_ = 0F;
				bitField0_ = (bitField0_ & ~0x00000002);
				min_ = 0F;
				bitField0_ = (bitField0_ & ~0x00000004);
				max_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000008);
				mean_ = 0F;
				bitField0_ = (bitField0_ & ~0x00000010);
				std_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000020);
				sparse_ = -1;
				bitField0_ = (bitField0_ & ~0x00000040);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_FillerParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.type_ = type_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.value_ = value_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.min_ = min_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.max_ = max_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.mean_ = mean_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.std_ = std_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.sparse_ = sparse_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					return this;
				if (other.hasType())
				{
					bitField0_ |= 0x00000001;
					type_ = other.type_;
					onChanged();
				}
				if (other.hasValue())
				{
					setValue(other.getValue());
				}
				if (other.hasMin())
				{
					setMin(other.getMin());
				}
				if (other.hasMax())
				{
					setMax(other.getMax());
				}
				if (other.hasMean())
				{
					setMean(other.getMean());
				}
				if (other.hasStd())
				{
					setStd(other.getStd());
				}
				if (other.hasSparse())
				{
					setSparse(other.getSparse());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object type_ = "constant";

			/**
			 * <code>optional string type = 1 [default = "constant"];</code>
			 *
			 * <pre>
			 * The filler type.
			 * </pre>
			 */
			@Override
			public boolean hasType()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string type = 1 [default = "constant"];</code>
			 *
			 * <pre>
			 * The filler type.
			 * </pre>
			 */
			@Override
			public java.lang.String getType()
			{
				java.lang.Object ref = type_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						type_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string type = 1 [default = "constant"];</code>
			 *
			 * <pre>
			 * The filler type.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getTypeBytes()
			{
				java.lang.Object ref = type_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					type_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string type = 1 [default = "constant"];</code>
			 *
			 * <pre>
			 * The filler type.
			 * </pre>
			 */
			public Builder setType(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				type_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string type = 1 [default = "constant"];</code>
			 *
			 * <pre>
			 * The filler type.
			 * </pre>
			 */
			public Builder clearType()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				type_ = getDefaultInstance().getType();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string type = 1 [default = "constant"];</code>
			 *
			 * <pre>
			 * The filler type.
			 * </pre>
			 */
			public Builder setTypeBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				type_ = value;
				onChanged();
				return this;
			}

			private float value_;

			/**
			 * <code>optional float value = 2 [default = 0];</code>
			 *
			 * <pre>
			 * the value in constant filler
			 * </pre>
			 */
			@Override
			public boolean hasValue()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional float value = 2 [default = 0];</code>
			 *
			 * <pre>
			 * the value in constant filler
			 * </pre>
			 */
			@Override
			public float getValue()
			{
				return value_;
			}

			/**
			 * <code>optional float value = 2 [default = 0];</code>
			 *
			 * <pre>
			 * the value in constant filler
			 * </pre>
			 */
			public Builder setValue(float value)
			{
				bitField0_ |= 0x00000002;
				value_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float value = 2 [default = 0];</code>
			 *
			 * <pre>
			 * the value in constant filler
			 * </pre>
			 */
			public Builder clearValue()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				value_ = 0F;
				onChanged();
				return this;
			}

			private float min_;

			/**
			 * <code>optional float min = 3 [default = 0];</code>
			 *
			 * <pre>
			 * the min value in uniform filler
			 * </pre>
			 */
			@Override
			public boolean hasMin()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional float min = 3 [default = 0];</code>
			 *
			 * <pre>
			 * the min value in uniform filler
			 * </pre>
			 */
			@Override
			public float getMin()
			{
				return min_;
			}

			/**
			 * <code>optional float min = 3 [default = 0];</code>
			 *
			 * <pre>
			 * the min value in uniform filler
			 * </pre>
			 */
			public Builder setMin(float value)
			{
				bitField0_ |= 0x00000004;
				min_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float min = 3 [default = 0];</code>
			 *
			 * <pre>
			 * the min value in uniform filler
			 * </pre>
			 */
			public Builder clearMin()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				min_ = 0F;
				onChanged();
				return this;
			}

			private float max_ = 1F;

			/**
			 * <code>optional float max = 4 [default = 1];</code>
			 *
			 * <pre>
			 * the max value in uniform filler
			 * </pre>
			 */
			@Override
			public boolean hasMax()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional float max = 4 [default = 1];</code>
			 *
			 * <pre>
			 * the max value in uniform filler
			 * </pre>
			 */
			@Override
			public float getMax()
			{
				return max_;
			}

			/**
			 * <code>optional float max = 4 [default = 1];</code>
			 *
			 * <pre>
			 * the max value in uniform filler
			 * </pre>
			 */
			public Builder setMax(float value)
			{
				bitField0_ |= 0x00000008;
				max_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float max = 4 [default = 1];</code>
			 *
			 * <pre>
			 * the max value in uniform filler
			 * </pre>
			 */
			public Builder clearMax()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				max_ = 1F;
				onChanged();
				return this;
			}

			private float mean_;

			/**
			 * <code>optional float mean = 5 [default = 0];</code>
			 *
			 * <pre>
			 * the mean value in Gaussian filler
			 * </pre>
			 */
			@Override
			public boolean hasMean()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional float mean = 5 [default = 0];</code>
			 *
			 * <pre>
			 * the mean value in Gaussian filler
			 * </pre>
			 */
			@Override
			public float getMean()
			{
				return mean_;
			}

			/**
			 * <code>optional float mean = 5 [default = 0];</code>
			 *
			 * <pre>
			 * the mean value in Gaussian filler
			 * </pre>
			 */
			public Builder setMean(float value)
			{
				bitField0_ |= 0x00000010;
				mean_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float mean = 5 [default = 0];</code>
			 *
			 * <pre>
			 * the mean value in Gaussian filler
			 * </pre>
			 */
			public Builder clearMean()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				mean_ = 0F;
				onChanged();
				return this;
			}

			private float std_ = 1F;

			/**
			 * <code>optional float std = 6 [default = 1];</code>
			 *
			 * <pre>
			 * the std value in Gaussian filler
			 * </pre>
			 */
			@Override
			public boolean hasStd()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional float std = 6 [default = 1];</code>
			 *
			 * <pre>
			 * the std value in Gaussian filler
			 * </pre>
			 */
			@Override
			public float getStd()
			{
				return std_;
			}

			/**
			 * <code>optional float std = 6 [default = 1];</code>
			 *
			 * <pre>
			 * the std value in Gaussian filler
			 * </pre>
			 */
			public Builder setStd(float value)
			{
				bitField0_ |= 0x00000020;
				std_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float std = 6 [default = 1];</code>
			 *
			 * <pre>
			 * the std value in Gaussian filler
			 * </pre>
			 */
			public Builder clearStd()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				std_ = 1F;
				onChanged();
				return this;
			}

			private int sparse_ = -1;

			/**
			 * <code>optional int32 sparse = 7 [default = -1];</code>
			 *
			 * <pre>
			 * The expected number of non-zero input weights for a given output in
			 * Gaussian filler -- the default -1 means don't perform sparsification.
			 * </pre>
			 */
			@Override
			public boolean hasSparse()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional int32 sparse = 7 [default = -1];</code>
			 *
			 * <pre>
			 * The expected number of non-zero input weights for a given output in
			 * Gaussian filler -- the default -1 means don't perform sparsification.
			 * </pre>
			 */
			@Override
			public int getSparse()
			{
				return sparse_;
			}

			/**
			 * <code>optional int32 sparse = 7 [default = -1];</code>
			 *
			 * <pre>
			 * The expected number of non-zero input weights for a given output in
			 * Gaussian filler -- the default -1 means don't perform sparsification.
			 * </pre>
			 */
			public Builder setSparse(int value)
			{
				bitField0_ |= 0x00000040;
				sparse_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 sparse = 7 [default = -1];</code>
			 *
			 * <pre>
			 * The expected number of non-zero input weights for a given output in
			 * Gaussian filler -- the default -1 means don't perform sparsification.
			 * </pre>
			 */
			public Builder clearSparse()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				sparse_ = -1;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.FillerParameter)
		}

		static
		{
			defaultInstance = new FillerParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.FillerParameter)
	}

	public interface NetParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.NetParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * consider giving the network a name
		 * </pre>
		 */
		boolean hasName();

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * consider giving the network a name
		 * </pre>
		 */
		java.lang.String getName();

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * consider giving the network a name
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getNameBytes();

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter>
				getLayersList();

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter getLayers(int index);

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		int getLayersCount();

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder>
				getLayersOrBuilderList();

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder getLayersOrBuilder(
				int index);

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		com.google.protobuf.ProtocolStringList
				getInputList();

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		int getInputCount();

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		java.lang.String getInput(int index);

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getInputBytes(int index);

		/**
		 * <code>repeated int32 input_dim = 4;</code>
		 *
		 * <pre>
		 * The dim of the input blobs. For each input blob there should be four
		 * values specifying the num, channels, height and width of the input blob.
		 * Thus, there should be a total of (4 * #input) numbers.
		 * </pre>
		 */
		java.util.List<java.lang.Integer> getInputDimList();

		/**
		 * <code>repeated int32 input_dim = 4;</code>
		 *
		 * <pre>
		 * The dim of the input blobs. For each input blob there should be four
		 * values specifying the num, channels, height and width of the input blob.
		 * Thus, there should be a total of (4 * #input) numbers.
		 * </pre>
		 */
		int getInputDimCount();

		/**
		 * <code>repeated int32 input_dim = 4;</code>
		 *
		 * <pre>
		 * The dim of the input blobs. For each input blob there should be four
		 * values specifying the num, channels, height and width of the input blob.
		 * Thus, there should be a total of (4 * #input) numbers.
		 * </pre>
		 */
		int getInputDim(int index);

		/**
		 * <code>optional bool force_backward = 5 [default = false];</code>
		 *
		 * <pre>
		 * Whether the network will force every layer to carry out backward operation.
		 * If set False, then whether to carry out backward is determined
		 * automatically according to the net structure and learning rates.
		 * </pre>
		 */
		boolean hasForceBackward();

		/**
		 * <code>optional bool force_backward = 5 [default = false];</code>
		 *
		 * <pre>
		 * Whether the network will force every layer to carry out backward operation.
		 * If set False, then whether to carry out backward is determined
		 * automatically according to the net structure and learning rates.
		 * </pre>
		 */
		boolean getForceBackward();

		/**
		 * <code>optional .caffe.NetState state = 6;</code>
		 *
		 * <pre>
		 * The current "state" of the network, including the phase, level, and stage.
		 * Some layers may be included/excluded depending on this state and the states
		 * specified in the layers' include and exclude fields.
		 * </pre>
		 */
		boolean hasState();

		/**
		 * <code>optional .caffe.NetState state = 6;</code>
		 *
		 * <pre>
		 * The current "state" of the network, including the phase, level, and stage.
		 * Some layers may be included/excluded depending on this state and the states
		 * specified in the layers' include and exclude fields.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getState();

		/**
		 * <code>optional .caffe.NetState state = 6;</code>
		 *
		 * <pre>
		 * The current "state" of the network, including the phase, level, and stage.
		 * Some layers may be included/excluded depending on this state and the states
		 * specified in the layers' include and exclude fields.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getStateOrBuilder();
	}

	/**
	 * Protobuf type {@code caffe.NetParameter}
	 */
	public static final class NetParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.NetParameter)
			NetParameterOrBuilder
	{
		// Use NetParameter.newBuilder() to construct.
		private NetParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private NetParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final NetParameter defaultInstance;

		public static NetParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public NetParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private NetParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						name_ = bs;
						break;
					}
					case 18:
					{
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002))
						{
							layers_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter>();
							mutable_bitField0_ |= 0x00000002;
						}
						layers_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.PARSER, extensionRegistry));
						break;
					}
					case 26:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000004) == 0x00000004))
						{
							input_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000004;
						}
						input_.add(bs);
						break;
					}
					case 32:
					{
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008))
						{
							inputDim_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000008;
						}
						inputDim_.add(input.readInt32());
						break;
					}
					case 34:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008) && input.getBytesUntilLimit() > 0)
						{
							inputDim_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000008;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							inputDim_.add(input.readInt32());
						}
						input.popLimit(limit);
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000002;
						forceBackward_ = input.readBool();
						break;
					}
					case 50:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder subBuilder = null;
						if (((bitField0_ & 0x00000004) == 0x00000004))
						{
							subBuilder = state_.toBuilder();
						}
						state_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(state_);
							state_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000004;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000002) == 0x00000002))
				{
					layers_ = java.util.Collections.unmodifiableList(layers_);
				}
				if (((mutable_bitField0_ & 0x00000004) == 0x00000004))
				{
					input_ = input_.getUnmodifiableView();
				}
				if (((mutable_bitField0_ & 0x00000008) == 0x00000008))
				{
					inputDim_ = java.util.Collections.unmodifiableList(inputDim_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<NetParameter> PARSER =
				new com.google.protobuf.AbstractParser<NetParameter>()
				{
					@Override
					public NetParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new NetParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<NetParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int NAME_FIELD_NUMBER = 1;
		private java.lang.Object name_;

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * consider giving the network a name
		 * </pre>
		 */
		@Override
		public boolean hasName()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * consider giving the network a name
		 * </pre>
		 */
		@Override
		public java.lang.String getName()
		{
			java.lang.Object ref = name_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					name_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * consider giving the network a name
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getNameBytes()
		{
			java.lang.Object ref = name_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				name_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int LAYERS_FIELD_NUMBER = 2;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter> layers_;

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter> getLayersList()
		{
			return layers_;
		}

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder>
				getLayersOrBuilderList()
		{
			return layers_;
		}

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		@Override
		public int getLayersCount()
		{
			return layers_.size();
		}

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter getLayers(int index)
		{
			return layers_.get(index);
		}

		/**
		 * <code>repeated .caffe.LayerParameter layers = 2;</code>
		 *
		 * <pre>
		 * a bunch of layers.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder getLayersOrBuilder(
				int index)
		{
			return layers_.get(index);
		}

		public static final int INPUT_FIELD_NUMBER = 3;
		private com.google.protobuf.LazyStringList input_;

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getInputList()
		{
			return input_;
		}

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		@Override
		public int getInputCount()
		{
			return input_.size();
		}

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		@Override
		public java.lang.String getInput(int index)
		{
			return input_.get(index);
		}

		/**
		 * <code>repeated string input = 3;</code>
		 *
		 * <pre>
		 * The input blobs to the network.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getInputBytes(int index)
		{
			return input_.getByteString(index);
		}

		public static final int INPUT_DIM_FIELD_NUMBER = 4;
		private java.util.List<java.lang.Integer> inputDim_;

		/**
		 * <code>repeated int32 input_dim = 4;</code>
		 *
		 * <pre>
		 * The dim of the input blobs. For each input blob there should be four
		 * values specifying the num, channels, height and width of the input blob.
		 * Thus, there should be a total of (4 * #input) numbers.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getInputDimList()
		{
			return inputDim_;
		}

		/**
		 * <code>repeated int32 input_dim = 4;</code>
		 *
		 * <pre>
		 * The dim of the input blobs. For each input blob there should be four
		 * values specifying the num, channels, height and width of the input blob.
		 * Thus, there should be a total of (4 * #input) numbers.
		 * </pre>
		 */
		@Override
		public int getInputDimCount()
		{
			return inputDim_.size();
		}

		/**
		 * <code>repeated int32 input_dim = 4;</code>
		 *
		 * <pre>
		 * The dim of the input blobs. For each input blob there should be four
		 * values specifying the num, channels, height and width of the input blob.
		 * Thus, there should be a total of (4 * #input) numbers.
		 * </pre>
		 */
		@Override
		public int getInputDim(int index)
		{
			return inputDim_.get(index);
		}

		public static final int FORCE_BACKWARD_FIELD_NUMBER = 5;
		private boolean forceBackward_;

		/**
		 * <code>optional bool force_backward = 5 [default = false];</code>
		 *
		 * <pre>
		 * Whether the network will force every layer to carry out backward operation.
		 * If set False, then whether to carry out backward is determined
		 * automatically according to the net structure and learning rates.
		 * </pre>
		 */
		@Override
		public boolean hasForceBackward()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bool force_backward = 5 [default = false];</code>
		 *
		 * <pre>
		 * Whether the network will force every layer to carry out backward operation.
		 * If set False, then whether to carry out backward is determined
		 * automatically according to the net structure and learning rates.
		 * </pre>
		 */
		@Override
		public boolean getForceBackward()
		{
			return forceBackward_;
		}

		public static final int STATE_FIELD_NUMBER = 6;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState state_;

		/**
		 * <code>optional .caffe.NetState state = 6;</code>
		 *
		 * <pre>
		 * The current "state" of the network, including the phase, level, and stage.
		 * Some layers may be included/excluded depending on this state and the states
		 * specified in the layers' include and exclude fields.
		 * </pre>
		 */
		@Override
		public boolean hasState()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional .caffe.NetState state = 6;</code>
		 *
		 * <pre>
		 * The current "state" of the network, including the phase, level, and stage.
		 * Some layers may be included/excluded depending on this state and the states
		 * specified in the layers' include and exclude fields.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getState()
		{
			return state_;
		}

		/**
		 * <code>optional .caffe.NetState state = 6;</code>
		 *
		 * <pre>
		 * The current "state" of the network, including the phase, level, and stage.
		 * Some layers may be included/excluded depending on this state and the states
		 * specified in the layers' include and exclude fields.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getStateOrBuilder()
		{
			return state_;
		}

		private void initFields()
		{
			name_ = "";
			layers_ = java.util.Collections.emptyList();
			input_ = com.google.protobuf.LazyStringArrayList.EMPTY;
			inputDim_ = java.util.Collections.emptyList();
			forceBackward_ = false;
			state_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getNameBytes());
			}
			for (int i = 0; i < layers_.size(); i++)
			{
				output.writeMessage(2, layers_.get(i));
			}
			for (int i = 0; i < input_.size(); i++)
			{
				output.writeBytes(3, input_.getByteString(i));
			}
			for (int i = 0; i < inputDim_.size(); i++)
			{
				output.writeInt32(4, inputDim_.get(i));
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBool(5, forceBackward_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeMessage(6, state_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getNameBytes());
			}
			for (int i = 0; i < layers_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(2, layers_.get(i));
			}
			{
				int dataSize = 0;
				for (int i = 0; i < input_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(input_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getInputList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < inputDim_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeInt32SizeNoTag(inputDim_.get(i));
				}
				size += dataSize;
				size += 1 * getInputDimList().size();
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(5, forceBackward_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(6, state_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.NetParameter}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.NetParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getLayersFieldBuilder();
					getStateFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				name_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				if (layersBuilder_ == null)
				{
					layers_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000002);
				} else
				{
					layersBuilder_.clear();
				}
				input_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000004);
				inputDim_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000008);
				forceBackward_ = false;
				bitField0_ = (bitField0_ & ~0x00000010);
				if (stateBuilder_ == null)
				{
					state_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
				} else
				{
					stateBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000020);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.name_ = name_;
				if (layersBuilder_ == null)
				{
					if (((bitField0_ & 0x00000002) == 0x00000002))
					{
						layers_ = java.util.Collections.unmodifiableList(layers_);
						bitField0_ = (bitField0_ & ~0x00000002);
					}
					result.layers_ = layers_;
				} else
				{
					result.layers_ = layersBuilder_.build();
				}
				if (((bitField0_ & 0x00000004) == 0x00000004))
				{
					input_ = input_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000004);
				}
				result.input_ = input_;
				if (((bitField0_ & 0x00000008) == 0x00000008))
				{
					inputDim_ = java.util.Collections.unmodifiableList(inputDim_);
					bitField0_ = (bitField0_ & ~0x00000008);
				}
				result.inputDim_ = inputDim_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.forceBackward_ = forceBackward_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000004;
				}
				if (stateBuilder_ == null)
				{
					result.state_ = state_;
				} else
				{
					result.state_ = stateBuilder_.build();
				}
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance())
					return this;
				if (other.hasName())
				{
					bitField0_ |= 0x00000001;
					name_ = other.name_;
					onChanged();
				}
				if (layersBuilder_ == null)
				{
					if (!other.layers_.isEmpty())
					{
						if (layers_.isEmpty())
						{
							layers_ = other.layers_;
							bitField0_ = (bitField0_ & ~0x00000002);
						} else
						{
							ensureLayersIsMutable();
							layers_.addAll(other.layers_);
						}
						onChanged();
					}
				} else
				{
					if (!other.layers_.isEmpty())
					{
						if (layersBuilder_.isEmpty())
						{
							layersBuilder_.dispose();
							layersBuilder_ = null;
							layers_ = other.layers_;
							bitField0_ = (bitField0_ & ~0x00000002);
							layersBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getLayersFieldBuilder() : null;
						} else
						{
							layersBuilder_.addAllMessages(other.layers_);
						}
					}
				}
				if (!other.input_.isEmpty())
				{
					if (input_.isEmpty())
					{
						input_ = other.input_;
						bitField0_ = (bitField0_ & ~0x00000004);
					} else
					{
						ensureInputIsMutable();
						input_.addAll(other.input_);
					}
					onChanged();
				}
				if (!other.inputDim_.isEmpty())
				{
					if (inputDim_.isEmpty())
					{
						inputDim_ = other.inputDim_;
						bitField0_ = (bitField0_ & ~0x00000008);
					} else
					{
						ensureInputDimIsMutable();
						inputDim_.addAll(other.inputDim_);
					}
					onChanged();
				}
				if (other.hasForceBackward())
				{
					setForceBackward(other.getForceBackward());
				}
				if (other.hasState())
				{
					mergeState(other.getState());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object name_ = "";

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * consider giving the network a name
			 * </pre>
			 */
			@Override
			public boolean hasName()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * consider giving the network a name
			 * </pre>
			 */
			@Override
			public java.lang.String getName()
			{
				java.lang.Object ref = name_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						name_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * consider giving the network a name
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getNameBytes()
			{
				java.lang.Object ref = name_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					name_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * consider giving the network a name
			 * </pre>
			 */
			public Builder setName(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				name_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * consider giving the network a name
			 * </pre>
			 */
			public Builder clearName()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				name_ = getDefaultInstance().getName();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * consider giving the network a name
			 * </pre>
			 */
			public Builder setNameBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				name_ = value;
				onChanged();
				return this;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter> layers_ =
					java.util.Collections.emptyList();

			private void ensureLayersIsMutable()
			{
				if (!((bitField0_ & 0x00000002) == 0x00000002))
				{
					layers_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter>(layers_);
					bitField0_ |= 0x00000002;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder> layersBuilder_;

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter> getLayersList()
			{
				if (layersBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(layers_);
				} else
				{
					return layersBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			@Override
			public int getLayersCount()
			{
				if (layersBuilder_ == null)
				{
					return layers_.size();
				} else
				{
					return layersBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter getLayers(int index)
			{
				if (layersBuilder_ == null)
				{
					return layers_.get(index);
				} else
				{
					return layersBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder setLayers(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter value)
			{
				if (layersBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureLayersIsMutable();
					layers_.set(index, value);
					onChanged();
				} else
				{
					layersBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder setLayers(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder builderForValue)
			{
				if (layersBuilder_ == null)
				{
					ensureLayersIsMutable();
					layers_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					layersBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder addLayers(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter value)
			{
				if (layersBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureLayersIsMutable();
					layers_.add(value);
					onChanged();
				} else
				{
					layersBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder addLayers(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter value)
			{
				if (layersBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureLayersIsMutable();
					layers_.add(index, value);
					onChanged();
				} else
				{
					layersBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder addLayers(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder builderForValue)
			{
				if (layersBuilder_ == null)
				{
					ensureLayersIsMutable();
					layers_.add(builderForValue.build());
					onChanged();
				} else
				{
					layersBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder addLayers(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder builderForValue)
			{
				if (layersBuilder_ == null)
				{
					ensureLayersIsMutable();
					layers_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					layersBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder addAllLayers(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter> values)
			{
				if (layersBuilder_ == null)
				{
					ensureLayersIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, layers_);
					onChanged();
				} else
				{
					layersBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder clearLayers()
			{
				if (layersBuilder_ == null)
				{
					layers_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000002);
					onChanged();
				} else
				{
					layersBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public Builder removeLayers(int index)
			{
				if (layersBuilder_ == null)
				{
					ensureLayersIsMutable();
					layers_.remove(index);
					onChanged();
				} else
				{
					layersBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder getLayersBuilder(
					int index)
			{
				return getLayersFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder getLayersOrBuilder(
					int index)
			{
				if (layersBuilder_ == null)
				{
					return layers_.get(index);
				} else
				{
					return layersBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder>
					getLayersOrBuilderList()
			{
				if (layersBuilder_ != null)
				{
					return layersBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(layers_);
				}
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder addLayersBuilder()
			{
				return getLayersFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder addLayersBuilder(
					int index)
			{
				return getLayersFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.LayerParameter layers = 2;</code>
			 *
			 * <pre>
			 * a bunch of layers.
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder>
					getLayersBuilderList()
			{
				return getLayersFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder>
					getLayersFieldBuilder()
			{
				if (layersBuilder_ == null)
				{
					layersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder>(
									layers_,
									((bitField0_ & 0x00000002) == 0x00000002),
									getParentForChildren(),
									isClean());
					layers_ = null;
				}
				return layersBuilder_;
			}

			private com.google.protobuf.LazyStringList input_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureInputIsMutable()
			{
				if (!((bitField0_ & 0x00000004) == 0x00000004))
				{
					input_ = new com.google.protobuf.LazyStringArrayList(input_);
					bitField0_ |= 0x00000004;
				}
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getInputList()
			{
				return input_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			@Override
			public int getInputCount()
			{
				return input_.size();
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			@Override
			public java.lang.String getInput(int index)
			{
				return input_.get(index);
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getInputBytes(int index)
			{
				return input_.getByteString(index);
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			public Builder setInput(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureInputIsMutable();
				input_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			public Builder addInput(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureInputIsMutable();
				input_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			public Builder addAllInput(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureInputIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, input_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			public Builder clearInput()
			{
				input_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000004);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string input = 3;</code>
			 *
			 * <pre>
			 * The input blobs to the network.
			 * </pre>
			 */
			public Builder addInputBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureInputIsMutable();
				input_.add(value);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Integer> inputDim_ = java.util.Collections.emptyList();

			private void ensureInputDimIsMutable()
			{
				if (!((bitField0_ & 0x00000008) == 0x00000008))
				{
					inputDim_ = new java.util.ArrayList<java.lang.Integer>(inputDim_);
					bitField0_ |= 0x00000008;
				}
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getInputDimList()
			{
				return java.util.Collections.unmodifiableList(inputDim_);
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			@Override
			public int getInputDimCount()
			{
				return inputDim_.size();
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			@Override
			public int getInputDim(int index)
			{
				return inputDim_.get(index);
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			public Builder setInputDim(
					int index, int value)
			{
				ensureInputDimIsMutable();
				inputDim_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			public Builder addInputDim(int value)
			{
				ensureInputDimIsMutable();
				inputDim_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			public Builder addAllInputDim(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureInputDimIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, inputDim_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 input_dim = 4;</code>
			 *
			 * <pre>
			 * The dim of the input blobs. For each input blob there should be four
			 * values specifying the num, channels, height and width of the input blob.
			 * Thus, there should be a total of (4 * #input) numbers.
			 * </pre>
			 */
			public Builder clearInputDim()
			{
				inputDim_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000008);
				onChanged();
				return this;
			}

			private boolean forceBackward_;

			/**
			 * <code>optional bool force_backward = 5 [default = false];</code>
			 *
			 * <pre>
			 * Whether the network will force every layer to carry out backward operation.
			 * If set False, then whether to carry out backward is determined
			 * automatically according to the net structure and learning rates.
			 * </pre>
			 */
			@Override
			public boolean hasForceBackward()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional bool force_backward = 5 [default = false];</code>
			 *
			 * <pre>
			 * Whether the network will force every layer to carry out backward operation.
			 * If set False, then whether to carry out backward is determined
			 * automatically according to the net structure and learning rates.
			 * </pre>
			 */
			@Override
			public boolean getForceBackward()
			{
				return forceBackward_;
			}

			/**
			 * <code>optional bool force_backward = 5 [default = false];</code>
			 *
			 * <pre>
			 * Whether the network will force every layer to carry out backward operation.
			 * If set False, then whether to carry out backward is determined
			 * automatically according to the net structure and learning rates.
			 * </pre>
			 */
			public Builder setForceBackward(boolean value)
			{
				bitField0_ |= 0x00000010;
				forceBackward_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool force_backward = 5 [default = false];</code>
			 *
			 * <pre>
			 * Whether the network will force every layer to carry out backward operation.
			 * If set False, then whether to carry out backward is determined
			 * automatically according to the net structure and learning rates.
			 * </pre>
			 */
			public Builder clearForceBackward()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				forceBackward_ = false;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState state_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder> stateBuilder_;

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			@Override
			public boolean hasState()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getState()
			{
				if (stateBuilder_ == null)
				{
					return state_;
				} else
				{
					return stateBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			public Builder setState(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (stateBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					state_ = value;
					onChanged();
				} else
				{
					stateBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			public Builder setState(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder builderForValue)
			{
				if (stateBuilder_ == null)
				{
					state_ = builderForValue.build();
					onChanged();
				} else
				{
					stateBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			public Builder mergeState(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (stateBuilder_ == null)
				{
					if (((bitField0_ & 0x00000020) == 0x00000020) &&
							state_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance())
					{
						state_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.newBuilder(state_).mergeFrom(value).buildPartial();
					} else
					{
						state_ = value;
					}
					onChanged();
				} else
				{
					stateBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			public Builder clearState()
			{
				if (stateBuilder_ == null)
				{
					state_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
					onChanged();
				} else
				{
					stateBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000020);
				return this;
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder getStateBuilder()
			{
				bitField0_ |= 0x00000020;
				onChanged();
				return getStateFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getStateOrBuilder()
			{
				if (stateBuilder_ != null)
				{
					return stateBuilder_.getMessageOrBuilder();
				} else
				{
					return state_;
				}
			}

			/**
			 * <code>optional .caffe.NetState state = 6;</code>
			 *
			 * <pre>
			 * The current "state" of the network, including the phase, level, and stage.
			 * Some layers may be included/excluded depending on this state and the states
			 * specified in the layers' include and exclude fields.
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>
					getStateFieldBuilder()
			{
				if (stateBuilder_ == null)
				{
					stateBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>(
									getState(),
									getParentForChildren(),
									isClean());
					state_ = null;
				}
				return stateBuilder_;
			}

			// @@protoc_insertion_point(builder_scope:caffe.NetParameter)
		}

		static
		{
			defaultInstance = new NetParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.NetParameter)
	}

	public interface SolverParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.SolverParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string net = 24;</code>
		 *
		 * <pre>
		 * Proto filename for the train net, possibly combined with one or more
		 * test nets.
		 * </pre>
		 */
		boolean hasNet();

		/**
		 * <code>optional string net = 24;</code>
		 *
		 * <pre>
		 * Proto filename for the train net, possibly combined with one or more
		 * test nets.
		 * </pre>
		 */
		java.lang.String getNet();

		/**
		 * <code>optional string net = 24;</code>
		 *
		 * <pre>
		 * Proto filename for the train net, possibly combined with one or more
		 * test nets.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getNetBytes();

		/**
		 * <code>optional .caffe.NetParameter net_param = 25;</code>
		 *
		 * <pre>
		 * Inline train net param, possibly combined with one or more test nets.
		 * </pre>
		 */
		boolean hasNetParam();

		/**
		 * <code>optional .caffe.NetParameter net_param = 25;</code>
		 *
		 * <pre>
		 * Inline train net param, possibly combined with one or more test nets.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getNetParam();

		/**
		 * <code>optional .caffe.NetParameter net_param = 25;</code>
		 *
		 * <pre>
		 * Inline train net param, possibly combined with one or more test nets.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getNetParamOrBuilder();

		/**
		 * <code>optional string train_net = 1;</code>
		 *
		 * <pre>
		 * Proto filename for the train net.
		 * </pre>
		 */
		boolean hasTrainNet();

		/**
		 * <code>optional string train_net = 1;</code>
		 *
		 * <pre>
		 * Proto filename for the train net.
		 * </pre>
		 */
		java.lang.String getTrainNet();

		/**
		 * <code>optional string train_net = 1;</code>
		 *
		 * <pre>
		 * Proto filename for the train net.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getTrainNetBytes();

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		com.google.protobuf.ProtocolStringList
				getTestNetList();

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		int getTestNetCount();

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		java.lang.String getTestNet(int index);

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getTestNetBytes(int index);

		/**
		 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
		 *
		 * <pre>
		 * Inline train net params.
		 * </pre>
		 */
		boolean hasTrainNetParam();

		/**
		 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
		 *
		 * <pre>
		 * Inline train net params.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getTrainNetParam();

		/**
		 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
		 *
		 * <pre>
		 * Inline train net params.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getTrainNetParamOrBuilder();

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter>
				getTestNetParamList();

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getTestNetParam(int index);

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		int getTestNetParamCount();

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>
				getTestNetParamOrBuilderList();

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getTestNetParamOrBuilder(
				int index);

		/**
		 * <code>optional .caffe.NetState train_state = 26;</code>
		 *
		 * <pre>
		 * The states for the train/test nets. Must be unspecified or
		 * specified once per net.
		 * By default, all states will have solver = true;
		 * train_state will have phase = TRAIN,
		 * and all test_state's will have phase = TEST.
		 * Other defaults are set according to the NetState defaults.
		 * </pre>
		 */
		boolean hasTrainState();

		/**
		 * <code>optional .caffe.NetState train_state = 26;</code>
		 *
		 * <pre>
		 * The states for the train/test nets. Must be unspecified or
		 * specified once per net.
		 * By default, all states will have solver = true;
		 * train_state will have phase = TRAIN,
		 * and all test_state's will have phase = TEST.
		 * Other defaults are set according to the NetState defaults.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getTrainState();

		/**
		 * <code>optional .caffe.NetState train_state = 26;</code>
		 *
		 * <pre>
		 * The states for the train/test nets. Must be unspecified or
		 * specified once per net.
		 * By default, all states will have solver = true;
		 * train_state will have phase = TRAIN,
		 * and all test_state's will have phase = TEST.
		 * Other defaults are set according to the NetState defaults.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getTrainStateOrBuilder();

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState>
				getTestStateList();

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getTestState(int index);

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		int getTestStateCount();

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>
				getTestStateOrBuilderList();

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getTestStateOrBuilder(
				int index);

		/**
		 * <code>repeated int32 test_iter = 3;</code>
		 *
		 * <pre>
		 * The number of iterations for each test net.
		 * </pre>
		 */
		java.util.List<java.lang.Integer> getTestIterList();

		/**
		 * <code>repeated int32 test_iter = 3;</code>
		 *
		 * <pre>
		 * The number of iterations for each test net.
		 * </pre>
		 */
		int getTestIterCount();

		/**
		 * <code>repeated int32 test_iter = 3;</code>
		 *
		 * <pre>
		 * The number of iterations for each test net.
		 * </pre>
		 */
		int getTestIter(int index);

		/**
		 * <code>optional int32 test_interval = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The number of iterations between two testing phases.
		 * </pre>
		 */
		boolean hasTestInterval();

		/**
		 * <code>optional int32 test_interval = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The number of iterations between two testing phases.
		 * </pre>
		 */
		int getTestInterval();

		/**
		 * <code>optional bool test_compute_loss = 19 [default = false];</code>
		 */
		boolean hasTestComputeLoss();

		/**
		 * <code>optional bool test_compute_loss = 19 [default = false];</code>
		 */
		boolean getTestComputeLoss();

		/**
		 * <code>optional bool test_initialization = 32 [default = true];</code>
		 *
		 * <pre>
		 * If true, run an initial test pass before the first iteration,
		 * ensuring memory availability and printing the starting value of the loss.
		 * </pre>
		 */
		boolean hasTestInitialization();

		/**
		 * <code>optional bool test_initialization = 32 [default = true];</code>
		 *
		 * <pre>
		 * If true, run an initial test pass before the first iteration,
		 * ensuring memory availability and printing the starting value of the loss.
		 * </pre>
		 */
		boolean getTestInitialization();

		/**
		 * <code>optional float base_lr = 5;</code>
		 *
		 * <pre>
		 * The base learning rate
		 * </pre>
		 */
		boolean hasBaseLr();

		/**
		 * <code>optional float base_lr = 5;</code>
		 *
		 * <pre>
		 * The base learning rate
		 * </pre>
		 */
		float getBaseLr();

		/**
		 * <code>optional int32 display = 6;</code>
		 *
		 * <pre>
		 * the number of iterations between displaying info. If display = 0, no info
		 * will be displayed.
		 * </pre>
		 */
		boolean hasDisplay();

		/**
		 * <code>optional int32 display = 6;</code>
		 *
		 * <pre>
		 * the number of iterations between displaying info. If display = 0, no info
		 * will be displayed.
		 * </pre>
		 */
		int getDisplay();

		/**
		 * <code>optional int32 average_loss = 33 [default = 1];</code>
		 *
		 * <pre>
		 * Display the cost averaged over the last average_cost iterations
		 * </pre>
		 */
		boolean hasAverageLoss();

		/**
		 * <code>optional int32 average_loss = 33 [default = 1];</code>
		 *
		 * <pre>
		 * Display the cost averaged over the last average_cost iterations
		 * </pre>
		 */
		int getAverageLoss();

		/**
		 * <code>optional int32 max_iter = 7;</code>
		 *
		 * <pre>
		 * the maximum number of iterations
		 * </pre>
		 */
		boolean hasMaxIter();

		/**
		 * <code>optional int32 max_iter = 7;</code>
		 *
		 * <pre>
		 * the maximum number of iterations
		 * </pre>
		 */
		int getMaxIter();

		/**
		 * <code>optional string lr_policy = 8;</code>
		 *
		 * <pre>
		 * The learning rate decay policy.
		 * </pre>
		 */
		boolean hasLrPolicy();

		/**
		 * <code>optional string lr_policy = 8;</code>
		 *
		 * <pre>
		 * The learning rate decay policy.
		 * </pre>
		 */
		java.lang.String getLrPolicy();

		/**
		 * <code>optional string lr_policy = 8;</code>
		 *
		 * <pre>
		 * The learning rate decay policy.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getLrPolicyBytes();

		/**
		 * <code>optional float gamma = 9;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		boolean hasGamma();

		/**
		 * <code>optional float gamma = 9;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		float getGamma();

		/**
		 * <code>optional float power = 10;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		boolean hasPower();

		/**
		 * <code>optional float power = 10;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		float getPower();

		/**
		 * <code>optional float momentum = 11;</code>
		 *
		 * <pre>
		 * The momentum value.
		 * </pre>
		 */
		boolean hasMomentum();

		/**
		 * <code>optional float momentum = 11;</code>
		 *
		 * <pre>
		 * The momentum value.
		 * </pre>
		 */
		float getMomentum();

		/**
		 * <code>optional float weight_decay = 12;</code>
		 *
		 * <pre>
		 * The weight decay.
		 * </pre>
		 */
		boolean hasWeightDecay();

		/**
		 * <code>optional float weight_decay = 12;</code>
		 *
		 * <pre>
		 * The weight decay.
		 * </pre>
		 */
		float getWeightDecay();

		/**
		 * <code>optional string regularization_type = 29 [default = "L2"];</code>
		 *
		 * <pre>
		 * regularization types supported: L1 and L2
		 * controlled by weight_decay
		 * </pre>
		 */
		boolean hasRegularizationType();

		/**
		 * <code>optional string regularization_type = 29 [default = "L2"];</code>
		 *
		 * <pre>
		 * regularization types supported: L1 and L2
		 * controlled by weight_decay
		 * </pre>
		 */
		java.lang.String getRegularizationType();

		/**
		 * <code>optional string regularization_type = 29 [default = "L2"];</code>
		 *
		 * <pre>
		 * regularization types supported: L1 and L2
		 * controlled by weight_decay
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getRegularizationTypeBytes();

		/**
		 * <code>optional int32 stepsize = 13;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "step"
		 * </pre>
		 */
		boolean hasStepsize();

		/**
		 * <code>optional int32 stepsize = 13;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "step"
		 * </pre>
		 */
		int getStepsize();

		/**
		 * <code>repeated int32 stepvalue = 34;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "multistep"
		 * </pre>
		 */
		java.util.List<java.lang.Integer> getStepvalueList();

		/**
		 * <code>repeated int32 stepvalue = 34;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "multistep"
		 * </pre>
		 */
		int getStepvalueCount();

		/**
		 * <code>repeated int32 stepvalue = 34;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "multistep"
		 * </pre>
		 */
		int getStepvalue(int index);

		/**
		 * <code>optional int32 snapshot = 14 [default = 0];</code>
		 *
		 * <pre>
		 * The snapshot interval
		 * </pre>
		 */
		boolean hasSnapshot();

		/**
		 * <code>optional int32 snapshot = 14 [default = 0];</code>
		 *
		 * <pre>
		 * The snapshot interval
		 * </pre>
		 */
		int getSnapshot();

		/**
		 * <code>optional string snapshot_prefix = 15;</code>
		 *
		 * <pre>
		 * The prefix for the snapshot.
		 * </pre>
		 */
		boolean hasSnapshotPrefix();

		/**
		 * <code>optional string snapshot_prefix = 15;</code>
		 *
		 * <pre>
		 * The prefix for the snapshot.
		 * </pre>
		 */
		java.lang.String getSnapshotPrefix();

		/**
		 * <code>optional string snapshot_prefix = 15;</code>
		 *
		 * <pre>
		 * The prefix for the snapshot.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSnapshotPrefixBytes();

		/**
		 * <code>optional bool snapshot_diff = 16 [default = false];</code>
		 *
		 * <pre>
		 * whether to snapshot diff in the results or not. Snapshotting diff will help
		 * debugging but the final protocol buffer size will be much larger.
		 * </pre>
		 */
		boolean hasSnapshotDiff();

		/**
		 * <code>optional bool snapshot_diff = 16 [default = false];</code>
		 *
		 * <pre>
		 * whether to snapshot diff in the results or not. Snapshotting diff will help
		 * debugging but the final protocol buffer size will be much larger.
		 * </pre>
		 */
		boolean getSnapshotDiff();

		/**
		 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
		 */
		boolean hasSolverMode();

		/**
		 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode getSolverMode();

		/**
		 * <code>optional int32 device_id = 18 [default = 0];</code>
		 *
		 * <pre>
		 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
		 * </pre>
		 */
		boolean hasDeviceId();

		/**
		 * <code>optional int32 device_id = 18 [default = 0];</code>
		 *
		 * <pre>
		 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
		 * </pre>
		 */
		int getDeviceId();

		/**
		 * <code>optional int64 random_seed = 20 [default = -1];</code>
		 *
		 * <pre>
		 * If non-negative, the seed with which the Solver will initialize the Caffe
		 * random number generator -- useful for reproducible results. Otherwise,
		 * (and by default) initialize using a seed derived from the system clock.
		 * </pre>
		 */
		boolean hasRandomSeed();

		/**
		 * <code>optional int64 random_seed = 20 [default = -1];</code>
		 *
		 * <pre>
		 * If non-negative, the seed with which the Solver will initialize the Caffe
		 * random number generator -- useful for reproducible results. Otherwise,
		 * (and by default) initialize using a seed derived from the system clock.
		 * </pre>
		 */
		long getRandomSeed();

		/**
		 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
		 */
		boolean hasSolverType();

		/**
		 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType getSolverType();

		/**
		 * <code>optional float delta = 31 [default = 1e-008];</code>
		 *
		 * <pre>
		 * numerical stability for AdaGrad
		 * </pre>
		 */
		boolean hasDelta();

		/**
		 * <code>optional float delta = 31 [default = 1e-008];</code>
		 *
		 * <pre>
		 * numerical stability for AdaGrad
		 * </pre>
		 */
		float getDelta();

		/**
		 * <code>optional bool debug_info = 23 [default = false];</code>
		 *
		 * <pre>
		 * If true, print information about the state of the net that may help with
		 * debugging learning problems.
		 * </pre>
		 */
		boolean hasDebugInfo();

		/**
		 * <code>optional bool debug_info = 23 [default = false];</code>
		 *
		 * <pre>
		 * If true, print information about the state of the net that may help with
		 * debugging learning problems.
		 * </pre>
		 */
		boolean getDebugInfo();

		/**
		 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
		 *
		 * <pre>
		 * If false, don't save a snapshot after training finishes.
		 * </pre>
		 */
		boolean hasSnapshotAfterTrain();

		/**
		 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
		 *
		 * <pre>
		 * If false, don't save a snapshot after training finishes.
		 * </pre>
		 */
		boolean getSnapshotAfterTrain();
	}

	/**
	 * Protobuf type {@code caffe.SolverParameter}
	 *
	 * <pre>
	 * NOTE
	 * Update the next available ID when you add a new SolverParameter field.
	 * SolverParameter next available ID: 35 (last added: stepvalue)
	 * </pre>
	 */
	public static final class SolverParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.SolverParameter)
			SolverParameterOrBuilder
	{
		// Use SolverParameter.newBuilder() to construct.
		private SolverParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private SolverParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final SolverParameter defaultInstance;

		public static SolverParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public SolverParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private SolverParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			int mutable_bitField1_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000004;
						trainNet_ = bs;
						break;
					}
					case 18:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008))
						{
							testNet_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000008;
						}
						testNet_.add(bs);
						break;
					}
					case 24:
					{
						if (!((mutable_bitField0_ & 0x00000100) == 0x00000100))
						{
							testIter_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000100;
						}
						testIter_.add(input.readInt32());
						break;
					}
					case 26:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000100) == 0x00000100) && input.getBytesUntilLimit() > 0)
						{
							testIter_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000100;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							testIter_.add(input.readInt32());
						}
						input.popLimit(limit);
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000020;
						testInterval_ = input.readInt32();
						break;
					}
					case 45:
					{
						bitField0_ |= 0x00000100;
						baseLr_ = input.readFloat();
						break;
					}
					case 48:
					{
						bitField0_ |= 0x00000200;
						display_ = input.readInt32();
						break;
					}
					case 56:
					{
						bitField0_ |= 0x00000800;
						maxIter_ = input.readInt32();
						break;
					}
					case 66:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00001000;
						lrPolicy_ = bs;
						break;
					}
					case 77:
					{
						bitField0_ |= 0x00002000;
						gamma_ = input.readFloat();
						break;
					}
					case 85:
					{
						bitField0_ |= 0x00004000;
						power_ = input.readFloat();
						break;
					}
					case 93:
					{
						bitField0_ |= 0x00008000;
						momentum_ = input.readFloat();
						break;
					}
					case 101:
					{
						bitField0_ |= 0x00010000;
						weightDecay_ = input.readFloat();
						break;
					}
					case 104:
					{
						bitField0_ |= 0x00040000;
						stepsize_ = input.readInt32();
						break;
					}
					case 112:
					{
						bitField0_ |= 0x00080000;
						snapshot_ = input.readInt32();
						break;
					}
					case 122:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00100000;
						snapshotPrefix_ = bs;
						break;
					}
					case 128:
					{
						bitField0_ |= 0x00200000;
						snapshotDiff_ = input.readBool();
						break;
					}
					case 136:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(17, rawValue);
						} else
						{
							bitField0_ |= 0x00400000;
							solverMode_ = value;
						}
						break;
					}
					case 144:
					{
						bitField0_ |= 0x00800000;
						deviceId_ = input.readInt32();
						break;
					}
					case 152:
					{
						bitField0_ |= 0x00000040;
						testComputeLoss_ = input.readBool();
						break;
					}
					case 160:
					{
						bitField0_ |= 0x01000000;
						randomSeed_ = input.readInt64();
						break;
					}
					case 170:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000008) == 0x00000008))
						{
							subBuilder = trainNetParam_.toBuilder();
						}
						trainNetParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(trainNetParam_);
							trainNetParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000008;
						break;
					}
					case 178:
					{
						if (!((mutable_bitField0_ & 0x00000020) == 0x00000020))
						{
							testNetParam_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter>();
							mutable_bitField0_ |= 0x00000020;
						}
						testNetParam_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.PARSER, extensionRegistry));
						break;
					}
					case 184:
					{
						bitField0_ |= 0x08000000;
						debugInfo_ = input.readBool();
						break;
					}
					case 194:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						net_ = bs;
						break;
					}
					case 202:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000002) == 0x00000002))
						{
							subBuilder = netParam_.toBuilder();
						}
						netParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(netParam_);
							netParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000002;
						break;
					}
					case 210:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder subBuilder = null;
						if (((bitField0_ & 0x00000010) == 0x00000010))
						{
							subBuilder = trainState_.toBuilder();
						}
						trainState_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(trainState_);
							trainState_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000010;
						break;
					}
					case 218:
					{
						if (!((mutable_bitField0_ & 0x00000080) == 0x00000080))
						{
							testState_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState>();
							mutable_bitField0_ |= 0x00000080;
						}
						testState_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.PARSER, extensionRegistry));
						break;
					}
					case 224:
					{
						bitField0_ |= 0x10000000;
						snapshotAfterTrain_ = input.readBool();
						break;
					}
					case 234:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00020000;
						regularizationType_ = bs;
						break;
					}
					case 240:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(30, rawValue);
						} else
						{
							bitField0_ |= 0x02000000;
							solverType_ = value;
						}
						break;
					}
					case 253:
					{
						bitField0_ |= 0x04000000;
						delta_ = input.readFloat();
						break;
					}
					case 256:
					{
						bitField0_ |= 0x00000080;
						testInitialization_ = input.readBool();
						break;
					}
					case 264:
					{
						bitField0_ |= 0x00000400;
						averageLoss_ = input.readInt32();
						break;
					}
					case 272:
					{
						if (!((mutable_bitField0_ & 0x00800000) == 0x00800000))
						{
							stepvalue_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00800000;
						}
						stepvalue_.add(input.readInt32());
						break;
					}
					case 274:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00800000) == 0x00800000) && input.getBytesUntilLimit() > 0)
						{
							stepvalue_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00800000;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							stepvalue_.add(input.readInt32());
						}
						input.popLimit(limit);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000008) == 0x00000008))
				{
					testNet_ = testNet_.getUnmodifiableView();
				}
				if (((mutable_bitField0_ & 0x00000100) == 0x00000100))
				{
					testIter_ = java.util.Collections.unmodifiableList(testIter_);
				}
				if (((mutable_bitField0_ & 0x00000020) == 0x00000020))
				{
					testNetParam_ = java.util.Collections.unmodifiableList(testNetParam_);
				}
				if (((mutable_bitField0_ & 0x00000080) == 0x00000080))
				{
					testState_ = java.util.Collections.unmodifiableList(testState_);
				}
				if (((mutable_bitField0_ & 0x00800000) == 0x00800000))
				{
					stepvalue_ = java.util.Collections.unmodifiableList(stepvalue_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<SolverParameter> PARSER =
				new com.google.protobuf.AbstractParser<SolverParameter>()
				{
					@Override
					public SolverParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new SolverParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<SolverParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.SolverParameter.SolverMode}
		 *
		 * <pre>
		 * the mode solver will use: 0 for CPU and 1 for GPU. Use GPU in default.
		 * </pre>
		 */
		public enum SolverMode
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>CPU = 0;</code>
			 */
			CPU(0, 0),
			/**
			 * <code>GPU = 1;</code>
			 */
			GPU(1, 1), ;

			/**
			 * <code>CPU = 0;</code>
			 */
			public static final int CPU_VALUE = 0;
			/**
			 * <code>GPU = 1;</code>
			 */
			public static final int GPU_VALUE = 1;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static SolverMode valueOf(int value)
			{
				switch (value) {
				case 0:
					return CPU;
				case 1:
					return GPU;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<SolverMode>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<SolverMode> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<SolverMode>()
					{
						@Override
						public SolverMode findValueByNumber(int number)
						{
							return SolverMode.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final SolverMode[] VALUES = values();

			public static SolverMode valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private SolverMode(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.SolverParameter.SolverMode)
		}

		/**
		 * Protobuf enum {@code caffe.SolverParameter.SolverType}
		 *
		 * <pre>
		 * Solver type
		 * </pre>
		 */
		public enum SolverType
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>SGD = 0;</code>
			 */
			SGD(0, 0),
			/**
			 * <code>NESTEROV = 1;</code>
			 */
			NESTEROV(1, 1),
			/**
			 * <code>ADAGRAD = 2;</code>
			 */
			ADAGRAD(2, 2), ;

			/**
			 * <code>SGD = 0;</code>
			 */
			public static final int SGD_VALUE = 0;
			/**
			 * <code>NESTEROV = 1;</code>
			 */
			public static final int NESTEROV_VALUE = 1;
			/**
			 * <code>ADAGRAD = 2;</code>
			 */
			public static final int ADAGRAD_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static SolverType valueOf(int value)
			{
				switch (value) {
				case 0:
					return SGD;
				case 1:
					return NESTEROV;
				case 2:
					return ADAGRAD;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<SolverType>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<SolverType> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<SolverType>()
					{
						@Override
						public SolverType findValueByNumber(int number)
						{
							return SolverType.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.getDescriptor().getEnumTypes().get(1);
			}

			private static final SolverType[] VALUES = values();

			public static SolverType valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private SolverType(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.SolverParameter.SolverType)
		}

		private int bitField0_;
		public static final int NET_FIELD_NUMBER = 24;
		private java.lang.Object net_;

		/**
		 * <code>optional string net = 24;</code>
		 *
		 * <pre>
		 * Proto filename for the train net, possibly combined with one or more
		 * test nets.
		 * </pre>
		 */
		@Override
		public boolean hasNet()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string net = 24;</code>
		 *
		 * <pre>
		 * Proto filename for the train net, possibly combined with one or more
		 * test nets.
		 * </pre>
		 */
		@Override
		public java.lang.String getNet()
		{
			java.lang.Object ref = net_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					net_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string net = 24;</code>
		 *
		 * <pre>
		 * Proto filename for the train net, possibly combined with one or more
		 * test nets.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getNetBytes()
		{
			java.lang.Object ref = net_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				net_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int NET_PARAM_FIELD_NUMBER = 25;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter netParam_;

		/**
		 * <code>optional .caffe.NetParameter net_param = 25;</code>
		 *
		 * <pre>
		 * Inline train net param, possibly combined with one or more test nets.
		 * </pre>
		 */
		@Override
		public boolean hasNetParam()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional .caffe.NetParameter net_param = 25;</code>
		 *
		 * <pre>
		 * Inline train net param, possibly combined with one or more test nets.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getNetParam()
		{
			return netParam_;
		}

		/**
		 * <code>optional .caffe.NetParameter net_param = 25;</code>
		 *
		 * <pre>
		 * Inline train net param, possibly combined with one or more test nets.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getNetParamOrBuilder()
		{
			return netParam_;
		}

		public static final int TRAIN_NET_FIELD_NUMBER = 1;
		private java.lang.Object trainNet_;

		/**
		 * <code>optional string train_net = 1;</code>
		 *
		 * <pre>
		 * Proto filename for the train net.
		 * </pre>
		 */
		@Override
		public boolean hasTrainNet()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional string train_net = 1;</code>
		 *
		 * <pre>
		 * Proto filename for the train net.
		 * </pre>
		 */
		@Override
		public java.lang.String getTrainNet()
		{
			java.lang.Object ref = trainNet_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					trainNet_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string train_net = 1;</code>
		 *
		 * <pre>
		 * Proto filename for the train net.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getTrainNetBytes()
		{
			java.lang.Object ref = trainNet_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				trainNet_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int TEST_NET_FIELD_NUMBER = 2;
		private com.google.protobuf.LazyStringList testNet_;

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getTestNetList()
		{
			return testNet_;
		}

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		@Override
		public int getTestNetCount()
		{
			return testNet_.size();
		}

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		@Override
		public java.lang.String getTestNet(int index)
		{
			return testNet_.get(index);
		}

		/**
		 * <code>repeated string test_net = 2;</code>
		 *
		 * <pre>
		 * Proto filenames for the test nets.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getTestNetBytes(int index)
		{
			return testNet_.getByteString(index);
		}

		public static final int TRAIN_NET_PARAM_FIELD_NUMBER = 21;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter trainNetParam_;

		/**
		 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
		 *
		 * <pre>
		 * Inline train net params.
		 * </pre>
		 */
		@Override
		public boolean hasTrainNetParam()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
		 *
		 * <pre>
		 * Inline train net params.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getTrainNetParam()
		{
			return trainNetParam_;
		}

		/**
		 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
		 *
		 * <pre>
		 * Inline train net params.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getTrainNetParamOrBuilder()
		{
			return trainNetParam_;
		}

		public static final int TEST_NET_PARAM_FIELD_NUMBER = 22;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter> testNetParam_;

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter> getTestNetParamList()
		{
			return testNetParam_;
		}

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>
				getTestNetParamOrBuilderList()
		{
			return testNetParam_;
		}

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		@Override
		public int getTestNetParamCount()
		{
			return testNetParam_.size();
		}

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getTestNetParam(int index)
		{
			return testNetParam_.get(index);
		}

		/**
		 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
		 *
		 * <pre>
		 * Inline test net params.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getTestNetParamOrBuilder(
				int index)
		{
			return testNetParam_.get(index);
		}

		public static final int TRAIN_STATE_FIELD_NUMBER = 26;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState trainState_;

		/**
		 * <code>optional .caffe.NetState train_state = 26;</code>
		 *
		 * <pre>
		 * The states for the train/test nets. Must be unspecified or
		 * specified once per net.
		 * By default, all states will have solver = true;
		 * train_state will have phase = TRAIN,
		 * and all test_state's will have phase = TEST.
		 * Other defaults are set according to the NetState defaults.
		 * </pre>
		 */
		@Override
		public boolean hasTrainState()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional .caffe.NetState train_state = 26;</code>
		 *
		 * <pre>
		 * The states for the train/test nets. Must be unspecified or
		 * specified once per net.
		 * By default, all states will have solver = true;
		 * train_state will have phase = TRAIN,
		 * and all test_state's will have phase = TEST.
		 * Other defaults are set according to the NetState defaults.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getTrainState()
		{
			return trainState_;
		}

		/**
		 * <code>optional .caffe.NetState train_state = 26;</code>
		 *
		 * <pre>
		 * The states for the train/test nets. Must be unspecified or
		 * specified once per net.
		 * By default, all states will have solver = true;
		 * train_state will have phase = TRAIN,
		 * and all test_state's will have phase = TEST.
		 * Other defaults are set according to the NetState defaults.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getTrainStateOrBuilder()
		{
			return trainState_;
		}

		public static final int TEST_STATE_FIELD_NUMBER = 27;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState> testState_;

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState> getTestStateList()
		{
			return testState_;
		}

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>
				getTestStateOrBuilderList()
		{
			return testState_;
		}

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		@Override
		public int getTestStateCount()
		{
			return testState_.size();
		}

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getTestState(int index)
		{
			return testState_.get(index);
		}

		/**
		 * <code>repeated .caffe.NetState test_state = 27;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getTestStateOrBuilder(
				int index)
		{
			return testState_.get(index);
		}

		public static final int TEST_ITER_FIELD_NUMBER = 3;
		private java.util.List<java.lang.Integer> testIter_;

		/**
		 * <code>repeated int32 test_iter = 3;</code>
		 *
		 * <pre>
		 * The number of iterations for each test net.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getTestIterList()
		{
			return testIter_;
		}

		/**
		 * <code>repeated int32 test_iter = 3;</code>
		 *
		 * <pre>
		 * The number of iterations for each test net.
		 * </pre>
		 */
		@Override
		public int getTestIterCount()
		{
			return testIter_.size();
		}

		/**
		 * <code>repeated int32 test_iter = 3;</code>
		 *
		 * <pre>
		 * The number of iterations for each test net.
		 * </pre>
		 */
		@Override
		public int getTestIter(int index)
		{
			return testIter_.get(index);
		}

		public static final int TEST_INTERVAL_FIELD_NUMBER = 4;
		private int testInterval_;

		/**
		 * <code>optional int32 test_interval = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The number of iterations between two testing phases.
		 * </pre>
		 */
		@Override
		public boolean hasTestInterval()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional int32 test_interval = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The number of iterations between two testing phases.
		 * </pre>
		 */
		@Override
		public int getTestInterval()
		{
			return testInterval_;
		}

		public static final int TEST_COMPUTE_LOSS_FIELD_NUMBER = 19;
		private boolean testComputeLoss_;

		/**
		 * <code>optional bool test_compute_loss = 19 [default = false];</code>
		 */
		@Override
		public boolean hasTestComputeLoss()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional bool test_compute_loss = 19 [default = false];</code>
		 */
		@Override
		public boolean getTestComputeLoss()
		{
			return testComputeLoss_;
		}

		public static final int TEST_INITIALIZATION_FIELD_NUMBER = 32;
		private boolean testInitialization_;

		/**
		 * <code>optional bool test_initialization = 32 [default = true];</code>
		 *
		 * <pre>
		 * If true, run an initial test pass before the first iteration,
		 * ensuring memory availability and printing the starting value of the loss.
		 * </pre>
		 */
		@Override
		public boolean hasTestInitialization()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional bool test_initialization = 32 [default = true];</code>
		 *
		 * <pre>
		 * If true, run an initial test pass before the first iteration,
		 * ensuring memory availability and printing the starting value of the loss.
		 * </pre>
		 */
		@Override
		public boolean getTestInitialization()
		{
			return testInitialization_;
		}

		public static final int BASE_LR_FIELD_NUMBER = 5;
		private float baseLr_;

		/**
		 * <code>optional float base_lr = 5;</code>
		 *
		 * <pre>
		 * The base learning rate
		 * </pre>
		 */
		@Override
		public boolean hasBaseLr()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional float base_lr = 5;</code>
		 *
		 * <pre>
		 * The base learning rate
		 * </pre>
		 */
		@Override
		public float getBaseLr()
		{
			return baseLr_;
		}

		public static final int DISPLAY_FIELD_NUMBER = 6;
		private int display_;

		/**
		 * <code>optional int32 display = 6;</code>
		 *
		 * <pre>
		 * the number of iterations between displaying info. If display = 0, no info
		 * will be displayed.
		 * </pre>
		 */
		@Override
		public boolean hasDisplay()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional int32 display = 6;</code>
		 *
		 * <pre>
		 * the number of iterations between displaying info. If display = 0, no info
		 * will be displayed.
		 * </pre>
		 */
		@Override
		public int getDisplay()
		{
			return display_;
		}

		public static final int AVERAGE_LOSS_FIELD_NUMBER = 33;
		private int averageLoss_;

		/**
		 * <code>optional int32 average_loss = 33 [default = 1];</code>
		 *
		 * <pre>
		 * Display the cost averaged over the last average_cost iterations
		 * </pre>
		 */
		@Override
		public boolean hasAverageLoss()
		{
			return ((bitField0_ & 0x00000400) == 0x00000400);
		}

		/**
		 * <code>optional int32 average_loss = 33 [default = 1];</code>
		 *
		 * <pre>
		 * Display the cost averaged over the last average_cost iterations
		 * </pre>
		 */
		@Override
		public int getAverageLoss()
		{
			return averageLoss_;
		}

		public static final int MAX_ITER_FIELD_NUMBER = 7;
		private int maxIter_;

		/**
		 * <code>optional int32 max_iter = 7;</code>
		 *
		 * <pre>
		 * the maximum number of iterations
		 * </pre>
		 */
		@Override
		public boolean hasMaxIter()
		{
			return ((bitField0_ & 0x00000800) == 0x00000800);
		}

		/**
		 * <code>optional int32 max_iter = 7;</code>
		 *
		 * <pre>
		 * the maximum number of iterations
		 * </pre>
		 */
		@Override
		public int getMaxIter()
		{
			return maxIter_;
		}

		public static final int LR_POLICY_FIELD_NUMBER = 8;
		private java.lang.Object lrPolicy_;

		/**
		 * <code>optional string lr_policy = 8;</code>
		 *
		 * <pre>
		 * The learning rate decay policy.
		 * </pre>
		 */
		@Override
		public boolean hasLrPolicy()
		{
			return ((bitField0_ & 0x00001000) == 0x00001000);
		}

		/**
		 * <code>optional string lr_policy = 8;</code>
		 *
		 * <pre>
		 * The learning rate decay policy.
		 * </pre>
		 */
		@Override
		public java.lang.String getLrPolicy()
		{
			java.lang.Object ref = lrPolicy_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					lrPolicy_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string lr_policy = 8;</code>
		 *
		 * <pre>
		 * The learning rate decay policy.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getLrPolicyBytes()
		{
			java.lang.Object ref = lrPolicy_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				lrPolicy_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int GAMMA_FIELD_NUMBER = 9;
		private float gamma_;

		/**
		 * <code>optional float gamma = 9;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		@Override
		public boolean hasGamma()
		{
			return ((bitField0_ & 0x00002000) == 0x00002000);
		}

		/**
		 * <code>optional float gamma = 9;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		@Override
		public float getGamma()
		{
			return gamma_;
		}

		public static final int POWER_FIELD_NUMBER = 10;
		private float power_;

		/**
		 * <code>optional float power = 10;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		@Override
		public boolean hasPower()
		{
			return ((bitField0_ & 0x00004000) == 0x00004000);
		}

		/**
		 * <code>optional float power = 10;</code>
		 *
		 * <pre>
		 * The parameter to compute the learning rate.
		 * </pre>
		 */
		@Override
		public float getPower()
		{
			return power_;
		}

		public static final int MOMENTUM_FIELD_NUMBER = 11;
		private float momentum_;

		/**
		 * <code>optional float momentum = 11;</code>
		 *
		 * <pre>
		 * The momentum value.
		 * </pre>
		 */
		@Override
		public boolean hasMomentum()
		{
			return ((bitField0_ & 0x00008000) == 0x00008000);
		}

		/**
		 * <code>optional float momentum = 11;</code>
		 *
		 * <pre>
		 * The momentum value.
		 * </pre>
		 */
		@Override
		public float getMomentum()
		{
			return momentum_;
		}

		public static final int WEIGHT_DECAY_FIELD_NUMBER = 12;
		private float weightDecay_;

		/**
		 * <code>optional float weight_decay = 12;</code>
		 *
		 * <pre>
		 * The weight decay.
		 * </pre>
		 */
		@Override
		public boolean hasWeightDecay()
		{
			return ((bitField0_ & 0x00010000) == 0x00010000);
		}

		/**
		 * <code>optional float weight_decay = 12;</code>
		 *
		 * <pre>
		 * The weight decay.
		 * </pre>
		 */
		@Override
		public float getWeightDecay()
		{
			return weightDecay_;
		}

		public static final int REGULARIZATION_TYPE_FIELD_NUMBER = 29;
		private java.lang.Object regularizationType_;

		/**
		 * <code>optional string regularization_type = 29 [default = "L2"];</code>
		 *
		 * <pre>
		 * regularization types supported: L1 and L2
		 * controlled by weight_decay
		 * </pre>
		 */
		@Override
		public boolean hasRegularizationType()
		{
			return ((bitField0_ & 0x00020000) == 0x00020000);
		}

		/**
		 * <code>optional string regularization_type = 29 [default = "L2"];</code>
		 *
		 * <pre>
		 * regularization types supported: L1 and L2
		 * controlled by weight_decay
		 * </pre>
		 */
		@Override
		public java.lang.String getRegularizationType()
		{
			java.lang.Object ref = regularizationType_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					regularizationType_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string regularization_type = 29 [default = "L2"];</code>
		 *
		 * <pre>
		 * regularization types supported: L1 and L2
		 * controlled by weight_decay
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getRegularizationTypeBytes()
		{
			java.lang.Object ref = regularizationType_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				regularizationType_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int STEPSIZE_FIELD_NUMBER = 13;
		private int stepsize_;

		/**
		 * <code>optional int32 stepsize = 13;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "step"
		 * </pre>
		 */
		@Override
		public boolean hasStepsize()
		{
			return ((bitField0_ & 0x00040000) == 0x00040000);
		}

		/**
		 * <code>optional int32 stepsize = 13;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "step"
		 * </pre>
		 */
		@Override
		public int getStepsize()
		{
			return stepsize_;
		}

		public static final int STEPVALUE_FIELD_NUMBER = 34;
		private java.util.List<java.lang.Integer> stepvalue_;

		/**
		 * <code>repeated int32 stepvalue = 34;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "multistep"
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getStepvalueList()
		{
			return stepvalue_;
		}

		/**
		 * <code>repeated int32 stepvalue = 34;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "multistep"
		 * </pre>
		 */
		@Override
		public int getStepvalueCount()
		{
			return stepvalue_.size();
		}

		/**
		 * <code>repeated int32 stepvalue = 34;</code>
		 *
		 * <pre>
		 * the stepsize for learning rate policy "multistep"
		 * </pre>
		 */
		@Override
		public int getStepvalue(int index)
		{
			return stepvalue_.get(index);
		}

		public static final int SNAPSHOT_FIELD_NUMBER = 14;
		private int snapshot_;

		/**
		 * <code>optional int32 snapshot = 14 [default = 0];</code>
		 *
		 * <pre>
		 * The snapshot interval
		 * </pre>
		 */
		@Override
		public boolean hasSnapshot()
		{
			return ((bitField0_ & 0x00080000) == 0x00080000);
		}

		/**
		 * <code>optional int32 snapshot = 14 [default = 0];</code>
		 *
		 * <pre>
		 * The snapshot interval
		 * </pre>
		 */
		@Override
		public int getSnapshot()
		{
			return snapshot_;
		}

		public static final int SNAPSHOT_PREFIX_FIELD_NUMBER = 15;
		private java.lang.Object snapshotPrefix_;

		/**
		 * <code>optional string snapshot_prefix = 15;</code>
		 *
		 * <pre>
		 * The prefix for the snapshot.
		 * </pre>
		 */
		@Override
		public boolean hasSnapshotPrefix()
		{
			return ((bitField0_ & 0x00100000) == 0x00100000);
		}

		/**
		 * <code>optional string snapshot_prefix = 15;</code>
		 *
		 * <pre>
		 * The prefix for the snapshot.
		 * </pre>
		 */
		@Override
		public java.lang.String getSnapshotPrefix()
		{
			java.lang.Object ref = snapshotPrefix_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					snapshotPrefix_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string snapshot_prefix = 15;</code>
		 *
		 * <pre>
		 * The prefix for the snapshot.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSnapshotPrefixBytes()
		{
			java.lang.Object ref = snapshotPrefix_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				snapshotPrefix_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int SNAPSHOT_DIFF_FIELD_NUMBER = 16;
		private boolean snapshotDiff_;

		/**
		 * <code>optional bool snapshot_diff = 16 [default = false];</code>
		 *
		 * <pre>
		 * whether to snapshot diff in the results or not. Snapshotting diff will help
		 * debugging but the final protocol buffer size will be much larger.
		 * </pre>
		 */
		@Override
		public boolean hasSnapshotDiff()
		{
			return ((bitField0_ & 0x00200000) == 0x00200000);
		}

		/**
		 * <code>optional bool snapshot_diff = 16 [default = false];</code>
		 *
		 * <pre>
		 * whether to snapshot diff in the results or not. Snapshotting diff will help
		 * debugging but the final protocol buffer size will be much larger.
		 * </pre>
		 */
		@Override
		public boolean getSnapshotDiff()
		{
			return snapshotDiff_;
		}

		public static final int SOLVER_MODE_FIELD_NUMBER = 17;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode solverMode_;

		/**
		 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
		 */
		@Override
		public boolean hasSolverMode()
		{
			return ((bitField0_ & 0x00400000) == 0x00400000);
		}

		/**
		 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode getSolverMode()
		{
			return solverMode_;
		}

		public static final int DEVICE_ID_FIELD_NUMBER = 18;
		private int deviceId_;

		/**
		 * <code>optional int32 device_id = 18 [default = 0];</code>
		 *
		 * <pre>
		 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
		 * </pre>
		 */
		@Override
		public boolean hasDeviceId()
		{
			return ((bitField0_ & 0x00800000) == 0x00800000);
		}

		/**
		 * <code>optional int32 device_id = 18 [default = 0];</code>
		 *
		 * <pre>
		 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
		 * </pre>
		 */
		@Override
		public int getDeviceId()
		{
			return deviceId_;
		}

		public static final int RANDOM_SEED_FIELD_NUMBER = 20;
		private long randomSeed_;

		/**
		 * <code>optional int64 random_seed = 20 [default = -1];</code>
		 *
		 * <pre>
		 * If non-negative, the seed with which the Solver will initialize the Caffe
		 * random number generator -- useful for reproducible results. Otherwise,
		 * (and by default) initialize using a seed derived from the system clock.
		 * </pre>
		 */
		@Override
		public boolean hasRandomSeed()
		{
			return ((bitField0_ & 0x01000000) == 0x01000000);
		}

		/**
		 * <code>optional int64 random_seed = 20 [default = -1];</code>
		 *
		 * <pre>
		 * If non-negative, the seed with which the Solver will initialize the Caffe
		 * random number generator -- useful for reproducible results. Otherwise,
		 * (and by default) initialize using a seed derived from the system clock.
		 * </pre>
		 */
		@Override
		public long getRandomSeed()
		{
			return randomSeed_;
		}

		public static final int SOLVER_TYPE_FIELD_NUMBER = 30;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType solverType_;

		/**
		 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
		 */
		@Override
		public boolean hasSolverType()
		{
			return ((bitField0_ & 0x02000000) == 0x02000000);
		}

		/**
		 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType getSolverType()
		{
			return solverType_;
		}

		public static final int DELTA_FIELD_NUMBER = 31;
		private float delta_;

		/**
		 * <code>optional float delta = 31 [default = 1e-008];</code>
		 *
		 * <pre>
		 * numerical stability for AdaGrad
		 * </pre>
		 */
		@Override
		public boolean hasDelta()
		{
			return ((bitField0_ & 0x04000000) == 0x04000000);
		}

		/**
		 * <code>optional float delta = 31 [default = 1e-008];</code>
		 *
		 * <pre>
		 * numerical stability for AdaGrad
		 * </pre>
		 */
		@Override
		public float getDelta()
		{
			return delta_;
		}

		public static final int DEBUG_INFO_FIELD_NUMBER = 23;
		private boolean debugInfo_;

		/**
		 * <code>optional bool debug_info = 23 [default = false];</code>
		 *
		 * <pre>
		 * If true, print information about the state of the net that may help with
		 * debugging learning problems.
		 * </pre>
		 */
		@Override
		public boolean hasDebugInfo()
		{
			return ((bitField0_ & 0x08000000) == 0x08000000);
		}

		/**
		 * <code>optional bool debug_info = 23 [default = false];</code>
		 *
		 * <pre>
		 * If true, print information about the state of the net that may help with
		 * debugging learning problems.
		 * </pre>
		 */
		@Override
		public boolean getDebugInfo()
		{
			return debugInfo_;
		}

		public static final int SNAPSHOT_AFTER_TRAIN_FIELD_NUMBER = 28;
		private boolean snapshotAfterTrain_;

		/**
		 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
		 *
		 * <pre>
		 * If false, don't save a snapshot after training finishes.
		 * </pre>
		 */
		@Override
		public boolean hasSnapshotAfterTrain()
		{
			return ((bitField0_ & 0x10000000) == 0x10000000);
		}

		/**
		 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
		 *
		 * <pre>
		 * If false, don't save a snapshot after training finishes.
		 * </pre>
		 */
		@Override
		public boolean getSnapshotAfterTrain()
		{
			return snapshotAfterTrain_;
		}

		private void initFields()
		{
			net_ = "";
			netParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
			trainNet_ = "";
			testNet_ = com.google.protobuf.LazyStringArrayList.EMPTY;
			trainNetParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
			testNetParam_ = java.util.Collections.emptyList();
			trainState_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
			testState_ = java.util.Collections.emptyList();
			testIter_ = java.util.Collections.emptyList();
			testInterval_ = 0;
			testComputeLoss_ = false;
			testInitialization_ = true;
			baseLr_ = 0F;
			display_ = 0;
			averageLoss_ = 1;
			maxIter_ = 0;
			lrPolicy_ = "";
			gamma_ = 0F;
			power_ = 0F;
			momentum_ = 0F;
			weightDecay_ = 0F;
			regularizationType_ = "L2";
			stepsize_ = 0;
			stepvalue_ = java.util.Collections.emptyList();
			snapshot_ = 0;
			snapshotPrefix_ = "";
			snapshotDiff_ = false;
			solverMode_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode.GPU;
			deviceId_ = 0;
			randomSeed_ = -1L;
			solverType_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType.SGD;
			delta_ = 1e-008F;
			debugInfo_ = false;
			snapshotAfterTrain_ = true;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeBytes(1, getTrainNetBytes());
			}
			for (int i = 0; i < testNet_.size(); i++)
			{
				output.writeBytes(2, testNet_.getByteString(i));
			}
			for (int i = 0; i < testIter_.size(); i++)
			{
				output.writeInt32(3, testIter_.get(i));
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeInt32(4, testInterval_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeFloat(5, baseLr_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeInt32(6, display_);
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				output.writeInt32(7, maxIter_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				output.writeBytes(8, getLrPolicyBytes());
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				output.writeFloat(9, gamma_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				output.writeFloat(10, power_);
			}
			if (((bitField0_ & 0x00008000) == 0x00008000))
			{
				output.writeFloat(11, momentum_);
			}
			if (((bitField0_ & 0x00010000) == 0x00010000))
			{
				output.writeFloat(12, weightDecay_);
			}
			if (((bitField0_ & 0x00040000) == 0x00040000))
			{
				output.writeInt32(13, stepsize_);
			}
			if (((bitField0_ & 0x00080000) == 0x00080000))
			{
				output.writeInt32(14, snapshot_);
			}
			if (((bitField0_ & 0x00100000) == 0x00100000))
			{
				output.writeBytes(15, getSnapshotPrefixBytes());
			}
			if (((bitField0_ & 0x00200000) == 0x00200000))
			{
				output.writeBool(16, snapshotDiff_);
			}
			if (((bitField0_ & 0x00400000) == 0x00400000))
			{
				output.writeEnum(17, solverMode_.getNumber());
			}
			if (((bitField0_ & 0x00800000) == 0x00800000))
			{
				output.writeInt32(18, deviceId_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeBool(19, testComputeLoss_);
			}
			if (((bitField0_ & 0x01000000) == 0x01000000))
			{
				output.writeInt64(20, randomSeed_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeMessage(21, trainNetParam_);
			}
			for (int i = 0; i < testNetParam_.size(); i++)
			{
				output.writeMessage(22, testNetParam_.get(i));
			}
			if (((bitField0_ & 0x08000000) == 0x08000000))
			{
				output.writeBool(23, debugInfo_);
			}
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(24, getNetBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeMessage(25, netParam_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeMessage(26, trainState_);
			}
			for (int i = 0; i < testState_.size(); i++)
			{
				output.writeMessage(27, testState_.get(i));
			}
			if (((bitField0_ & 0x10000000) == 0x10000000))
			{
				output.writeBool(28, snapshotAfterTrain_);
			}
			if (((bitField0_ & 0x00020000) == 0x00020000))
			{
				output.writeBytes(29, getRegularizationTypeBytes());
			}
			if (((bitField0_ & 0x02000000) == 0x02000000))
			{
				output.writeEnum(30, solverType_.getNumber());
			}
			if (((bitField0_ & 0x04000000) == 0x04000000))
			{
				output.writeFloat(31, delta_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeBool(32, testInitialization_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				output.writeInt32(33, averageLoss_);
			}
			for (int i = 0; i < stepvalue_.size(); i++)
			{
				output.writeInt32(34, stepvalue_.get(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getTrainNetBytes());
			}
			{
				int dataSize = 0;
				for (int i = 0; i < testNet_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(testNet_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getTestNetList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < testIter_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeInt32SizeNoTag(testIter_.get(i));
				}
				size += dataSize;
				size += 1 * getTestIterList().size();
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(4, testInterval_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(5, baseLr_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(6, display_);
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(7, maxIter_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(8, getLrPolicyBytes());
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(9, gamma_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(10, power_);
			}
			if (((bitField0_ & 0x00008000) == 0x00008000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(11, momentum_);
			}
			if (((bitField0_ & 0x00010000) == 0x00010000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(12, weightDecay_);
			}
			if (((bitField0_ & 0x00040000) == 0x00040000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(13, stepsize_);
			}
			if (((bitField0_ & 0x00080000) == 0x00080000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(14, snapshot_);
			}
			if (((bitField0_ & 0x00100000) == 0x00100000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(15, getSnapshotPrefixBytes());
			}
			if (((bitField0_ & 0x00200000) == 0x00200000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(16, snapshotDiff_);
			}
			if (((bitField0_ & 0x00400000) == 0x00400000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(17, solverMode_.getNumber());
			}
			if (((bitField0_ & 0x00800000) == 0x00800000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(18, deviceId_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(19, testComputeLoss_);
			}
			if (((bitField0_ & 0x01000000) == 0x01000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt64Size(20, randomSeed_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(21, trainNetParam_);
			}
			for (int i = 0; i < testNetParam_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(22, testNetParam_.get(i));
			}
			if (((bitField0_ & 0x08000000) == 0x08000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(23, debugInfo_);
			}
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(24, getNetBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(25, netParam_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(26, trainState_);
			}
			for (int i = 0; i < testState_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(27, testState_.get(i));
			}
			if (((bitField0_ & 0x10000000) == 0x10000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(28, snapshotAfterTrain_);
			}
			if (((bitField0_ & 0x00020000) == 0x00020000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(29, getRegularizationTypeBytes());
			}
			if (((bitField0_ & 0x02000000) == 0x02000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(30, solverType_.getNumber());
			}
			if (((bitField0_ & 0x04000000) == 0x04000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(31, delta_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(32, testInitialization_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(33, averageLoss_);
			}
			{
				int dataSize = 0;
				for (int i = 0; i < stepvalue_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeInt32SizeNoTag(stepvalue_.get(i));
				}
				size += dataSize;
				size += 2 * getStepvalueList().size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.SolverParameter}
		 *
		 * <pre>
		 * NOTE
		 * Update the next available ID when you add a new SolverParameter field.
		 * SolverParameter next available ID: 35 (last added: stepvalue)
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.SolverParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getNetParamFieldBuilder();
					getTrainNetParamFieldBuilder();
					getTestNetParamFieldBuilder();
					getTrainStateFieldBuilder();
					getTestStateFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				net_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				if (netParamBuilder_ == null)
				{
					netParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
				} else
				{
					netParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000002);
				trainNet_ = "";
				bitField0_ = (bitField0_ & ~0x00000004);
				testNet_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000008);
				if (trainNetParamBuilder_ == null)
				{
					trainNetParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
				} else
				{
					trainNetParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000010);
				if (testNetParamBuilder_ == null)
				{
					testNetParam_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000020);
				} else
				{
					testNetParamBuilder_.clear();
				}
				if (trainStateBuilder_ == null)
				{
					trainState_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
				} else
				{
					trainStateBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000040);
				if (testStateBuilder_ == null)
				{
					testState_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000080);
				} else
				{
					testStateBuilder_.clear();
				}
				testIter_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000100);
				testInterval_ = 0;
				bitField0_ = (bitField0_ & ~0x00000200);
				testComputeLoss_ = false;
				bitField0_ = (bitField0_ & ~0x00000400);
				testInitialization_ = true;
				bitField0_ = (bitField0_ & ~0x00000800);
				baseLr_ = 0F;
				bitField0_ = (bitField0_ & ~0x00001000);
				display_ = 0;
				bitField0_ = (bitField0_ & ~0x00002000);
				averageLoss_ = 1;
				bitField0_ = (bitField0_ & ~0x00004000);
				maxIter_ = 0;
				bitField0_ = (bitField0_ & ~0x00008000);
				lrPolicy_ = "";
				bitField0_ = (bitField0_ & ~0x00010000);
				gamma_ = 0F;
				bitField0_ = (bitField0_ & ~0x00020000);
				power_ = 0F;
				bitField0_ = (bitField0_ & ~0x00040000);
				momentum_ = 0F;
				bitField0_ = (bitField0_ & ~0x00080000);
				weightDecay_ = 0F;
				bitField0_ = (bitField0_ & ~0x00100000);
				regularizationType_ = "L2";
				bitField0_ = (bitField0_ & ~0x00200000);
				stepsize_ = 0;
				bitField0_ = (bitField0_ & ~0x00400000);
				stepvalue_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00800000);
				snapshot_ = 0;
				bitField0_ = (bitField0_ & ~0x01000000);
				snapshotPrefix_ = "";
				bitField0_ = (bitField0_ & ~0x02000000);
				snapshotDiff_ = false;
				bitField0_ = (bitField0_ & ~0x04000000);
				solverMode_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode.GPU;
				bitField0_ = (bitField0_ & ~0x08000000);
				deviceId_ = 0;
				bitField0_ = (bitField0_ & ~0x10000000);
				randomSeed_ = -1L;
				bitField0_ = (bitField0_ & ~0x20000000);
				solverType_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType.SGD;
				bitField0_ = (bitField0_ & ~0x40000000);
				delta_ = 1e-008F;
				bitField0_ = (bitField0_ & ~0x80000000);
				debugInfo_ = false;
				bitField1_ = (bitField1_ & ~0x00000001);
				snapshotAfterTrain_ = true;
				bitField1_ = (bitField1_ & ~0x00000002);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter(this);
				int from_bitField0_ = bitField0_;
				int from_bitField1_ = bitField1_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.net_ = net_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				if (netParamBuilder_ == null)
				{
					result.netParam_ = netParam_;
				} else
				{
					result.netParam_ = netParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.trainNet_ = trainNet_;
				if (((bitField0_ & 0x00000008) == 0x00000008))
				{
					testNet_ = testNet_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000008);
				}
				result.testNet_ = testNet_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000008;
				}
				if (trainNetParamBuilder_ == null)
				{
					result.trainNetParam_ = trainNetParam_;
				} else
				{
					result.trainNetParam_ = trainNetParamBuilder_.build();
				}
				if (testNetParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00000020) == 0x00000020))
					{
						testNetParam_ = java.util.Collections.unmodifiableList(testNetParam_);
						bitField0_ = (bitField0_ & ~0x00000020);
					}
					result.testNetParam_ = testNetParam_;
				} else
				{
					result.testNetParam_ = testNetParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000010;
				}
				if (trainStateBuilder_ == null)
				{
					result.trainState_ = trainState_;
				} else
				{
					result.trainState_ = trainStateBuilder_.build();
				}
				if (testStateBuilder_ == null)
				{
					if (((bitField0_ & 0x00000080) == 0x00000080))
					{
						testState_ = java.util.Collections.unmodifiableList(testState_);
						bitField0_ = (bitField0_ & ~0x00000080);
					}
					result.testState_ = testState_;
				} else
				{
					result.testState_ = testStateBuilder_.build();
				}
				if (((bitField0_ & 0x00000100) == 0x00000100))
				{
					testIter_ = java.util.Collections.unmodifiableList(testIter_);
					bitField0_ = (bitField0_ & ~0x00000100);
				}
				result.testIter_ = testIter_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.testInterval_ = testInterval_;
				if (((from_bitField0_ & 0x00000400) == 0x00000400))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.testComputeLoss_ = testComputeLoss_;
				if (((from_bitField0_ & 0x00000800) == 0x00000800))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.testInitialization_ = testInitialization_;
				if (((from_bitField0_ & 0x00001000) == 0x00001000))
				{
					to_bitField0_ |= 0x00000100;
				}
				result.baseLr_ = baseLr_;
				if (((from_bitField0_ & 0x00002000) == 0x00002000))
				{
					to_bitField0_ |= 0x00000200;
				}
				result.display_ = display_;
				if (((from_bitField0_ & 0x00004000) == 0x00004000))
				{
					to_bitField0_ |= 0x00000400;
				}
				result.averageLoss_ = averageLoss_;
				if (((from_bitField0_ & 0x00008000) == 0x00008000))
				{
					to_bitField0_ |= 0x00000800;
				}
				result.maxIter_ = maxIter_;
				if (((from_bitField0_ & 0x00010000) == 0x00010000))
				{
					to_bitField0_ |= 0x00001000;
				}
				result.lrPolicy_ = lrPolicy_;
				if (((from_bitField0_ & 0x00020000) == 0x00020000))
				{
					to_bitField0_ |= 0x00002000;
				}
				result.gamma_ = gamma_;
				if (((from_bitField0_ & 0x00040000) == 0x00040000))
				{
					to_bitField0_ |= 0x00004000;
				}
				result.power_ = power_;
				if (((from_bitField0_ & 0x00080000) == 0x00080000))
				{
					to_bitField0_ |= 0x00008000;
				}
				result.momentum_ = momentum_;
				if (((from_bitField0_ & 0x00100000) == 0x00100000))
				{
					to_bitField0_ |= 0x00010000;
				}
				result.weightDecay_ = weightDecay_;
				if (((from_bitField0_ & 0x00200000) == 0x00200000))
				{
					to_bitField0_ |= 0x00020000;
				}
				result.regularizationType_ = regularizationType_;
				if (((from_bitField0_ & 0x00400000) == 0x00400000))
				{
					to_bitField0_ |= 0x00040000;
				}
				result.stepsize_ = stepsize_;
				if (((bitField0_ & 0x00800000) == 0x00800000))
				{
					stepvalue_ = java.util.Collections.unmodifiableList(stepvalue_);
					bitField0_ = (bitField0_ & ~0x00800000);
				}
				result.stepvalue_ = stepvalue_;
				if (((from_bitField0_ & 0x01000000) == 0x01000000))
				{
					to_bitField0_ |= 0x00080000;
				}
				result.snapshot_ = snapshot_;
				if (((from_bitField0_ & 0x02000000) == 0x02000000))
				{
					to_bitField0_ |= 0x00100000;
				}
				result.snapshotPrefix_ = snapshotPrefix_;
				if (((from_bitField0_ & 0x04000000) == 0x04000000))
				{
					to_bitField0_ |= 0x00200000;
				}
				result.snapshotDiff_ = snapshotDiff_;
				if (((from_bitField0_ & 0x08000000) == 0x08000000))
				{
					to_bitField0_ |= 0x00400000;
				}
				result.solverMode_ = solverMode_;
				if (((from_bitField0_ & 0x10000000) == 0x10000000))
				{
					to_bitField0_ |= 0x00800000;
				}
				result.deviceId_ = deviceId_;
				if (((from_bitField0_ & 0x20000000) == 0x20000000))
				{
					to_bitField0_ |= 0x01000000;
				}
				result.randomSeed_ = randomSeed_;
				if (((from_bitField0_ & 0x40000000) == 0x40000000))
				{
					to_bitField0_ |= 0x02000000;
				}
				result.solverType_ = solverType_;
				if (((from_bitField0_ & 0x80000000) == 0x80000000))
				{
					to_bitField0_ |= 0x04000000;
				}
				result.delta_ = delta_;
				if (((from_bitField1_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x08000000;
				}
				result.debugInfo_ = debugInfo_;
				if (((from_bitField1_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x10000000;
				}
				result.snapshotAfterTrain_ = snapshotAfterTrain_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.getDefaultInstance())
					return this;
				if (other.hasNet())
				{
					bitField0_ |= 0x00000001;
					net_ = other.net_;
					onChanged();
				}
				if (other.hasNetParam())
				{
					mergeNetParam(other.getNetParam());
				}
				if (other.hasTrainNet())
				{
					bitField0_ |= 0x00000004;
					trainNet_ = other.trainNet_;
					onChanged();
				}
				if (!other.testNet_.isEmpty())
				{
					if (testNet_.isEmpty())
					{
						testNet_ = other.testNet_;
						bitField0_ = (bitField0_ & ~0x00000008);
					} else
					{
						ensureTestNetIsMutable();
						testNet_.addAll(other.testNet_);
					}
					onChanged();
				}
				if (other.hasTrainNetParam())
				{
					mergeTrainNetParam(other.getTrainNetParam());
				}
				if (testNetParamBuilder_ == null)
				{
					if (!other.testNetParam_.isEmpty())
					{
						if (testNetParam_.isEmpty())
						{
							testNetParam_ = other.testNetParam_;
							bitField0_ = (bitField0_ & ~0x00000020);
						} else
						{
							ensureTestNetParamIsMutable();
							testNetParam_.addAll(other.testNetParam_);
						}
						onChanged();
					}
				} else
				{
					if (!other.testNetParam_.isEmpty())
					{
						if (testNetParamBuilder_.isEmpty())
						{
							testNetParamBuilder_.dispose();
							testNetParamBuilder_ = null;
							testNetParam_ = other.testNetParam_;
							bitField0_ = (bitField0_ & ~0x00000020);
							testNetParamBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getTestNetParamFieldBuilder() : null;
						} else
						{
							testNetParamBuilder_.addAllMessages(other.testNetParam_);
						}
					}
				}
				if (other.hasTrainState())
				{
					mergeTrainState(other.getTrainState());
				}
				if (testStateBuilder_ == null)
				{
					if (!other.testState_.isEmpty())
					{
						if (testState_.isEmpty())
						{
							testState_ = other.testState_;
							bitField0_ = (bitField0_ & ~0x00000080);
						} else
						{
							ensureTestStateIsMutable();
							testState_.addAll(other.testState_);
						}
						onChanged();
					}
				} else
				{
					if (!other.testState_.isEmpty())
					{
						if (testStateBuilder_.isEmpty())
						{
							testStateBuilder_.dispose();
							testStateBuilder_ = null;
							testState_ = other.testState_;
							bitField0_ = (bitField0_ & ~0x00000080);
							testStateBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getTestStateFieldBuilder() : null;
						} else
						{
							testStateBuilder_.addAllMessages(other.testState_);
						}
					}
				}
				if (!other.testIter_.isEmpty())
				{
					if (testIter_.isEmpty())
					{
						testIter_ = other.testIter_;
						bitField0_ = (bitField0_ & ~0x00000100);
					} else
					{
						ensureTestIterIsMutable();
						testIter_.addAll(other.testIter_);
					}
					onChanged();
				}
				if (other.hasTestInterval())
				{
					setTestInterval(other.getTestInterval());
				}
				if (other.hasTestComputeLoss())
				{
					setTestComputeLoss(other.getTestComputeLoss());
				}
				if (other.hasTestInitialization())
				{
					setTestInitialization(other.getTestInitialization());
				}
				if (other.hasBaseLr())
				{
					setBaseLr(other.getBaseLr());
				}
				if (other.hasDisplay())
				{
					setDisplay(other.getDisplay());
				}
				if (other.hasAverageLoss())
				{
					setAverageLoss(other.getAverageLoss());
				}
				if (other.hasMaxIter())
				{
					setMaxIter(other.getMaxIter());
				}
				if (other.hasLrPolicy())
				{
					bitField0_ |= 0x00010000;
					lrPolicy_ = other.lrPolicy_;
					onChanged();
				}
				if (other.hasGamma())
				{
					setGamma(other.getGamma());
				}
				if (other.hasPower())
				{
					setPower(other.getPower());
				}
				if (other.hasMomentum())
				{
					setMomentum(other.getMomentum());
				}
				if (other.hasWeightDecay())
				{
					setWeightDecay(other.getWeightDecay());
				}
				if (other.hasRegularizationType())
				{
					bitField0_ |= 0x00200000;
					regularizationType_ = other.regularizationType_;
					onChanged();
				}
				if (other.hasStepsize())
				{
					setStepsize(other.getStepsize());
				}
				if (!other.stepvalue_.isEmpty())
				{
					if (stepvalue_.isEmpty())
					{
						stepvalue_ = other.stepvalue_;
						bitField0_ = (bitField0_ & ~0x00800000);
					} else
					{
						ensureStepvalueIsMutable();
						stepvalue_.addAll(other.stepvalue_);
					}
					onChanged();
				}
				if (other.hasSnapshot())
				{
					setSnapshot(other.getSnapshot());
				}
				if (other.hasSnapshotPrefix())
				{
					bitField0_ |= 0x02000000;
					snapshotPrefix_ = other.snapshotPrefix_;
					onChanged();
				}
				if (other.hasSnapshotDiff())
				{
					setSnapshotDiff(other.getSnapshotDiff());
				}
				if (other.hasSolverMode())
				{
					setSolverMode(other.getSolverMode());
				}
				if (other.hasDeviceId())
				{
					setDeviceId(other.getDeviceId());
				}
				if (other.hasRandomSeed())
				{
					setRandomSeed(other.getRandomSeed());
				}
				if (other.hasSolverType())
				{
					setSolverType(other.getSolverType());
				}
				if (other.hasDelta())
				{
					setDelta(other.getDelta());
				}
				if (other.hasDebugInfo())
				{
					setDebugInfo(other.getDebugInfo());
				}
				if (other.hasSnapshotAfterTrain())
				{
					setSnapshotAfterTrain(other.getSnapshotAfterTrain());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;
			private int bitField1_;

			private java.lang.Object net_ = "";

			/**
			 * <code>optional string net = 24;</code>
			 *
			 * <pre>
			 * Proto filename for the train net, possibly combined with one or more
			 * test nets.
			 * </pre>
			 */
			@Override
			public boolean hasNet()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string net = 24;</code>
			 *
			 * <pre>
			 * Proto filename for the train net, possibly combined with one or more
			 * test nets.
			 * </pre>
			 */
			@Override
			public java.lang.String getNet()
			{
				java.lang.Object ref = net_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						net_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string net = 24;</code>
			 *
			 * <pre>
			 * Proto filename for the train net, possibly combined with one or more
			 * test nets.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getNetBytes()
			{
				java.lang.Object ref = net_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					net_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string net = 24;</code>
			 *
			 * <pre>
			 * Proto filename for the train net, possibly combined with one or more
			 * test nets.
			 * </pre>
			 */
			public Builder setNet(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				net_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string net = 24;</code>
			 *
			 * <pre>
			 * Proto filename for the train net, possibly combined with one or more
			 * test nets.
			 * </pre>
			 */
			public Builder clearNet()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				net_ = getDefaultInstance().getNet();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string net = 24;</code>
			 *
			 * <pre>
			 * Proto filename for the train net, possibly combined with one or more
			 * test nets.
			 * </pre>
			 */
			public Builder setNetBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				net_ = value;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter netParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder> netParamBuilder_;

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			@Override
			public boolean hasNetParam()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getNetParam()
			{
				if (netParamBuilder_ == null)
				{
					return netParam_;
				} else
				{
					return netParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			public Builder setNetParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (netParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					netParam_ = value;
					onChanged();
				} else
				{
					netParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000002;
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			public Builder setNetParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder builderForValue)
			{
				if (netParamBuilder_ == null)
				{
					netParam_ = builderForValue.build();
					onChanged();
				} else
				{
					netParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000002;
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			public Builder mergeNetParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (netParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00000002) == 0x00000002) &&
							netParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance())
					{
						netParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.newBuilder(netParam_).mergeFrom(value).buildPartial();
					} else
					{
						netParam_ = value;
					}
					onChanged();
				} else
				{
					netParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000002;
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			public Builder clearNetParam()
			{
				if (netParamBuilder_ == null)
				{
					netParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
					onChanged();
				} else
				{
					netParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder getNetParamBuilder()
			{
				bitField0_ |= 0x00000002;
				onChanged();
				return getNetParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getNetParamOrBuilder()
			{
				if (netParamBuilder_ != null)
				{
					return netParamBuilder_.getMessageOrBuilder();
				} else
				{
					return netParam_;
				}
			}

			/**
			 * <code>optional .caffe.NetParameter net_param = 25;</code>
			 *
			 * <pre>
			 * Inline train net param, possibly combined with one or more test nets.
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>
					getNetParamFieldBuilder()
			{
				if (netParamBuilder_ == null)
				{
					netParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>(
									getNetParam(),
									getParentForChildren(),
									isClean());
					netParam_ = null;
				}
				return netParamBuilder_;
			}

			private java.lang.Object trainNet_ = "";

			/**
			 * <code>optional string train_net = 1;</code>
			 *
			 * <pre>
			 * Proto filename for the train net.
			 * </pre>
			 */
			@Override
			public boolean hasTrainNet()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional string train_net = 1;</code>
			 *
			 * <pre>
			 * Proto filename for the train net.
			 * </pre>
			 */
			@Override
			public java.lang.String getTrainNet()
			{
				java.lang.Object ref = trainNet_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						trainNet_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string train_net = 1;</code>
			 *
			 * <pre>
			 * Proto filename for the train net.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getTrainNetBytes()
			{
				java.lang.Object ref = trainNet_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					trainNet_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string train_net = 1;</code>
			 *
			 * <pre>
			 * Proto filename for the train net.
			 * </pre>
			 */
			public Builder setTrainNet(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				trainNet_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string train_net = 1;</code>
			 *
			 * <pre>
			 * Proto filename for the train net.
			 * </pre>
			 */
			public Builder clearTrainNet()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				trainNet_ = getDefaultInstance().getTrainNet();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string train_net = 1;</code>
			 *
			 * <pre>
			 * Proto filename for the train net.
			 * </pre>
			 */
			public Builder setTrainNetBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				trainNet_ = value;
				onChanged();
				return this;
			}

			private com.google.protobuf.LazyStringList testNet_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureTestNetIsMutable()
			{
				if (!((bitField0_ & 0x00000008) == 0x00000008))
				{
					testNet_ = new com.google.protobuf.LazyStringArrayList(testNet_);
					bitField0_ |= 0x00000008;
				}
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getTestNetList()
			{
				return testNet_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			@Override
			public int getTestNetCount()
			{
				return testNet_.size();
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			@Override
			public java.lang.String getTestNet(int index)
			{
				return testNet_.get(index);
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getTestNetBytes(int index)
			{
				return testNet_.getByteString(index);
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			public Builder setTestNet(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureTestNetIsMutable();
				testNet_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			public Builder addTestNet(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureTestNetIsMutable();
				testNet_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			public Builder addAllTestNet(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureTestNetIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, testNet_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			public Builder clearTestNet()
			{
				testNet_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000008);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string test_net = 2;</code>
			 *
			 * <pre>
			 * Proto filenames for the test nets.
			 * </pre>
			 */
			public Builder addTestNetBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureTestNetIsMutable();
				testNet_.add(value);
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter trainNetParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder> trainNetParamBuilder_;

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			@Override
			public boolean hasTrainNetParam()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getTrainNetParam()
			{
				if (trainNetParamBuilder_ == null)
				{
					return trainNetParam_;
				} else
				{
					return trainNetParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			public Builder setTrainNetParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (trainNetParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					trainNetParam_ = value;
					onChanged();
				} else
				{
					trainNetParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			public Builder setTrainNetParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder builderForValue)
			{
				if (trainNetParamBuilder_ == null)
				{
					trainNetParam_ = builderForValue.build();
					onChanged();
				} else
				{
					trainNetParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			public Builder mergeTrainNetParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (trainNetParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00000010) == 0x00000010) &&
							trainNetParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance())
					{
						trainNetParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.newBuilder(trainNetParam_).mergeFrom(value).buildPartial();
					} else
					{
						trainNetParam_ = value;
					}
					onChanged();
				} else
				{
					trainNetParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			public Builder clearTrainNetParam()
			{
				if (trainNetParamBuilder_ == null)
				{
					trainNetParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance();
					onChanged();
				} else
				{
					trainNetParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000010);
				return this;
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder getTrainNetParamBuilder()
			{
				bitField0_ |= 0x00000010;
				onChanged();
				return getTrainNetParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getTrainNetParamOrBuilder()
			{
				if (trainNetParamBuilder_ != null)
				{
					return trainNetParamBuilder_.getMessageOrBuilder();
				} else
				{
					return trainNetParam_;
				}
			}

			/**
			 * <code>optional .caffe.NetParameter train_net_param = 21;</code>
			 *
			 * <pre>
			 * Inline train net params.
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>
					getTrainNetParamFieldBuilder()
			{
				if (trainNetParamBuilder_ == null)
				{
					trainNetParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>(
									getTrainNetParam(),
									getParentForChildren(),
									isClean());
					trainNetParam_ = null;
				}
				return trainNetParamBuilder_;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter> testNetParam_ =
					java.util.Collections.emptyList();

			private void ensureTestNetParamIsMutable()
			{
				if (!((bitField0_ & 0x00000020) == 0x00000020))
				{
					testNetParam_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter>(testNetParam_);
					bitField0_ |= 0x00000020;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder> testNetParamBuilder_;

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter> getTestNetParamList()
			{
				if (testNetParamBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(testNetParam_);
				} else
				{
					return testNetParamBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			@Override
			public int getTestNetParamCount()
			{
				if (testNetParamBuilder_ == null)
				{
					return testNetParam_.size();
				} else
				{
					return testNetParamBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter getTestNetParam(int index)
			{
				if (testNetParamBuilder_ == null)
				{
					return testNetParam_.get(index);
				} else
				{
					return testNetParamBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder setTestNetParam(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (testNetParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureTestNetParamIsMutable();
					testNetParam_.set(index, value);
					onChanged();
				} else
				{
					testNetParamBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder setTestNetParam(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder builderForValue)
			{
				if (testNetParamBuilder_ == null)
				{
					ensureTestNetParamIsMutable();
					testNetParam_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					testNetParamBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder addTestNetParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (testNetParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureTestNetParamIsMutable();
					testNetParam_.add(value);
					onChanged();
				} else
				{
					testNetParamBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder addTestNetParam(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter value)
			{
				if (testNetParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureTestNetParamIsMutable();
					testNetParam_.add(index, value);
					onChanged();
				} else
				{
					testNetParamBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder addTestNetParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder builderForValue)
			{
				if (testNetParamBuilder_ == null)
				{
					ensureTestNetParamIsMutable();
					testNetParam_.add(builderForValue.build());
					onChanged();
				} else
				{
					testNetParamBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder addTestNetParam(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder builderForValue)
			{
				if (testNetParamBuilder_ == null)
				{
					ensureTestNetParamIsMutable();
					testNetParam_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					testNetParamBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder addAllTestNetParam(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter> values)
			{
				if (testNetParamBuilder_ == null)
				{
					ensureTestNetParamIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, testNetParam_);
					onChanged();
				} else
				{
					testNetParamBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder clearTestNetParam()
			{
				if (testNetParamBuilder_ == null)
				{
					testNetParam_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000020);
					onChanged();
				} else
				{
					testNetParamBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public Builder removeTestNetParam(int index)
			{
				if (testNetParamBuilder_ == null)
				{
					ensureTestNetParamIsMutable();
					testNetParam_.remove(index);
					onChanged();
				} else
				{
					testNetParamBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder getTestNetParamBuilder(
					int index)
			{
				return getTestNetParamFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder getTestNetParamOrBuilder(
					int index)
			{
				if (testNetParamBuilder_ == null)
				{
					return testNetParam_.get(index);
				} else
				{
					return testNetParamBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>
					getTestNetParamOrBuilderList()
			{
				if (testNetParamBuilder_ != null)
				{
					return testNetParamBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(testNetParam_);
				}
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder addTestNetParamBuilder()
			{
				return getTestNetParamFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder addTestNetParamBuilder(
					int index)
			{
				return getTestNetParamFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetParameter test_net_param = 22;</code>
			 *
			 * <pre>
			 * Inline test net params.
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder>
					getTestNetParamBuilderList()
			{
				return getTestNetParamFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>
					getTestNetParamFieldBuilder()
			{
				if (testNetParamBuilder_ == null)
				{
					testNetParamBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetParameterOrBuilder>(
									testNetParam_,
									((bitField0_ & 0x00000020) == 0x00000020),
									getParentForChildren(),
									isClean());
					testNetParam_ = null;
				}
				return testNetParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState trainState_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder> trainStateBuilder_;

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			@Override
			public boolean hasTrainState()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getTrainState()
			{
				if (trainStateBuilder_ == null)
				{
					return trainState_;
				} else
				{
					return trainStateBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			public Builder setTrainState(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (trainStateBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					trainState_ = value;
					onChanged();
				} else
				{
					trainStateBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000040;
				return this;
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			public Builder setTrainState(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder builderForValue)
			{
				if (trainStateBuilder_ == null)
				{
					trainState_ = builderForValue.build();
					onChanged();
				} else
				{
					trainStateBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000040;
				return this;
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			public Builder mergeTrainState(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (trainStateBuilder_ == null)
				{
					if (((bitField0_ & 0x00000040) == 0x00000040) &&
							trainState_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance())
					{
						trainState_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.newBuilder(trainState_).mergeFrom(value).buildPartial();
					} else
					{
						trainState_ = value;
					}
					onChanged();
				} else
				{
					trainStateBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000040;
				return this;
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			public Builder clearTrainState()
			{
				if (trainStateBuilder_ == null)
				{
					trainState_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
					onChanged();
				} else
				{
					trainStateBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000040);
				return this;
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder getTrainStateBuilder()
			{
				bitField0_ |= 0x00000040;
				onChanged();
				return getTrainStateFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getTrainStateOrBuilder()
			{
				if (trainStateBuilder_ != null)
				{
					return trainStateBuilder_.getMessageOrBuilder();
				} else
				{
					return trainState_;
				}
			}

			/**
			 * <code>optional .caffe.NetState train_state = 26;</code>
			 *
			 * <pre>
			 * The states for the train/test nets. Must be unspecified or
			 * specified once per net.
			 * By default, all states will have solver = true;
			 * train_state will have phase = TRAIN,
			 * and all test_state's will have phase = TEST.
			 * Other defaults are set according to the NetState defaults.
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>
					getTrainStateFieldBuilder()
			{
				if (trainStateBuilder_ == null)
				{
					trainStateBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>(
									getTrainState(),
									getParentForChildren(),
									isClean());
					trainState_ = null;
				}
				return trainStateBuilder_;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState> testState_ =
					java.util.Collections.emptyList();

			private void ensureTestStateIsMutable()
			{
				if (!((bitField0_ & 0x00000080) == 0x00000080))
				{
					testState_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState>(testState_);
					bitField0_ |= 0x00000080;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder> testStateBuilder_;

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState> getTestStateList()
			{
				if (testStateBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(testState_);
				} else
				{
					return testStateBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			@Override
			public int getTestStateCount()
			{
				if (testStateBuilder_ == null)
				{
					return testState_.size();
				} else
				{
					return testStateBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getTestState(int index)
			{
				if (testStateBuilder_ == null)
				{
					return testState_.get(index);
				} else
				{
					return testStateBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder setTestState(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (testStateBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureTestStateIsMutable();
					testState_.set(index, value);
					onChanged();
				} else
				{
					testStateBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder setTestState(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder builderForValue)
			{
				if (testStateBuilder_ == null)
				{
					ensureTestStateIsMutable();
					testState_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					testStateBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder addTestState(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (testStateBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureTestStateIsMutable();
					testState_.add(value);
					onChanged();
				} else
				{
					testStateBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder addTestState(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState value)
			{
				if (testStateBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureTestStateIsMutable();
					testState_.add(index, value);
					onChanged();
				} else
				{
					testStateBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder addTestState(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder builderForValue)
			{
				if (testStateBuilder_ == null)
				{
					ensureTestStateIsMutable();
					testState_.add(builderForValue.build());
					onChanged();
				} else
				{
					testStateBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder addTestState(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder builderForValue)
			{
				if (testStateBuilder_ == null)
				{
					ensureTestStateIsMutable();
					testState_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					testStateBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder addAllTestState(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState> values)
			{
				if (testStateBuilder_ == null)
				{
					ensureTestStateIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, testState_);
					onChanged();
				} else
				{
					testStateBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder clearTestState()
			{
				if (testStateBuilder_ == null)
				{
					testState_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000080);
					onChanged();
				} else
				{
					testStateBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public Builder removeTestState(int index)
			{
				if (testStateBuilder_ == null)
				{
					ensureTestStateIsMutable();
					testState_.remove(index);
					onChanged();
				} else
				{
					testStateBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder getTestStateBuilder(
					int index)
			{
				return getTestStateFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder getTestStateOrBuilder(
					int index)
			{
				if (testStateBuilder_ == null)
				{
					return testState_.get(index);
				} else
				{
					return testStateBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>
					getTestStateOrBuilderList()
			{
				if (testStateBuilder_ != null)
				{
					return testStateBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(testState_);
				}
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder addTestStateBuilder()
			{
				return getTestStateFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder addTestStateBuilder(
					int index)
			{
				return getTestStateFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetState test_state = 27;</code>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder>
					getTestStateBuilderList()
			{
				return getTestStateFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>
					getTestStateFieldBuilder()
			{
				if (testStateBuilder_ == null)
				{
					testStateBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder>(
									testState_,
									((bitField0_ & 0x00000080) == 0x00000080),
									getParentForChildren(),
									isClean());
					testState_ = null;
				}
				return testStateBuilder_;
			}

			private java.util.List<java.lang.Integer> testIter_ = java.util.Collections.emptyList();

			private void ensureTestIterIsMutable()
			{
				if (!((bitField0_ & 0x00000100) == 0x00000100))
				{
					testIter_ = new java.util.ArrayList<java.lang.Integer>(testIter_);
					bitField0_ |= 0x00000100;
				}
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getTestIterList()
			{
				return java.util.Collections.unmodifiableList(testIter_);
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			@Override
			public int getTestIterCount()
			{
				return testIter_.size();
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			@Override
			public int getTestIter(int index)
			{
				return testIter_.get(index);
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			public Builder setTestIter(
					int index, int value)
			{
				ensureTestIterIsMutable();
				testIter_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			public Builder addTestIter(int value)
			{
				ensureTestIterIsMutable();
				testIter_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			public Builder addAllTestIter(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureTestIterIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, testIter_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 test_iter = 3;</code>
			 *
			 * <pre>
			 * The number of iterations for each test net.
			 * </pre>
			 */
			public Builder clearTestIter()
			{
				testIter_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000100);
				onChanged();
				return this;
			}

			private int testInterval_;

			/**
			 * <code>optional int32 test_interval = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The number of iterations between two testing phases.
			 * </pre>
			 */
			@Override
			public boolean hasTestInterval()
			{
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional int32 test_interval = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The number of iterations between two testing phases.
			 * </pre>
			 */
			@Override
			public int getTestInterval()
			{
				return testInterval_;
			}

			/**
			 * <code>optional int32 test_interval = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The number of iterations between two testing phases.
			 * </pre>
			 */
			public Builder setTestInterval(int value)
			{
				bitField0_ |= 0x00000200;
				testInterval_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 test_interval = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The number of iterations between two testing phases.
			 * </pre>
			 */
			public Builder clearTestInterval()
			{
				bitField0_ = (bitField0_ & ~0x00000200);
				testInterval_ = 0;
				onChanged();
				return this;
			}

			private boolean testComputeLoss_;

			/**
			 * <code>optional bool test_compute_loss = 19 [default = false];</code>
			 */
			@Override
			public boolean hasTestComputeLoss()
			{
				return ((bitField0_ & 0x00000400) == 0x00000400);
			}

			/**
			 * <code>optional bool test_compute_loss = 19 [default = false];</code>
			 */
			@Override
			public boolean getTestComputeLoss()
			{
				return testComputeLoss_;
			}

			/**
			 * <code>optional bool test_compute_loss = 19 [default = false];</code>
			 */
			public Builder setTestComputeLoss(boolean value)
			{
				bitField0_ |= 0x00000400;
				testComputeLoss_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool test_compute_loss = 19 [default = false];</code>
			 */
			public Builder clearTestComputeLoss()
			{
				bitField0_ = (bitField0_ & ~0x00000400);
				testComputeLoss_ = false;
				onChanged();
				return this;
			}

			private boolean testInitialization_ = true;

			/**
			 * <code>optional bool test_initialization = 32 [default = true];</code>
			 *
			 * <pre>
			 * If true, run an initial test pass before the first iteration,
			 * ensuring memory availability and printing the starting value of the loss.
			 * </pre>
			 */
			@Override
			public boolean hasTestInitialization()
			{
				return ((bitField0_ & 0x00000800) == 0x00000800);
			}

			/**
			 * <code>optional bool test_initialization = 32 [default = true];</code>
			 *
			 * <pre>
			 * If true, run an initial test pass before the first iteration,
			 * ensuring memory availability and printing the starting value of the loss.
			 * </pre>
			 */
			@Override
			public boolean getTestInitialization()
			{
				return testInitialization_;
			}

			/**
			 * <code>optional bool test_initialization = 32 [default = true];</code>
			 *
			 * <pre>
			 * If true, run an initial test pass before the first iteration,
			 * ensuring memory availability and printing the starting value of the loss.
			 * </pre>
			 */
			public Builder setTestInitialization(boolean value)
			{
				bitField0_ |= 0x00000800;
				testInitialization_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool test_initialization = 32 [default = true];</code>
			 *
			 * <pre>
			 * If true, run an initial test pass before the first iteration,
			 * ensuring memory availability and printing the starting value of the loss.
			 * </pre>
			 */
			public Builder clearTestInitialization()
			{
				bitField0_ = (bitField0_ & ~0x00000800);
				testInitialization_ = true;
				onChanged();
				return this;
			}

			private float baseLr_;

			/**
			 * <code>optional float base_lr = 5;</code>
			 *
			 * <pre>
			 * The base learning rate
			 * </pre>
			 */
			@Override
			public boolean hasBaseLr()
			{
				return ((bitField0_ & 0x00001000) == 0x00001000);
			}

			/**
			 * <code>optional float base_lr = 5;</code>
			 *
			 * <pre>
			 * The base learning rate
			 * </pre>
			 */
			@Override
			public float getBaseLr()
			{
				return baseLr_;
			}

			/**
			 * <code>optional float base_lr = 5;</code>
			 *
			 * <pre>
			 * The base learning rate
			 * </pre>
			 */
			public Builder setBaseLr(float value)
			{
				bitField0_ |= 0x00001000;
				baseLr_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float base_lr = 5;</code>
			 *
			 * <pre>
			 * The base learning rate
			 * </pre>
			 */
			public Builder clearBaseLr()
			{
				bitField0_ = (bitField0_ & ~0x00001000);
				baseLr_ = 0F;
				onChanged();
				return this;
			}

			private int display_;

			/**
			 * <code>optional int32 display = 6;</code>
			 *
			 * <pre>
			 * the number of iterations between displaying info. If display = 0, no info
			 * will be displayed.
			 * </pre>
			 */
			@Override
			public boolean hasDisplay()
			{
				return ((bitField0_ & 0x00002000) == 0x00002000);
			}

			/**
			 * <code>optional int32 display = 6;</code>
			 *
			 * <pre>
			 * the number of iterations between displaying info. If display = 0, no info
			 * will be displayed.
			 * </pre>
			 */
			@Override
			public int getDisplay()
			{
				return display_;
			}

			/**
			 * <code>optional int32 display = 6;</code>
			 *
			 * <pre>
			 * the number of iterations between displaying info. If display = 0, no info
			 * will be displayed.
			 * </pre>
			 */
			public Builder setDisplay(int value)
			{
				bitField0_ |= 0x00002000;
				display_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 display = 6;</code>
			 *
			 * <pre>
			 * the number of iterations between displaying info. If display = 0, no info
			 * will be displayed.
			 * </pre>
			 */
			public Builder clearDisplay()
			{
				bitField0_ = (bitField0_ & ~0x00002000);
				display_ = 0;
				onChanged();
				return this;
			}

			private int averageLoss_ = 1;

			/**
			 * <code>optional int32 average_loss = 33 [default = 1];</code>
			 *
			 * <pre>
			 * Display the cost averaged over the last average_cost iterations
			 * </pre>
			 */
			@Override
			public boolean hasAverageLoss()
			{
				return ((bitField0_ & 0x00004000) == 0x00004000);
			}

			/**
			 * <code>optional int32 average_loss = 33 [default = 1];</code>
			 *
			 * <pre>
			 * Display the cost averaged over the last average_cost iterations
			 * </pre>
			 */
			@Override
			public int getAverageLoss()
			{
				return averageLoss_;
			}

			/**
			 * <code>optional int32 average_loss = 33 [default = 1];</code>
			 *
			 * <pre>
			 * Display the cost averaged over the last average_cost iterations
			 * </pre>
			 */
			public Builder setAverageLoss(int value)
			{
				bitField0_ |= 0x00004000;
				averageLoss_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 average_loss = 33 [default = 1];</code>
			 *
			 * <pre>
			 * Display the cost averaged over the last average_cost iterations
			 * </pre>
			 */
			public Builder clearAverageLoss()
			{
				bitField0_ = (bitField0_ & ~0x00004000);
				averageLoss_ = 1;
				onChanged();
				return this;
			}

			private int maxIter_;

			/**
			 * <code>optional int32 max_iter = 7;</code>
			 *
			 * <pre>
			 * the maximum number of iterations
			 * </pre>
			 */
			@Override
			public boolean hasMaxIter()
			{
				return ((bitField0_ & 0x00008000) == 0x00008000);
			}

			/**
			 * <code>optional int32 max_iter = 7;</code>
			 *
			 * <pre>
			 * the maximum number of iterations
			 * </pre>
			 */
			@Override
			public int getMaxIter()
			{
				return maxIter_;
			}

			/**
			 * <code>optional int32 max_iter = 7;</code>
			 *
			 * <pre>
			 * the maximum number of iterations
			 * </pre>
			 */
			public Builder setMaxIter(int value)
			{
				bitField0_ |= 0x00008000;
				maxIter_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 max_iter = 7;</code>
			 *
			 * <pre>
			 * the maximum number of iterations
			 * </pre>
			 */
			public Builder clearMaxIter()
			{
				bitField0_ = (bitField0_ & ~0x00008000);
				maxIter_ = 0;
				onChanged();
				return this;
			}

			private java.lang.Object lrPolicy_ = "";

			/**
			 * <code>optional string lr_policy = 8;</code>
			 *
			 * <pre>
			 * The learning rate decay policy.
			 * </pre>
			 */
			@Override
			public boolean hasLrPolicy()
			{
				return ((bitField0_ & 0x00010000) == 0x00010000);
			}

			/**
			 * <code>optional string lr_policy = 8;</code>
			 *
			 * <pre>
			 * The learning rate decay policy.
			 * </pre>
			 */
			@Override
			public java.lang.String getLrPolicy()
			{
				java.lang.Object ref = lrPolicy_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						lrPolicy_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string lr_policy = 8;</code>
			 *
			 * <pre>
			 * The learning rate decay policy.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getLrPolicyBytes()
			{
				java.lang.Object ref = lrPolicy_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					lrPolicy_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string lr_policy = 8;</code>
			 *
			 * <pre>
			 * The learning rate decay policy.
			 * </pre>
			 */
			public Builder setLrPolicy(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00010000;
				lrPolicy_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string lr_policy = 8;</code>
			 *
			 * <pre>
			 * The learning rate decay policy.
			 * </pre>
			 */
			public Builder clearLrPolicy()
			{
				bitField0_ = (bitField0_ & ~0x00010000);
				lrPolicy_ = getDefaultInstance().getLrPolicy();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string lr_policy = 8;</code>
			 *
			 * <pre>
			 * The learning rate decay policy.
			 * </pre>
			 */
			public Builder setLrPolicyBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00010000;
				lrPolicy_ = value;
				onChanged();
				return this;
			}

			private float gamma_;

			/**
			 * <code>optional float gamma = 9;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			@Override
			public boolean hasGamma()
			{
				return ((bitField0_ & 0x00020000) == 0x00020000);
			}

			/**
			 * <code>optional float gamma = 9;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			@Override
			public float getGamma()
			{
				return gamma_;
			}

			/**
			 * <code>optional float gamma = 9;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			public Builder setGamma(float value)
			{
				bitField0_ |= 0x00020000;
				gamma_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float gamma = 9;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			public Builder clearGamma()
			{
				bitField0_ = (bitField0_ & ~0x00020000);
				gamma_ = 0F;
				onChanged();
				return this;
			}

			private float power_;

			/**
			 * <code>optional float power = 10;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			@Override
			public boolean hasPower()
			{
				return ((bitField0_ & 0x00040000) == 0x00040000);
			}

			/**
			 * <code>optional float power = 10;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			@Override
			public float getPower()
			{
				return power_;
			}

			/**
			 * <code>optional float power = 10;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			public Builder setPower(float value)
			{
				bitField0_ |= 0x00040000;
				power_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float power = 10;</code>
			 *
			 * <pre>
			 * The parameter to compute the learning rate.
			 * </pre>
			 */
			public Builder clearPower()
			{
				bitField0_ = (bitField0_ & ~0x00040000);
				power_ = 0F;
				onChanged();
				return this;
			}

			private float momentum_;

			/**
			 * <code>optional float momentum = 11;</code>
			 *
			 * <pre>
			 * The momentum value.
			 * </pre>
			 */
			@Override
			public boolean hasMomentum()
			{
				return ((bitField0_ & 0x00080000) == 0x00080000);
			}

			/**
			 * <code>optional float momentum = 11;</code>
			 *
			 * <pre>
			 * The momentum value.
			 * </pre>
			 */
			@Override
			public float getMomentum()
			{
				return momentum_;
			}

			/**
			 * <code>optional float momentum = 11;</code>
			 *
			 * <pre>
			 * The momentum value.
			 * </pre>
			 */
			public Builder setMomentum(float value)
			{
				bitField0_ |= 0x00080000;
				momentum_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float momentum = 11;</code>
			 *
			 * <pre>
			 * The momentum value.
			 * </pre>
			 */
			public Builder clearMomentum()
			{
				bitField0_ = (bitField0_ & ~0x00080000);
				momentum_ = 0F;
				onChanged();
				return this;
			}

			private float weightDecay_;

			/**
			 * <code>optional float weight_decay = 12;</code>
			 *
			 * <pre>
			 * The weight decay.
			 * </pre>
			 */
			@Override
			public boolean hasWeightDecay()
			{
				return ((bitField0_ & 0x00100000) == 0x00100000);
			}

			/**
			 * <code>optional float weight_decay = 12;</code>
			 *
			 * <pre>
			 * The weight decay.
			 * </pre>
			 */
			@Override
			public float getWeightDecay()
			{
				return weightDecay_;
			}

			/**
			 * <code>optional float weight_decay = 12;</code>
			 *
			 * <pre>
			 * The weight decay.
			 * </pre>
			 */
			public Builder setWeightDecay(float value)
			{
				bitField0_ |= 0x00100000;
				weightDecay_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float weight_decay = 12;</code>
			 *
			 * <pre>
			 * The weight decay.
			 * </pre>
			 */
			public Builder clearWeightDecay()
			{
				bitField0_ = (bitField0_ & ~0x00100000);
				weightDecay_ = 0F;
				onChanged();
				return this;
			}

			private java.lang.Object regularizationType_ = "L2";

			/**
			 * <code>optional string regularization_type = 29 [default = "L2"];</code>
			 *
			 * <pre>
			 * regularization types supported: L1 and L2
			 * controlled by weight_decay
			 * </pre>
			 */
			@Override
			public boolean hasRegularizationType()
			{
				return ((bitField0_ & 0x00200000) == 0x00200000);
			}

			/**
			 * <code>optional string regularization_type = 29 [default = "L2"];</code>
			 *
			 * <pre>
			 * regularization types supported: L1 and L2
			 * controlled by weight_decay
			 * </pre>
			 */
			@Override
			public java.lang.String getRegularizationType()
			{
				java.lang.Object ref = regularizationType_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						regularizationType_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string regularization_type = 29 [default = "L2"];</code>
			 *
			 * <pre>
			 * regularization types supported: L1 and L2
			 * controlled by weight_decay
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getRegularizationTypeBytes()
			{
				java.lang.Object ref = regularizationType_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					regularizationType_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string regularization_type = 29 [default = "L2"];</code>
			 *
			 * <pre>
			 * regularization types supported: L1 and L2
			 * controlled by weight_decay
			 * </pre>
			 */
			public Builder setRegularizationType(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00200000;
				regularizationType_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string regularization_type = 29 [default = "L2"];</code>
			 *
			 * <pre>
			 * regularization types supported: L1 and L2
			 * controlled by weight_decay
			 * </pre>
			 */
			public Builder clearRegularizationType()
			{
				bitField0_ = (bitField0_ & ~0x00200000);
				regularizationType_ = getDefaultInstance().getRegularizationType();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string regularization_type = 29 [default = "L2"];</code>
			 *
			 * <pre>
			 * regularization types supported: L1 and L2
			 * controlled by weight_decay
			 * </pre>
			 */
			public Builder setRegularizationTypeBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00200000;
				regularizationType_ = value;
				onChanged();
				return this;
			}

			private int stepsize_;

			/**
			 * <code>optional int32 stepsize = 13;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "step"
			 * </pre>
			 */
			@Override
			public boolean hasStepsize()
			{
				return ((bitField0_ & 0x00400000) == 0x00400000);
			}

			/**
			 * <code>optional int32 stepsize = 13;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "step"
			 * </pre>
			 */
			@Override
			public int getStepsize()
			{
				return stepsize_;
			}

			/**
			 * <code>optional int32 stepsize = 13;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "step"
			 * </pre>
			 */
			public Builder setStepsize(int value)
			{
				bitField0_ |= 0x00400000;
				stepsize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 stepsize = 13;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "step"
			 * </pre>
			 */
			public Builder clearStepsize()
			{
				bitField0_ = (bitField0_ & ~0x00400000);
				stepsize_ = 0;
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Integer> stepvalue_ = java.util.Collections.emptyList();

			private void ensureStepvalueIsMutable()
			{
				if (!((bitField0_ & 0x00800000) == 0x00800000))
				{
					stepvalue_ = new java.util.ArrayList<java.lang.Integer>(stepvalue_);
					bitField0_ |= 0x00800000;
				}
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getStepvalueList()
			{
				return java.util.Collections.unmodifiableList(stepvalue_);
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			@Override
			public int getStepvalueCount()
			{
				return stepvalue_.size();
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			@Override
			public int getStepvalue(int index)
			{
				return stepvalue_.get(index);
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			public Builder setStepvalue(
					int index, int value)
			{
				ensureStepvalueIsMutable();
				stepvalue_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			public Builder addStepvalue(int value)
			{
				ensureStepvalueIsMutable();
				stepvalue_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			public Builder addAllStepvalue(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureStepvalueIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, stepvalue_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated int32 stepvalue = 34;</code>
			 *
			 * <pre>
			 * the stepsize for learning rate policy "multistep"
			 * </pre>
			 */
			public Builder clearStepvalue()
			{
				stepvalue_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00800000);
				onChanged();
				return this;
			}

			private int snapshot_;

			/**
			 * <code>optional int32 snapshot = 14 [default = 0];</code>
			 *
			 * <pre>
			 * The snapshot interval
			 * </pre>
			 */
			@Override
			public boolean hasSnapshot()
			{
				return ((bitField0_ & 0x01000000) == 0x01000000);
			}

			/**
			 * <code>optional int32 snapshot = 14 [default = 0];</code>
			 *
			 * <pre>
			 * The snapshot interval
			 * </pre>
			 */
			@Override
			public int getSnapshot()
			{
				return snapshot_;
			}

			/**
			 * <code>optional int32 snapshot = 14 [default = 0];</code>
			 *
			 * <pre>
			 * The snapshot interval
			 * </pre>
			 */
			public Builder setSnapshot(int value)
			{
				bitField0_ |= 0x01000000;
				snapshot_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 snapshot = 14 [default = 0];</code>
			 *
			 * <pre>
			 * The snapshot interval
			 * </pre>
			 */
			public Builder clearSnapshot()
			{
				bitField0_ = (bitField0_ & ~0x01000000);
				snapshot_ = 0;
				onChanged();
				return this;
			}

			private java.lang.Object snapshotPrefix_ = "";

			/**
			 * <code>optional string snapshot_prefix = 15;</code>
			 *
			 * <pre>
			 * The prefix for the snapshot.
			 * </pre>
			 */
			@Override
			public boolean hasSnapshotPrefix()
			{
				return ((bitField0_ & 0x02000000) == 0x02000000);
			}

			/**
			 * <code>optional string snapshot_prefix = 15;</code>
			 *
			 * <pre>
			 * The prefix for the snapshot.
			 * </pre>
			 */
			@Override
			public java.lang.String getSnapshotPrefix()
			{
				java.lang.Object ref = snapshotPrefix_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						snapshotPrefix_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string snapshot_prefix = 15;</code>
			 *
			 * <pre>
			 * The prefix for the snapshot.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSnapshotPrefixBytes()
			{
				java.lang.Object ref = snapshotPrefix_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					snapshotPrefix_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string snapshot_prefix = 15;</code>
			 *
			 * <pre>
			 * The prefix for the snapshot.
			 * </pre>
			 */
			public Builder setSnapshotPrefix(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x02000000;
				snapshotPrefix_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string snapshot_prefix = 15;</code>
			 *
			 * <pre>
			 * The prefix for the snapshot.
			 * </pre>
			 */
			public Builder clearSnapshotPrefix()
			{
				bitField0_ = (bitField0_ & ~0x02000000);
				snapshotPrefix_ = getDefaultInstance().getSnapshotPrefix();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string snapshot_prefix = 15;</code>
			 *
			 * <pre>
			 * The prefix for the snapshot.
			 * </pre>
			 */
			public Builder setSnapshotPrefixBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x02000000;
				snapshotPrefix_ = value;
				onChanged();
				return this;
			}

			private boolean snapshotDiff_;

			/**
			 * <code>optional bool snapshot_diff = 16 [default = false];</code>
			 *
			 * <pre>
			 * whether to snapshot diff in the results or not. Snapshotting diff will help
			 * debugging but the final protocol buffer size will be much larger.
			 * </pre>
			 */
			@Override
			public boolean hasSnapshotDiff()
			{
				return ((bitField0_ & 0x04000000) == 0x04000000);
			}

			/**
			 * <code>optional bool snapshot_diff = 16 [default = false];</code>
			 *
			 * <pre>
			 * whether to snapshot diff in the results or not. Snapshotting diff will help
			 * debugging but the final protocol buffer size will be much larger.
			 * </pre>
			 */
			@Override
			public boolean getSnapshotDiff()
			{
				return snapshotDiff_;
			}

			/**
			 * <code>optional bool snapshot_diff = 16 [default = false];</code>
			 *
			 * <pre>
			 * whether to snapshot diff in the results or not. Snapshotting diff will help
			 * debugging but the final protocol buffer size will be much larger.
			 * </pre>
			 */
			public Builder setSnapshotDiff(boolean value)
			{
				bitField0_ |= 0x04000000;
				snapshotDiff_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool snapshot_diff = 16 [default = false];</code>
			 *
			 * <pre>
			 * whether to snapshot diff in the results or not. Snapshotting diff will help
			 * debugging but the final protocol buffer size will be much larger.
			 * </pre>
			 */
			public Builder clearSnapshotDiff()
			{
				bitField0_ = (bitField0_ & ~0x04000000);
				snapshotDiff_ = false;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode solverMode_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode.GPU;

			/**
			 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
			 */
			@Override
			public boolean hasSolverMode()
			{
				return ((bitField0_ & 0x08000000) == 0x08000000);
			}

			/**
			 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode getSolverMode()
			{
				return solverMode_;
			}

			/**
			 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
			 */
			public Builder setSolverMode(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x08000000;
				solverMode_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.SolverParameter.SolverMode solver_mode = 17 [default = GPU];</code>
			 */
			public Builder clearSolverMode()
			{
				bitField0_ = (bitField0_ & ~0x08000000);
				solverMode_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverMode.GPU;
				onChanged();
				return this;
			}

			private int deviceId_;

			/**
			 * <code>optional int32 device_id = 18 [default = 0];</code>
			 *
			 * <pre>
			 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
			 * </pre>
			 */
			@Override
			public boolean hasDeviceId()
			{
				return ((bitField0_ & 0x10000000) == 0x10000000);
			}

			/**
			 * <code>optional int32 device_id = 18 [default = 0];</code>
			 *
			 * <pre>
			 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
			 * </pre>
			 */
			@Override
			public int getDeviceId()
			{
				return deviceId_;
			}

			/**
			 * <code>optional int32 device_id = 18 [default = 0];</code>
			 *
			 * <pre>
			 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
			 * </pre>
			 */
			public Builder setDeviceId(int value)
			{
				bitField0_ |= 0x10000000;
				deviceId_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 device_id = 18 [default = 0];</code>
			 *
			 * <pre>
			 * the device_id will that be used in GPU mode. Use device_id = 0 in default.
			 * </pre>
			 */
			public Builder clearDeviceId()
			{
				bitField0_ = (bitField0_ & ~0x10000000);
				deviceId_ = 0;
				onChanged();
				return this;
			}

			private long randomSeed_ = -1L;

			/**
			 * <code>optional int64 random_seed = 20 [default = -1];</code>
			 *
			 * <pre>
			 * If non-negative, the seed with which the Solver will initialize the Caffe
			 * random number generator -- useful for reproducible results. Otherwise,
			 * (and by default) initialize using a seed derived from the system clock.
			 * </pre>
			 */
			@Override
			public boolean hasRandomSeed()
			{
				return ((bitField0_ & 0x20000000) == 0x20000000);
			}

			/**
			 * <code>optional int64 random_seed = 20 [default = -1];</code>
			 *
			 * <pre>
			 * If non-negative, the seed with which the Solver will initialize the Caffe
			 * random number generator -- useful for reproducible results. Otherwise,
			 * (and by default) initialize using a seed derived from the system clock.
			 * </pre>
			 */
			@Override
			public long getRandomSeed()
			{
				return randomSeed_;
			}

			/**
			 * <code>optional int64 random_seed = 20 [default = -1];</code>
			 *
			 * <pre>
			 * If non-negative, the seed with which the Solver will initialize the Caffe
			 * random number generator -- useful for reproducible results. Otherwise,
			 * (and by default) initialize using a seed derived from the system clock.
			 * </pre>
			 */
			public Builder setRandomSeed(long value)
			{
				bitField0_ |= 0x20000000;
				randomSeed_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int64 random_seed = 20 [default = -1];</code>
			 *
			 * <pre>
			 * If non-negative, the seed with which the Solver will initialize the Caffe
			 * random number generator -- useful for reproducible results. Otherwise,
			 * (and by default) initialize using a seed derived from the system clock.
			 * </pre>
			 */
			public Builder clearRandomSeed()
			{
				bitField0_ = (bitField0_ & ~0x20000000);
				randomSeed_ = -1L;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType solverType_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType.SGD;

			/**
			 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
			 */
			@Override
			public boolean hasSolverType()
			{
				return ((bitField0_ & 0x40000000) == 0x40000000);
			}

			/**
			 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType getSolverType()
			{
				return solverType_;
			}

			/**
			 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
			 */
			public Builder setSolverType(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x40000000;
				solverType_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.SolverParameter.SolverType solver_type = 30 [default = SGD];</code>
			 */
			public Builder clearSolverType()
			{
				bitField0_ = (bitField0_ & ~0x40000000);
				solverType_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverParameter.SolverType.SGD;
				onChanged();
				return this;
			}

			private float delta_ = 1e-008F;

			/**
			 * <code>optional float delta = 31 [default = 1e-008];</code>
			 *
			 * <pre>
			 * numerical stability for AdaGrad
			 * </pre>
			 */
			@Override
			public boolean hasDelta()
			{
				return ((bitField0_ & 0x80000000) == 0x80000000);
			}

			/**
			 * <code>optional float delta = 31 [default = 1e-008];</code>
			 *
			 * <pre>
			 * numerical stability for AdaGrad
			 * </pre>
			 */
			@Override
			public float getDelta()
			{
				return delta_;
			}

			/**
			 * <code>optional float delta = 31 [default = 1e-008];</code>
			 *
			 * <pre>
			 * numerical stability for AdaGrad
			 * </pre>
			 */
			public Builder setDelta(float value)
			{
				bitField0_ |= 0x80000000;
				delta_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float delta = 31 [default = 1e-008];</code>
			 *
			 * <pre>
			 * numerical stability for AdaGrad
			 * </pre>
			 */
			public Builder clearDelta()
			{
				bitField0_ = (bitField0_ & ~0x80000000);
				delta_ = 1e-008F;
				onChanged();
				return this;
			}

			private boolean debugInfo_;

			/**
			 * <code>optional bool debug_info = 23 [default = false];</code>
			 *
			 * <pre>
			 * If true, print information about the state of the net that may help with
			 * debugging learning problems.
			 * </pre>
			 */
			@Override
			public boolean hasDebugInfo()
			{
				return ((bitField1_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional bool debug_info = 23 [default = false];</code>
			 *
			 * <pre>
			 * If true, print information about the state of the net that may help with
			 * debugging learning problems.
			 * </pre>
			 */
			@Override
			public boolean getDebugInfo()
			{
				return debugInfo_;
			}

			/**
			 * <code>optional bool debug_info = 23 [default = false];</code>
			 *
			 * <pre>
			 * If true, print information about the state of the net that may help with
			 * debugging learning problems.
			 * </pre>
			 */
			public Builder setDebugInfo(boolean value)
			{
				bitField1_ |= 0x00000001;
				debugInfo_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool debug_info = 23 [default = false];</code>
			 *
			 * <pre>
			 * If true, print information about the state of the net that may help with
			 * debugging learning problems.
			 * </pre>
			 */
			public Builder clearDebugInfo()
			{
				bitField1_ = (bitField1_ & ~0x00000001);
				debugInfo_ = false;
				onChanged();
				return this;
			}

			private boolean snapshotAfterTrain_ = true;

			/**
			 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
			 *
			 * <pre>
			 * If false, don't save a snapshot after training finishes.
			 * </pre>
			 */
			@Override
			public boolean hasSnapshotAfterTrain()
			{
				return ((bitField1_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
			 *
			 * <pre>
			 * If false, don't save a snapshot after training finishes.
			 * </pre>
			 */
			@Override
			public boolean getSnapshotAfterTrain()
			{
				return snapshotAfterTrain_;
			}

			/**
			 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
			 *
			 * <pre>
			 * If false, don't save a snapshot after training finishes.
			 * </pre>
			 */
			public Builder setSnapshotAfterTrain(boolean value)
			{
				bitField1_ |= 0x00000002;
				snapshotAfterTrain_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool snapshot_after_train = 28 [default = true];</code>
			 *
			 * <pre>
			 * If false, don't save a snapshot after training finishes.
			 * </pre>
			 */
			public Builder clearSnapshotAfterTrain()
			{
				bitField1_ = (bitField1_ & ~0x00000002);
				snapshotAfterTrain_ = true;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.SolverParameter)
		}

		static
		{
			defaultInstance = new SolverParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.SolverParameter)
	}

	public interface SolverStateOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.SolverState)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional int32 iter = 1;</code>
		 *
		 * <pre>
		 * The current iteration
		 * </pre>
		 */
		boolean hasIter();

		/**
		 * <code>optional int32 iter = 1;</code>
		 *
		 * <pre>
		 * The current iteration
		 * </pre>
		 */
		int getIter();

		/**
		 * <code>optional string learned_net = 2;</code>
		 *
		 * <pre>
		 * The file that stores the learned net.
		 * </pre>
		 */
		boolean hasLearnedNet();

		/**
		 * <code>optional string learned_net = 2;</code>
		 *
		 * <pre>
		 * The file that stores the learned net.
		 * </pre>
		 */
		java.lang.String getLearnedNet();

		/**
		 * <code>optional string learned_net = 2;</code>
		 *
		 * <pre>
		 * The file that stores the learned net.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getLearnedNetBytes();

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>
				getHistoryList();

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getHistory(int index);

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		int getHistoryCount();

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getHistoryOrBuilderList();

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getHistoryOrBuilder(
				int index);

		/**
		 * <code>optional int32 current_step = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The current step for learning rate
		 * </pre>
		 */
		boolean hasCurrentStep();

		/**
		 * <code>optional int32 current_step = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The current step for learning rate
		 * </pre>
		 */
		int getCurrentStep();
	}

	/**
	 * Protobuf type {@code caffe.SolverState}
	 *
	 * <pre>
	 * A message that stores the solver snapshots
	 * </pre>
	 */
	public static final class SolverState extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.SolverState)
			SolverStateOrBuilder
	{
		// Use SolverState.newBuilder() to construct.
		private SolverState(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private SolverState(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final SolverState defaultInstance;

		public static SolverState getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public SolverState getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private SolverState(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						iter_ = input.readInt32();
						break;
					}
					case 18:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000002;
						learnedNet_ = bs;
						break;
					}
					case 26:
					{
						if (!((mutable_bitField0_ & 0x00000004) == 0x00000004))
						{
							history_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>();
							mutable_bitField0_ |= 0x00000004;
						}
						history_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.PARSER, extensionRegistry));
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000004;
						currentStep_ = input.readInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000004) == 0x00000004))
				{
					history_ = java.util.Collections.unmodifiableList(history_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverState_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverState_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.Builder.class);
		}

		public static com.google.protobuf.Parser<SolverState> PARSER =
				new com.google.protobuf.AbstractParser<SolverState>()
				{
					@Override
					public SolverState parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new SolverState(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<SolverState> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int ITER_FIELD_NUMBER = 1;
		private int iter_;

		/**
		 * <code>optional int32 iter = 1;</code>
		 *
		 * <pre>
		 * The current iteration
		 * </pre>
		 */
		@Override
		public boolean hasIter()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional int32 iter = 1;</code>
		 *
		 * <pre>
		 * The current iteration
		 * </pre>
		 */
		@Override
		public int getIter()
		{
			return iter_;
		}

		public static final int LEARNED_NET_FIELD_NUMBER = 2;
		private java.lang.Object learnedNet_;

		/**
		 * <code>optional string learned_net = 2;</code>
		 *
		 * <pre>
		 * The file that stores the learned net.
		 * </pre>
		 */
		@Override
		public boolean hasLearnedNet()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional string learned_net = 2;</code>
		 *
		 * <pre>
		 * The file that stores the learned net.
		 * </pre>
		 */
		@Override
		public java.lang.String getLearnedNet()
		{
			java.lang.Object ref = learnedNet_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					learnedNet_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string learned_net = 2;</code>
		 *
		 * <pre>
		 * The file that stores the learned net.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getLearnedNetBytes()
		{
			java.lang.Object ref = learnedNet_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				learnedNet_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int HISTORY_FIELD_NUMBER = 3;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> history_;

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getHistoryList()
		{
			return history_;
		}

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getHistoryOrBuilderList()
		{
			return history_;
		}

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		@Override
		public int getHistoryCount()
		{
			return history_.size();
		}

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getHistory(int index)
		{
			return history_.get(index);
		}

		/**
		 * <code>repeated .caffe.BlobProto history = 3;</code>
		 *
		 * <pre>
		 * The history for sgd solvers
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getHistoryOrBuilder(
				int index)
		{
			return history_.get(index);
		}

		public static final int CURRENT_STEP_FIELD_NUMBER = 4;
		private int currentStep_;

		/**
		 * <code>optional int32 current_step = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The current step for learning rate
		 * </pre>
		 */
		@Override
		public boolean hasCurrentStep()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional int32 current_step = 4 [default = 0];</code>
		 *
		 * <pre>
		 * The current step for learning rate
		 * </pre>
		 */
		@Override
		public int getCurrentStep()
		{
			return currentStep_;
		}

		private void initFields()
		{
			iter_ = 0;
			learnedNet_ = "";
			history_ = java.util.Collections.emptyList();
			currentStep_ = 0;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeInt32(1, iter_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBytes(2, getLearnedNetBytes());
			}
			for (int i = 0; i < history_.size(); i++)
			{
				output.writeMessage(3, history_.get(i));
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeInt32(4, currentStep_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(1, iter_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(2, getLearnedNetBytes());
			}
			for (int i = 0; i < history_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(3, history_.get(i));
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(4, currentStep_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.SolverState}
		 *
		 * <pre>
		 * A message that stores the solver snapshots
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.SolverState)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverStateOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverState_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverState_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getHistoryFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				iter_ = 0;
				bitField0_ = (bitField0_ & ~0x00000001);
				learnedNet_ = "";
				bitField0_ = (bitField0_ & ~0x00000002);
				if (historyBuilder_ == null)
				{
					history_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000004);
				} else
				{
					historyBuilder_.clear();
				}
				currentStep_ = 0;
				bitField0_ = (bitField0_ & ~0x00000008);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SolverState_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.iter_ = iter_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.learnedNet_ = learnedNet_;
				if (historyBuilder_ == null)
				{
					if (((bitField0_ & 0x00000004) == 0x00000004))
					{
						history_ = java.util.Collections.unmodifiableList(history_);
						bitField0_ = (bitField0_ & ~0x00000004);
					}
					result.history_ = history_;
				} else
				{
					result.history_ = historyBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.currentStep_ = currentStep_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState.getDefaultInstance())
					return this;
				if (other.hasIter())
				{
					setIter(other.getIter());
				}
				if (other.hasLearnedNet())
				{
					bitField0_ |= 0x00000002;
					learnedNet_ = other.learnedNet_;
					onChanged();
				}
				if (historyBuilder_ == null)
				{
					if (!other.history_.isEmpty())
					{
						if (history_.isEmpty())
						{
							history_ = other.history_;
							bitField0_ = (bitField0_ & ~0x00000004);
						} else
						{
							ensureHistoryIsMutable();
							history_.addAll(other.history_);
						}
						onChanged();
					}
				} else
				{
					if (!other.history_.isEmpty())
					{
						if (historyBuilder_.isEmpty())
						{
							historyBuilder_.dispose();
							historyBuilder_ = null;
							history_ = other.history_;
							bitField0_ = (bitField0_ & ~0x00000004);
							historyBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getHistoryFieldBuilder() : null;
						} else
						{
							historyBuilder_.addAllMessages(other.history_);
						}
					}
				}
				if (other.hasCurrentStep())
				{
					setCurrentStep(other.getCurrentStep());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SolverState) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int iter_;

			/**
			 * <code>optional int32 iter = 1;</code>
			 *
			 * <pre>
			 * The current iteration
			 * </pre>
			 */
			@Override
			public boolean hasIter()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional int32 iter = 1;</code>
			 *
			 * <pre>
			 * The current iteration
			 * </pre>
			 */
			@Override
			public int getIter()
			{
				return iter_;
			}

			/**
			 * <code>optional int32 iter = 1;</code>
			 *
			 * <pre>
			 * The current iteration
			 * </pre>
			 */
			public Builder setIter(int value)
			{
				bitField0_ |= 0x00000001;
				iter_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 iter = 1;</code>
			 *
			 * <pre>
			 * The current iteration
			 * </pre>
			 */
			public Builder clearIter()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				iter_ = 0;
				onChanged();
				return this;
			}

			private java.lang.Object learnedNet_ = "";

			/**
			 * <code>optional string learned_net = 2;</code>
			 *
			 * <pre>
			 * The file that stores the learned net.
			 * </pre>
			 */
			@Override
			public boolean hasLearnedNet()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional string learned_net = 2;</code>
			 *
			 * <pre>
			 * The file that stores the learned net.
			 * </pre>
			 */
			@Override
			public java.lang.String getLearnedNet()
			{
				java.lang.Object ref = learnedNet_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						learnedNet_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string learned_net = 2;</code>
			 *
			 * <pre>
			 * The file that stores the learned net.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getLearnedNetBytes()
			{
				java.lang.Object ref = learnedNet_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					learnedNet_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string learned_net = 2;</code>
			 *
			 * <pre>
			 * The file that stores the learned net.
			 * </pre>
			 */
			public Builder setLearnedNet(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000002;
				learnedNet_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string learned_net = 2;</code>
			 *
			 * <pre>
			 * The file that stores the learned net.
			 * </pre>
			 */
			public Builder clearLearnedNet()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				learnedNet_ = getDefaultInstance().getLearnedNet();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string learned_net = 2;</code>
			 *
			 * <pre>
			 * The file that stores the learned net.
			 * </pre>
			 */
			public Builder setLearnedNetBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000002;
				learnedNet_ = value;
				onChanged();
				return this;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> history_ =
					java.util.Collections.emptyList();

			private void ensureHistoryIsMutable()
			{
				if (!((bitField0_ & 0x00000004) == 0x00000004))
				{
					history_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>(history_);
					bitField0_ |= 0x00000004;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder> historyBuilder_;

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getHistoryList()
			{
				if (historyBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(history_);
				} else
				{
					return historyBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			@Override
			public int getHistoryCount()
			{
				if (historyBuilder_ == null)
				{
					return history_.size();
				} else
				{
					return historyBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getHistory(int index)
			{
				if (historyBuilder_ == null)
				{
					return history_.get(index);
				} else
				{
					return historyBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder setHistory(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (historyBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureHistoryIsMutable();
					history_.set(index, value);
					onChanged();
				} else
				{
					historyBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder setHistory(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (historyBuilder_ == null)
				{
					ensureHistoryIsMutable();
					history_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					historyBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder addHistory(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (historyBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureHistoryIsMutable();
					history_.add(value);
					onChanged();
				} else
				{
					historyBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder addHistory(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (historyBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureHistoryIsMutable();
					history_.add(index, value);
					onChanged();
				} else
				{
					historyBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder addHistory(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (historyBuilder_ == null)
				{
					ensureHistoryIsMutable();
					history_.add(builderForValue.build());
					onChanged();
				} else
				{
					historyBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder addHistory(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (historyBuilder_ == null)
				{
					ensureHistoryIsMutable();
					history_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					historyBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder addAllHistory(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> values)
			{
				if (historyBuilder_ == null)
				{
					ensureHistoryIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, history_);
					onChanged();
				} else
				{
					historyBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder clearHistory()
			{
				if (historyBuilder_ == null)
				{
					history_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000004);
					onChanged();
				} else
				{
					historyBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public Builder removeHistory(int index)
			{
				if (historyBuilder_ == null)
				{
					ensureHistoryIsMutable();
					history_.remove(index);
					onChanged();
				} else
				{
					historyBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder getHistoryBuilder(
					int index)
			{
				return getHistoryFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getHistoryOrBuilder(
					int index)
			{
				if (historyBuilder_ == null)
				{
					return history_.get(index);
				} else
				{
					return historyBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getHistoryOrBuilderList()
			{
				if (historyBuilder_ != null)
				{
					return historyBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(history_);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addHistoryBuilder()
			{
				return getHistoryFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addHistoryBuilder(
					int index)
			{
				return getHistoryFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto history = 3;</code>
			 *
			 * <pre>
			 * The history for sgd solvers
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder>
					getHistoryBuilderList()
			{
				return getHistoryFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getHistoryFieldBuilder()
			{
				if (historyBuilder_ == null)
				{
					historyBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>(
									history_,
									((bitField0_ & 0x00000004) == 0x00000004),
									getParentForChildren(),
									isClean());
					history_ = null;
				}
				return historyBuilder_;
			}

			private int currentStep_;

			/**
			 * <code>optional int32 current_step = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The current step for learning rate
			 * </pre>
			 */
			@Override
			public boolean hasCurrentStep()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional int32 current_step = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The current step for learning rate
			 * </pre>
			 */
			@Override
			public int getCurrentStep()
			{
				return currentStep_;
			}

			/**
			 * <code>optional int32 current_step = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The current step for learning rate
			 * </pre>
			 */
			public Builder setCurrentStep(int value)
			{
				bitField0_ |= 0x00000008;
				currentStep_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 current_step = 4 [default = 0];</code>
			 *
			 * <pre>
			 * The current step for learning rate
			 * </pre>
			 */
			public Builder clearCurrentStep()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				currentStep_ = 0;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.SolverState)
		}

		static
		{
			defaultInstance = new SolverState(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.SolverState)
	}

	public interface NetStateOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.NetState)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
		 */
		boolean hasPhase();

		/**
		 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase getPhase();

		/**
		 * <code>optional int32 level = 2 [default = 0];</code>
		 */
		boolean hasLevel();

		/**
		 * <code>optional int32 level = 2 [default = 0];</code>
		 */
		int getLevel();

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		com.google.protobuf.ProtocolStringList
				getStageList();

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		int getStageCount();

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		java.lang.String getStage(int index);

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		com.google.protobuf.ByteString
				getStageBytes(int index);
	}

	/**
	 * Protobuf type {@code caffe.NetState}
	 */
	public static final class NetState extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.NetState)
			NetStateOrBuilder
	{
		// Use NetState.newBuilder() to construct.
		private NetState(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private NetState(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final NetState defaultInstance;

		public static NetState getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public NetState getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private NetState(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							phase_ = value;
						}
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						level_ = input.readInt32();
						break;
					}
					case 26:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000004) == 0x00000004))
						{
							stage_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000004;
						}
						stage_.add(bs);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000004) == 0x00000004))
				{
					stage_ = stage_.getUnmodifiableView();
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetState_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetState_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder.class);
		}

		public static com.google.protobuf.Parser<NetState> PARSER =
				new com.google.protobuf.AbstractParser<NetState>()
				{
					@Override
					public NetState parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new NetState(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<NetState> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int PHASE_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase phase_;

		/**
		 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
		 */
		@Override
		public boolean hasPhase()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase getPhase()
		{
			return phase_;
		}

		public static final int LEVEL_FIELD_NUMBER = 2;
		private int level_;

		/**
		 * <code>optional int32 level = 2 [default = 0];</code>
		 */
		@Override
		public boolean hasLevel()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional int32 level = 2 [default = 0];</code>
		 */
		@Override
		public int getLevel()
		{
			return level_;
		}

		public static final int STAGE_FIELD_NUMBER = 3;
		private com.google.protobuf.LazyStringList stage_;

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getStageList()
		{
			return stage_;
		}

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		@Override
		public int getStageCount()
		{
			return stage_.size();
		}

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		@Override
		public java.lang.String getStage(int index)
		{
			return stage_.get(index);
		}

		/**
		 * <code>repeated string stage = 3;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getStageBytes(int index)
		{
			return stage_.getByteString(index);
		}

		private void initFields()
		{
			phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TEST;
			level_ = 0;
			stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, phase_.getNumber());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeInt32(2, level_);
			}
			for (int i = 0; i < stage_.size(); i++)
			{
				output.writeBytes(3, stage_.getByteString(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, phase_.getNumber());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(2, level_);
			}
			{
				int dataSize = 0;
				for (int i = 0; i < stage_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(stage_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getStageList().size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.NetState}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.NetState)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetState_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetState_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TEST;
				bitField0_ = (bitField0_ & ~0x00000001);
				level_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000004);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetState_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.phase_ = phase_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.level_ = level_;
				if (((bitField0_ & 0x00000004) == 0x00000004))
				{
					stage_ = stage_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000004);
				}
				result.stage_ = stage_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState.getDefaultInstance())
					return this;
				if (other.hasPhase())
				{
					setPhase(other.getPhase());
				}
				if (other.hasLevel())
				{
					setLevel(other.getLevel());
				}
				if (!other.stage_.isEmpty())
				{
					if (stage_.isEmpty())
					{
						stage_ = other.stage_;
						bitField0_ = (bitField0_ & ~0x00000004);
					} else
					{
						ensureStageIsMutable();
						stage_.addAll(other.stage_);
					}
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetState) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TEST;

			/**
			 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
			 */
			@Override
			public boolean hasPhase()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase getPhase()
			{
				return phase_;
			}

			/**
			 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
			 */
			public Builder setPhase(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				phase_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.Phase phase = 1 [default = TEST];</code>
			 */
			public Builder clearPhase()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TEST;
				onChanged();
				return this;
			}

			private int level_;

			/**
			 * <code>optional int32 level = 2 [default = 0];</code>
			 */
			@Override
			public boolean hasLevel()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional int32 level = 2 [default = 0];</code>
			 */
			@Override
			public int getLevel()
			{
				return level_;
			}

			/**
			 * <code>optional int32 level = 2 [default = 0];</code>
			 */
			public Builder setLevel(int value)
			{
				bitField0_ |= 0x00000002;
				level_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 level = 2 [default = 0];</code>
			 */
			public Builder clearLevel()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				level_ = 0;
				onChanged();
				return this;
			}

			private com.google.protobuf.LazyStringList stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureStageIsMutable()
			{
				if (!((bitField0_ & 0x00000004) == 0x00000004))
				{
					stage_ = new com.google.protobuf.LazyStringArrayList(stage_);
					bitField0_ |= 0x00000004;
				}
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getStageList()
			{
				return stage_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			@Override
			public int getStageCount()
			{
				return stage_.size();
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			@Override
			public java.lang.String getStage(int index)
			{
				return stage_.get(index);
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getStageBytes(int index)
			{
				return stage_.getByteString(index);
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			public Builder setStage(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureStageIsMutable();
				stage_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			public Builder addStage(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureStageIsMutable();
				stage_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			public Builder addAllStage(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureStageIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, stage_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			public Builder clearStage()
			{
				stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000004);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 3;</code>
			 */
			public Builder addStageBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureStageIsMutable();
				stage_.add(value);
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.NetState)
		}

		static
		{
			defaultInstance = new NetState(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.NetState)
	}

	public interface NetStateRuleOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.NetStateRule)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.Phase phase = 1;</code>
		 *
		 * <pre>
		 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
		 * to meet this rule.
		 * </pre>
		 */
		boolean hasPhase();

		/**
		 * <code>optional .caffe.Phase phase = 1;</code>
		 *
		 * <pre>
		 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
		 * to meet this rule.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase getPhase();

		/**
		 * <code>optional int32 min_level = 2;</code>
		 *
		 * <pre>
		 * Set the minimum and/or maximum levels in which the layer should be used.
		 * Leave undefined to meet the rule regardless of level.
		 * </pre>
		 */
		boolean hasMinLevel();

		/**
		 * <code>optional int32 min_level = 2;</code>
		 *
		 * <pre>
		 * Set the minimum and/or maximum levels in which the layer should be used.
		 * Leave undefined to meet the rule regardless of level.
		 * </pre>
		 */
		int getMinLevel();

		/**
		 * <code>optional int32 max_level = 3;</code>
		 */
		boolean hasMaxLevel();

		/**
		 * <code>optional int32 max_level = 3;</code>
		 */
		int getMaxLevel();

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		com.google.protobuf.ProtocolStringList
				getStageList();

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		int getStageCount();

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		java.lang.String getStage(int index);

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getStageBytes(int index);

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		com.google.protobuf.ProtocolStringList
				getNotStageList();

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		int getNotStageCount();

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		java.lang.String getNotStage(int index);

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		com.google.protobuf.ByteString
				getNotStageBytes(int index);
	}

	/**
	 * Protobuf type {@code caffe.NetStateRule}
	 */
	public static final class NetStateRule extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.NetStateRule)
			NetStateRuleOrBuilder
	{
		// Use NetStateRule.newBuilder() to construct.
		private NetStateRule(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private NetStateRule(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final NetStateRule defaultInstance;

		public static NetStateRule getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public NetStateRule getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private NetStateRule(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							phase_ = value;
						}
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						minLevel_ = input.readInt32();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						maxLevel_ = input.readInt32();
						break;
					}
					case 34:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008))
						{
							stage_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000008;
						}
						stage_.add(bs);
						break;
					}
					case 42:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000010) == 0x00000010))
						{
							notStage_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000010;
						}
						notStage_.add(bs);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000008) == 0x00000008))
				{
					stage_ = stage_.getUnmodifiableView();
				}
				if (((mutable_bitField0_ & 0x00000010) == 0x00000010))
				{
					notStage_ = notStage_.getUnmodifiableView();
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetStateRule_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetStateRule_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder.class);
		}

		public static com.google.protobuf.Parser<NetStateRule> PARSER =
				new com.google.protobuf.AbstractParser<NetStateRule>()
				{
					@Override
					public NetStateRule parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new NetStateRule(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<NetStateRule> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int PHASE_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase phase_;

		/**
		 * <code>optional .caffe.Phase phase = 1;</code>
		 *
		 * <pre>
		 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
		 * to meet this rule.
		 * </pre>
		 */
		@Override
		public boolean hasPhase()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.Phase phase = 1;</code>
		 *
		 * <pre>
		 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
		 * to meet this rule.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase getPhase()
		{
			return phase_;
		}

		public static final int MIN_LEVEL_FIELD_NUMBER = 2;
		private int minLevel_;

		/**
		 * <code>optional int32 min_level = 2;</code>
		 *
		 * <pre>
		 * Set the minimum and/or maximum levels in which the layer should be used.
		 * Leave undefined to meet the rule regardless of level.
		 * </pre>
		 */
		@Override
		public boolean hasMinLevel()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional int32 min_level = 2;</code>
		 *
		 * <pre>
		 * Set the minimum and/or maximum levels in which the layer should be used.
		 * Leave undefined to meet the rule regardless of level.
		 * </pre>
		 */
		@Override
		public int getMinLevel()
		{
			return minLevel_;
		}

		public static final int MAX_LEVEL_FIELD_NUMBER = 3;
		private int maxLevel_;

		/**
		 * <code>optional int32 max_level = 3;</code>
		 */
		@Override
		public boolean hasMaxLevel()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional int32 max_level = 3;</code>
		 */
		@Override
		public int getMaxLevel()
		{
			return maxLevel_;
		}

		public static final int STAGE_FIELD_NUMBER = 4;
		private com.google.protobuf.LazyStringList stage_;

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getStageList()
		{
			return stage_;
		}

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		@Override
		public int getStageCount()
		{
			return stage_.size();
		}

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		@Override
		public java.lang.String getStage(int index)
		{
			return stage_.get(index);
		}

		/**
		 * <code>repeated string stage = 4;</code>
		 *
		 * <pre>
		 * Customizable sets of stages to include or exclude.
		 * The net must have ALL of the specified stages and NONE of the specified
		 * "not_stage"s to meet the rule.
		 * (Use multiple NetStateRules to specify conjunctions of stages.)
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getStageBytes(int index)
		{
			return stage_.getByteString(index);
		}

		public static final int NOT_STAGE_FIELD_NUMBER = 5;
		private com.google.protobuf.LazyStringList notStage_;

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getNotStageList()
		{
			return notStage_;
		}

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		@Override
		public int getNotStageCount()
		{
			return notStage_.size();
		}

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		@Override
		public java.lang.String getNotStage(int index)
		{
			return notStage_.get(index);
		}

		/**
		 * <code>repeated string not_stage = 5;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getNotStageBytes(int index)
		{
			return notStage_.getByteString(index);
		}

		private void initFields()
		{
			phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TRAIN;
			minLevel_ = 0;
			maxLevel_ = 0;
			stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
			notStage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, phase_.getNumber());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeInt32(2, minLevel_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeInt32(3, maxLevel_);
			}
			for (int i = 0; i < stage_.size(); i++)
			{
				output.writeBytes(4, stage_.getByteString(i));
			}
			for (int i = 0; i < notStage_.size(); i++)
			{
				output.writeBytes(5, notStage_.getByteString(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, phase_.getNumber());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(2, minLevel_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(3, maxLevel_);
			}
			{
				int dataSize = 0;
				for (int i = 0; i < stage_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(stage_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getStageList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < notStage_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(notStage_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getNotStageList().size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.NetStateRule}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.NetStateRule)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetStateRule_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetStateRule_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TRAIN;
				bitField0_ = (bitField0_ & ~0x00000001);
				minLevel_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				maxLevel_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000008);
				notStage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000010);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_NetStateRule_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.phase_ = phase_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.minLevel_ = minLevel_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.maxLevel_ = maxLevel_;
				if (((bitField0_ & 0x00000008) == 0x00000008))
				{
					stage_ = stage_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000008);
				}
				result.stage_ = stage_;
				if (((bitField0_ & 0x00000010) == 0x00000010))
				{
					notStage_ = notStage_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000010);
				}
				result.notStage_ = notStage_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.getDefaultInstance())
					return this;
				if (other.hasPhase())
				{
					setPhase(other.getPhase());
				}
				if (other.hasMinLevel())
				{
					setMinLevel(other.getMinLevel());
				}
				if (other.hasMaxLevel())
				{
					setMaxLevel(other.getMaxLevel());
				}
				if (!other.stage_.isEmpty())
				{
					if (stage_.isEmpty())
					{
						stage_ = other.stage_;
						bitField0_ = (bitField0_ & ~0x00000008);
					} else
					{
						ensureStageIsMutable();
						stage_.addAll(other.stage_);
					}
					onChanged();
				}
				if (!other.notStage_.isEmpty())
				{
					if (notStage_.isEmpty())
					{
						notStage_ = other.notStage_;
						bitField0_ = (bitField0_ & ~0x00000010);
					} else
					{
						ensureNotStageIsMutable();
						notStage_.addAll(other.notStage_);
					}
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TRAIN;

			/**
			 * <code>optional .caffe.Phase phase = 1;</code>
			 *
			 * <pre>
			 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
			 * to meet this rule.
			 * </pre>
			 */
			@Override
			public boolean hasPhase()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.Phase phase = 1;</code>
			 *
			 * <pre>
			 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
			 * to meet this rule.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase getPhase()
			{
				return phase_;
			}

			/**
			 * <code>optional .caffe.Phase phase = 1;</code>
			 *
			 * <pre>
			 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
			 * to meet this rule.
			 * </pre>
			 */
			public Builder setPhase(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				phase_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.Phase phase = 1;</code>
			 *
			 * <pre>
			 * Set phase to require the NetState have a particular phase (TRAIN or TEST)
			 * to meet this rule.
			 * </pre>
			 */
			public Builder clearPhase()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				phase_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.Phase.TRAIN;
				onChanged();
				return this;
			}

			private int minLevel_;

			/**
			 * <code>optional int32 min_level = 2;</code>
			 *
			 * <pre>
			 * Set the minimum and/or maximum levels in which the layer should be used.
			 * Leave undefined to meet the rule regardless of level.
			 * </pre>
			 */
			@Override
			public boolean hasMinLevel()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional int32 min_level = 2;</code>
			 *
			 * <pre>
			 * Set the minimum and/or maximum levels in which the layer should be used.
			 * Leave undefined to meet the rule regardless of level.
			 * </pre>
			 */
			@Override
			public int getMinLevel()
			{
				return minLevel_;
			}

			/**
			 * <code>optional int32 min_level = 2;</code>
			 *
			 * <pre>
			 * Set the minimum and/or maximum levels in which the layer should be used.
			 * Leave undefined to meet the rule regardless of level.
			 * </pre>
			 */
			public Builder setMinLevel(int value)
			{
				bitField0_ |= 0x00000002;
				minLevel_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 min_level = 2;</code>
			 *
			 * <pre>
			 * Set the minimum and/or maximum levels in which the layer should be used.
			 * Leave undefined to meet the rule regardless of level.
			 * </pre>
			 */
			public Builder clearMinLevel()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				minLevel_ = 0;
				onChanged();
				return this;
			}

			private int maxLevel_;

			/**
			 * <code>optional int32 max_level = 3;</code>
			 */
			@Override
			public boolean hasMaxLevel()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional int32 max_level = 3;</code>
			 */
			@Override
			public int getMaxLevel()
			{
				return maxLevel_;
			}

			/**
			 * <code>optional int32 max_level = 3;</code>
			 */
			public Builder setMaxLevel(int value)
			{
				bitField0_ |= 0x00000004;
				maxLevel_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 max_level = 3;</code>
			 */
			public Builder clearMaxLevel()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				maxLevel_ = 0;
				onChanged();
				return this;
			}

			private com.google.protobuf.LazyStringList stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureStageIsMutable()
			{
				if (!((bitField0_ & 0x00000008) == 0x00000008))
				{
					stage_ = new com.google.protobuf.LazyStringArrayList(stage_);
					bitField0_ |= 0x00000008;
				}
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getStageList()
			{
				return stage_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			@Override
			public int getStageCount()
			{
				return stage_.size();
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			@Override
			public java.lang.String getStage(int index)
			{
				return stage_.get(index);
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getStageBytes(int index)
			{
				return stage_.getByteString(index);
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			public Builder setStage(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureStageIsMutable();
				stage_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			public Builder addStage(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureStageIsMutable();
				stage_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			public Builder addAllStage(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureStageIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, stage_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			public Builder clearStage()
			{
				stage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000008);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string stage = 4;</code>
			 *
			 * <pre>
			 * Customizable sets of stages to include or exclude.
			 * The net must have ALL of the specified stages and NONE of the specified
			 * "not_stage"s to meet the rule.
			 * (Use multiple NetStateRules to specify conjunctions of stages.)
			 * </pre>
			 */
			public Builder addStageBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureStageIsMutable();
				stage_.add(value);
				onChanged();
				return this;
			}

			private com.google.protobuf.LazyStringList notStage_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureNotStageIsMutable()
			{
				if (!((bitField0_ & 0x00000010) == 0x00000010))
				{
					notStage_ = new com.google.protobuf.LazyStringArrayList(notStage_);
					bitField0_ |= 0x00000010;
				}
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getNotStageList()
			{
				return notStage_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			@Override
			public int getNotStageCount()
			{
				return notStage_.size();
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			@Override
			public java.lang.String getNotStage(int index)
			{
				return notStage_.get(index);
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getNotStageBytes(int index)
			{
				return notStage_.getByteString(index);
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			public Builder setNotStage(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureNotStageIsMutable();
				notStage_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			public Builder addNotStage(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureNotStageIsMutable();
				notStage_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			public Builder addAllNotStage(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureNotStageIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, notStage_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			public Builder clearNotStage()
			{
				notStage_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000010);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string not_stage = 5;</code>
			 */
			public Builder addNotStageBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureNotStageIsMutable();
				notStage_.add(value);
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.NetStateRule)
		}

		static
		{
			defaultInstance = new NetStateRule(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.NetStateRule)
	}

	public interface LayerParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.LayerParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		com.google.protobuf.ProtocolStringList
				getBottomList();

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		int getBottomCount();

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		java.lang.String getBottom(int index);

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getBottomBytes(int index);

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		com.google.protobuf.ProtocolStringList
				getTopList();

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		int getTopCount();

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		java.lang.String getTop(int index);

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getTopBytes(int index);

		/**
		 * <code>optional string name = 4;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		boolean hasName();

		/**
		 * <code>optional string name = 4;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		java.lang.String getName();

		/**
		 * <code>optional string name = 4;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getNameBytes();

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule>
				getIncludeList();

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getInclude(int index);

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		int getIncludeCount();

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
				getIncludeOrBuilderList();

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder getIncludeOrBuilder(
				int index);

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule>
				getExcludeList();

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getExclude(int index);

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		int getExcludeCount();

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
				getExcludeOrBuilderList();

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder getExcludeOrBuilder(
				int index);

		/**
		 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
		 *
		 * <pre>
		 * the layer type from the enum above
		 * </pre>
		 */
		boolean hasType();

		/**
		 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
		 *
		 * <pre>
		 * the layer type from the enum above
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType getType();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>
				getBlobsList();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index);

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		int getBlobsCount();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getBlobsOrBuilderList();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
				int index);

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		com.google.protobuf.ProtocolStringList
				getParamList();

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		int getParamCount();

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		java.lang.String getParam(int index);

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getParamBytes(int index);

		/**
		 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
		 *
		 * <pre>
		 * Whether to require shared weights to have the same shape, or just the same
		 * count -- defaults to STRICT if unspecified.
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode> getBlobShareModeList();

		/**
		 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
		 *
		 * <pre>
		 * Whether to require shared weights to have the same shape, or just the same
		 * count -- defaults to STRICT if unspecified.
		 * </pre>
		 */
		int getBlobShareModeCount();

		/**
		 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
		 *
		 * <pre>
		 * Whether to require shared weights to have the same shape, or just the same
		 * count -- defaults to STRICT if unspecified.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode getBlobShareMode(int index);

		/**
		 * <code>repeated float blobs_lr = 7;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		java.util.List<java.lang.Float> getBlobsLrList();

		/**
		 * <code>repeated float blobs_lr = 7;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		int getBlobsLrCount();

		/**
		 * <code>repeated float blobs_lr = 7;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		float getBlobsLr(int index);

		/**
		 * <code>repeated float weight_decay = 8;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		java.util.List<java.lang.Float> getWeightDecayList();

		/**
		 * <code>repeated float weight_decay = 8;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		int getWeightDecayCount();

		/**
		 * <code>repeated float weight_decay = 8;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		float getWeightDecay(int index);

		/**
		 * <code>repeated float loss_weight = 35;</code>
		 *
		 * <pre>
		 * The amount of weight to assign each top blob in the objective.
		 * Each layer assigns a default value, usually of either 0 or 1,
		 * to each top blob.
		 * </pre>
		 */
		java.util.List<java.lang.Float> getLossWeightList();

		/**
		 * <code>repeated float loss_weight = 35;</code>
		 *
		 * <pre>
		 * The amount of weight to assign each top blob in the objective.
		 * Each layer assigns a default value, usually of either 0 or 1,
		 * to each top blob.
		 * </pre>
		 */
		int getLossWeightCount();

		/**
		 * <code>repeated float loss_weight = 35;</code>
		 *
		 * <pre>
		 * The amount of weight to assign each top blob in the objective.
		 * Each layer assigns a default value, usually of either 0 or 1,
		 * to each top blob.
		 * </pre>
		 */
		float getLossWeight(int index);

		/**
		 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
		 */
		boolean hasAccuracyParam();

		/**
		 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter getAccuracyParam();

		/**
		 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder getAccuracyParamOrBuilder();

		/**
		 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
		 */
		boolean hasArgmaxParam();

		/**
		 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter getArgmaxParam();

		/**
		 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder getArgmaxParamOrBuilder();

		/**
		 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
		 */
		boolean hasConcatParam();

		/**
		 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter getConcatParam();

		/**
		 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder getConcatParamOrBuilder();

		/**
		 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
		 */
		boolean hasContrastiveLossParam();

		/**
		 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter getContrastiveLossParam();

		/**
		 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder getContrastiveLossParamOrBuilder();

		/**
		 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
		 */
		boolean hasConvolutionParam();

		/**
		 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter getConvolutionParam();

		/**
		 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder getConvolutionParamOrBuilder();

		/**
		 * <code>optional .caffe.DataParameter data_param = 11;</code>
		 */
		boolean hasDataParam();

		/**
		 * <code>optional .caffe.DataParameter data_param = 11;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter getDataParam();

		/**
		 * <code>optional .caffe.DataParameter data_param = 11;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder getDataParamOrBuilder();

		/**
		 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
		 */
		boolean hasDropoutParam();

		/**
		 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter getDropoutParam();

		/**
		 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder getDropoutParamOrBuilder();

		/**
		 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
		 */
		boolean hasDummyDataParam();

		/**
		 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter getDummyDataParam();

		/**
		 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder getDummyDataParamOrBuilder();

		/**
		 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
		 */
		boolean hasEltwiseParam();

		/**
		 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter getEltwiseParam();

		/**
		 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder getEltwiseParamOrBuilder();

		/**
		 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
		 */
		boolean hasHdf5DataParam();

		/**
		 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter getHdf5DataParam();

		/**
		 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder getHdf5DataParamOrBuilder();

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
		 */
		boolean hasHdf5OutputParam();

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getHdf5OutputParam();

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder getHdf5OutputParamOrBuilder();

		/**
		 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
		 */
		boolean hasHingeLossParam();

		/**
		 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter getHingeLossParam();

		/**
		 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder getHingeLossParamOrBuilder();

		/**
		 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
		 */
		boolean hasImageDataParam();

		/**
		 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter getImageDataParam();

		/**
		 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder getImageDataParamOrBuilder();

		/**
		 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
		 */
		boolean hasInfogainLossParam();

		/**
		 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter getInfogainLossParam();

		/**
		 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder getInfogainLossParamOrBuilder();

		/**
		 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
		 */
		boolean hasInnerProductParam();

		/**
		 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter getInnerProductParam();

		/**
		 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder getInnerProductParamOrBuilder();

		/**
		 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
		 */
		boolean hasLrnParam();

		/**
		 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter getLrnParam();

		/**
		 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder getLrnParamOrBuilder();

		/**
		 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
		 */
		boolean hasMemoryDataParam();

		/**
		 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter getMemoryDataParam();

		/**
		 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder getMemoryDataParamOrBuilder();

		/**
		 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
		 */
		boolean hasMvnParam();

		/**
		 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter getMvnParam();

		/**
		 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder getMvnParamOrBuilder();

		/**
		 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
		 */
		boolean hasPoolingParam();

		/**
		 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter getPoolingParam();

		/**
		 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder getPoolingParamOrBuilder();

		/**
		 * <code>optional .caffe.PowerParameter power_param = 21;</code>
		 */
		boolean hasPowerParam();

		/**
		 * <code>optional .caffe.PowerParameter power_param = 21;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter getPowerParam();

		/**
		 * <code>optional .caffe.PowerParameter power_param = 21;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder getPowerParamOrBuilder();

		/**
		 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
		 */
		boolean hasReluParam();

		/**
		 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter getReluParam();

		/**
		 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder getReluParamOrBuilder();

		/**
		 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
		 */
		boolean hasSigmoidParam();

		/**
		 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter getSigmoidParam();

		/**
		 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder getSigmoidParamOrBuilder();

		/**
		 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
		 */
		boolean hasSoftmaxParam();

		/**
		 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter getSoftmaxParam();

		/**
		 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder getSoftmaxParamOrBuilder();

		/**
		 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
		 */
		boolean hasSliceParam();

		/**
		 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter getSliceParam();

		/**
		 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder getSliceParamOrBuilder();

		/**
		 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
		 */
		boolean hasTanhParam();

		/**
		 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter getTanhParam();

		/**
		 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder getTanhParamOrBuilder();

		/**
		 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
		 */
		boolean hasThresholdParam();

		/**
		 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter getThresholdParam();

		/**
		 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder getThresholdParamOrBuilder();

		/**
		 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
		 */
		boolean hasWindowDataParam();

		/**
		 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter getWindowDataParam();

		/**
		 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder getWindowDataParamOrBuilder();

		/**
		 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
		 *
		 * <pre>
		 * Parameters for data pre-processing.
		 * </pre>
		 */
		boolean hasTransformParam();

		/**
		 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
		 *
		 * <pre>
		 * Parameters for data pre-processing.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter getTransformParam();

		/**
		 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
		 *
		 * <pre>
		 * Parameters for data pre-processing.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder getTransformParamOrBuilder();

		/**
		 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
		 *
		 * <pre>
		 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
		 * This should never be used by any code except to upgrade to the new
		 * LayerParameter specification.
		 * </pre>
		 */
		boolean hasLayer();

		/**
		 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
		 *
		 * <pre>
		 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
		 * This should never be used by any code except to upgrade to the new
		 * LayerParameter specification.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter getLayer();

		/**
		 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
		 *
		 * <pre>
		 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
		 * This should never be used by any code except to upgrade to the new
		 * LayerParameter specification.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder getLayerOrBuilder();
	}

	/**
	 * Protobuf type {@code caffe.LayerParameter}
	 *
	 * <pre>
	 * NOTE
	 * Update the next available ID when you add a new LayerParameter field.
	 * LayerParameter next available ID: 41 (last added: contrastive_loss_param)
	 * </pre>
	 */
	public static final class LayerParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.LayerParameter)
			LayerParameterOrBuilder
	{
		// Use LayerParameter.newBuilder() to construct.
		private LayerParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private LayerParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final LayerParameter defaultInstance;

		public static LayerParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public LayerParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private LayerParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			int mutable_bitField1_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x40000000) == 0x40000000))
						{
							subBuilder = layer_.toBuilder();
						}
						layer_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(layer_);
							layer_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x40000000;
						break;
					}
					case 18:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000001) == 0x00000001))
						{
							bottom_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000001;
						}
						bottom_.add(bs);
						break;
					}
					case 26:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002))
						{
							top_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000002;
						}
						top_.add(bs);
						break;
					}
					case 34:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						name_ = bs;
						break;
					}
					case 40:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(5, rawValue);
						} else
						{
							bitField0_ |= 0x00000002;
							type_ = value;
						}
						break;
					}
					case 50:
					{
						if (!((mutable_bitField0_ & 0x00000040) == 0x00000040))
						{
							blobs_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>();
							mutable_bitField0_ |= 0x00000040;
						}
						blobs_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.PARSER, extensionRegistry));
						break;
					}
					case 61:
					{
						if (!((mutable_bitField0_ & 0x00000200) == 0x00000200))
						{
							blobsLr_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000200;
						}
						blobsLr_.add(input.readFloat());
						break;
					}
					case 58:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000200) == 0x00000200) && input.getBytesUntilLimit() > 0)
						{
							blobsLr_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000200;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							blobsLr_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 69:
					{
						if (!((mutable_bitField0_ & 0x00000400) == 0x00000400))
						{
							weightDecay_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000400;
						}
						weightDecay_.add(input.readFloat());
						break;
					}
					case 66:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000400) == 0x00000400) && input.getBytesUntilLimit() > 0)
						{
							weightDecay_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000400;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							weightDecay_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 74:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000010) == 0x00000010))
						{
							subBuilder = concatParam_.toBuilder();
						}
						concatParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(concatParam_);
							concatParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000010;
						break;
					}
					case 82:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000040) == 0x00000040))
						{
							subBuilder = convolutionParam_.toBuilder();
						}
						convolutionParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(convolutionParam_);
							convolutionParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000040;
						break;
					}
					case 90:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000080) == 0x00000080))
						{
							subBuilder = dataParam_.toBuilder();
						}
						dataParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(dataParam_);
							dataParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000080;
						break;
					}
					case 98:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000100) == 0x00000100))
						{
							subBuilder = dropoutParam_.toBuilder();
						}
						dropoutParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(dropoutParam_);
							dropoutParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000100;
						break;
					}
					case 106:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000800) == 0x00000800))
						{
							subBuilder = hdf5DataParam_.toBuilder();
						}
						hdf5DataParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(hdf5DataParam_);
							hdf5DataParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000800;
						break;
					}
					case 114:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00001000) == 0x00001000))
						{
							subBuilder = hdf5OutputParam_.toBuilder();
						}
						hdf5OutputParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(hdf5OutputParam_);
							hdf5OutputParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00001000;
						break;
					}
					case 122:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00004000) == 0x00004000))
						{
							subBuilder = imageDataParam_.toBuilder();
						}
						imageDataParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(imageDataParam_);
							imageDataParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00004000;
						break;
					}
					case 130:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00008000) == 0x00008000))
						{
							subBuilder = infogainLossParam_.toBuilder();
						}
						infogainLossParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(infogainLossParam_);
							infogainLossParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00008000;
						break;
					}
					case 138:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00010000) == 0x00010000))
						{
							subBuilder = innerProductParam_.toBuilder();
						}
						innerProductParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(innerProductParam_);
							innerProductParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00010000;
						break;
					}
					case 146:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00020000) == 0x00020000))
						{
							subBuilder = lrnParam_.toBuilder();
						}
						lrnParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(lrnParam_);
							lrnParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00020000;
						break;
					}
					case 154:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00100000) == 0x00100000))
						{
							subBuilder = poolingParam_.toBuilder();
						}
						poolingParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(poolingParam_);
							poolingParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00100000;
						break;
					}
					case 162:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x10000000) == 0x10000000))
						{
							subBuilder = windowDataParam_.toBuilder();
						}
						windowDataParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(windowDataParam_);
							windowDataParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x10000000;
						break;
					}
					case 170:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00200000) == 0x00200000))
						{
							subBuilder = powerParam_.toBuilder();
						}
						powerParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(powerParam_);
							powerParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00200000;
						break;
					}
					case 178:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00040000) == 0x00040000))
						{
							subBuilder = memoryDataParam_.toBuilder();
						}
						memoryDataParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(memoryDataParam_);
							memoryDataParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00040000;
						break;
					}
					case 186:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000008) == 0x00000008))
						{
							subBuilder = argmaxParam_.toBuilder();
						}
						argmaxParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(argmaxParam_);
							argmaxParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000008;
						break;
					}
					case 194:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000400) == 0x00000400))
						{
							subBuilder = eltwiseParam_.toBuilder();
						}
						eltwiseParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(eltwiseParam_);
							eltwiseParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000400;
						break;
					}
					case 202:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x08000000) == 0x08000000))
						{
							subBuilder = thresholdParam_.toBuilder();
						}
						thresholdParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(thresholdParam_);
							thresholdParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x08000000;
						break;
					}
					case 210:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000200) == 0x00000200))
						{
							subBuilder = dummyDataParam_.toBuilder();
						}
						dummyDataParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(dummyDataParam_);
							dummyDataParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000200;
						break;
					}
					case 218:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000004) == 0x00000004))
						{
							subBuilder = accuracyParam_.toBuilder();
						}
						accuracyParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(accuracyParam_);
							accuracyParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000004;
						break;
					}
					case 234:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00002000) == 0x00002000))
						{
							subBuilder = hingeLossParam_.toBuilder();
						}
						hingeLossParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(hingeLossParam_);
							hingeLossParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00002000;
						break;
					}
					case 242:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00400000) == 0x00400000))
						{
							subBuilder = reluParam_.toBuilder();
						}
						reluParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(reluParam_);
							reluParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00400000;
						break;
					}
					case 250:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x02000000) == 0x02000000))
						{
							subBuilder = sliceParam_.toBuilder();
						}
						sliceParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(sliceParam_);
							sliceParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x02000000;
						break;
					}
					case 258:
					{
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008))
						{
							include_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule>();
							mutable_bitField0_ |= 0x00000008;
						}
						include_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.PARSER, extensionRegistry));
						break;
					}
					case 266:
					{
						if (!((mutable_bitField0_ & 0x00000010) == 0x00000010))
						{
							exclude_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule>();
							mutable_bitField0_ |= 0x00000010;
						}
						exclude_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.PARSER, extensionRegistry));
						break;
					}
					case 274:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00080000) == 0x00080000))
						{
							subBuilder = mvnParam_.toBuilder();
						}
						mvnParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(mvnParam_);
							mvnParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00080000;
						break;
					}
					case 285:
					{
						if (!((mutable_bitField0_ & 0x00000800) == 0x00000800))
						{
							lossWeight_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000800;
						}
						lossWeight_.add(input.readFloat());
						break;
					}
					case 282:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000800) == 0x00000800) && input.getBytesUntilLimit() > 0)
						{
							lossWeight_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000800;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							lossWeight_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 290:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x20000000) == 0x20000000))
						{
							subBuilder = transformParam_.toBuilder();
						}
						transformParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(transformParam_);
							transformParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x20000000;
						break;
					}
					case 298:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x04000000) == 0x04000000))
						{
							subBuilder = tanhParam_.toBuilder();
						}
						tanhParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(tanhParam_);
							tanhParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x04000000;
						break;
					}
					case 306:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00800000) == 0x00800000))
						{
							subBuilder = sigmoidParam_.toBuilder();
						}
						sigmoidParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(sigmoidParam_);
							sigmoidParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00800000;
						break;
					}
					case 314:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x01000000) == 0x01000000))
						{
							subBuilder = softmaxParam_.toBuilder();
						}
						softmaxParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(softmaxParam_);
							softmaxParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x01000000;
						break;
					}
					case 322:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000020) == 0x00000020))
						{
							subBuilder = contrastiveLossParam_.toBuilder();
						}
						contrastiveLossParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(contrastiveLossParam_);
							contrastiveLossParam_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000020;
						break;
					}
					case 8010:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						if (!((mutable_bitField0_ & 0x00000080) == 0x00000080))
						{
							param_ = new com.google.protobuf.LazyStringArrayList();
							mutable_bitField0_ |= 0x00000080;
						}
						param_.add(bs);
						break;
					}
					case 8016:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1002, rawValue);
						} else
						{
							if (!((mutable_bitField0_ & 0x00000100) == 0x00000100))
							{
								blobShareMode_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode>();
								mutable_bitField0_ |= 0x00000100;
							}
							blobShareMode_.add(value);
						}
						break;
					}
					case 8018:
					{
						int length = input.readRawVarint32();
						int oldLimit = input.pushLimit(length);
						while (input.getBytesUntilLimit() > 0)
						{
							int rawValue = input.readEnum();
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode
									.valueOf(rawValue);
							if (value == null)
							{
								unknownFields.mergeVarintField(1002, rawValue);
							} else
							{
								if (!((mutable_bitField0_ & 0x00000100) == 0x00000100))
								{
									blobShareMode_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode>();
									mutable_bitField0_ |= 0x00000100;
								}
								blobShareMode_.add(value);
							}
						}
						input.popLimit(oldLimit);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000001) == 0x00000001))
				{
					bottom_ = bottom_.getUnmodifiableView();
				}
				if (((mutable_bitField0_ & 0x00000002) == 0x00000002))
				{
					top_ = top_.getUnmodifiableView();
				}
				if (((mutable_bitField0_ & 0x00000040) == 0x00000040))
				{
					blobs_ = java.util.Collections.unmodifiableList(blobs_);
				}
				if (((mutable_bitField0_ & 0x00000200) == 0x00000200))
				{
					blobsLr_ = java.util.Collections.unmodifiableList(blobsLr_);
				}
				if (((mutable_bitField0_ & 0x00000400) == 0x00000400))
				{
					weightDecay_ = java.util.Collections.unmodifiableList(weightDecay_);
				}
				if (((mutable_bitField0_ & 0x00000008) == 0x00000008))
				{
					include_ = java.util.Collections.unmodifiableList(include_);
				}
				if (((mutable_bitField0_ & 0x00000010) == 0x00000010))
				{
					exclude_ = java.util.Collections.unmodifiableList(exclude_);
				}
				if (((mutable_bitField0_ & 0x00000800) == 0x00000800))
				{
					lossWeight_ = java.util.Collections.unmodifiableList(lossWeight_);
				}
				if (((mutable_bitField0_ & 0x00000080) == 0x00000080))
				{
					param_ = param_.getUnmodifiableView();
				}
				if (((mutable_bitField0_ & 0x00000100) == 0x00000100))
				{
					blobShareMode_ = java.util.Collections.unmodifiableList(blobShareMode_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LayerParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LayerParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<LayerParameter> PARSER =
				new com.google.protobuf.AbstractParser<LayerParameter>()
				{
					@Override
					public LayerParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new LayerParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<LayerParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.LayerParameter.LayerType}
		 *
		 * <pre>
		 * NOTE
		 * Add new LayerTypes to the enum below in lexicographical order (other than
		 * starting with NONE), starting with the next available ID in the comment
		 * line above the enum. Update the next available ID when you add a new
		 * LayerType.
		 * LayerType next available ID: 38 (last added: CONTRASTIVE_LOSS)
		 * </pre>
		 */
		public enum LayerType
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>NONE = 0;</code>
			 *
			 * <pre>
			 * "NONE" layer type is 0th enum element so that we don't cause confusion
			 * by defaulting to an existent LayerType (instead, should usually error if
			 * the type is unspecified).
			 * </pre>
			 */
			NONE(0, 0),
			/**
			 * <code>ABSVAL = 35;</code>
			 */
			ABSVAL(1, 35),
			/**
			 * <code>ACCURACY = 1;</code>
			 */
			ACCURACY(2, 1),
			/**
			 * <code>ARGMAX = 30;</code>
			 */
			ARGMAX(3, 30),
			/**
			 * <code>BNLL = 2;</code>
			 */
			BNLL(4, 2),
			/**
			 * <code>CONCAT = 3;</code>
			 */
			CONCAT(5, 3),
			/**
			 * <code>CONTRASTIVE_LOSS = 37;</code>
			 */
			CONTRASTIVE_LOSS(6, 37),
			/**
			 * <code>CONVOLUTION = 4;</code>
			 */
			CONVOLUTION(7, 4),
			/**
			 * <code>DATA = 5;</code>
			 */
			DATA(8, 5),
			/**
			 * <code>DROPOUT = 6;</code>
			 */
			DROPOUT(9, 6),
			/**
			 * <code>DUMMY_DATA = 32;</code>
			 */
			DUMMY_DATA(10, 32),
			/**
			 * <code>EUCLIDEAN_LOSS = 7;</code>
			 */
			EUCLIDEAN_LOSS(11, 7),
			/**
			 * <code>ELTWISE = 25;</code>
			 */
			ELTWISE(12, 25),
			/**
			 * <code>FLATTEN = 8;</code>
			 */
			FLATTEN(13, 8),
			/**
			 * <code>HDF5_DATA = 9;</code>
			 */
			HDF5_DATA(14, 9),
			/**
			 * <code>HDF5_OUTPUT = 10;</code>
			 */
			HDF5_OUTPUT(15, 10),
			/**
			 * <code>HINGE_LOSS = 28;</code>
			 */
			HINGE_LOSS(16, 28),
			/**
			 * <code>IM2COL = 11;</code>
			 */
			IM2COL(17, 11),
			/**
			 * <code>IMAGE_DATA = 12;</code>
			 */
			IMAGE_DATA(18, 12),
			/**
			 * <code>INFOGAIN_LOSS = 13;</code>
			 */
			INFOGAIN_LOSS(19, 13),
			/**
			 * <code>INNER_PRODUCT = 14;</code>
			 */
			INNER_PRODUCT(20, 14),
			/**
			 * <code>LRN = 15;</code>
			 */
			LRN(21, 15),
			/**
			 * <code>MEMORY_DATA = 29;</code>
			 */
			MEMORY_DATA(22, 29),
			/**
			 * <code>MULTINOMIAL_LOGISTIC_LOSS = 16;</code>
			 */
			MULTINOMIAL_LOGISTIC_LOSS(23, 16),
			/**
			 * <code>MVN = 34;</code>
			 */
			MVN(24, 34),
			/**
			 * <code>POOLING = 17;</code>
			 */
			POOLING(25, 17),
			/**
			 * <code>POWER = 26;</code>
			 */
			POWER(26, 26),
			/**
			 * <code>RELU = 18;</code>
			 */
			RELU(27, 18),
			/**
			 * <code>SIGMOID = 19;</code>
			 */
			SIGMOID(28, 19),
			/**
			 * <code>SIGMOID_CROSS_ENTROPY_LOSS = 27;</code>
			 */
			SIGMOID_CROSS_ENTROPY_LOSS(29, 27),
			/**
			 * <code>SILENCE = 36;</code>
			 */
			SILENCE(30, 36),
			/**
			 * <code>SOFTMAX = 20;</code>
			 */
			SOFTMAX(31, 20),
			/**
			 * <code>SOFTMAX_LOSS = 21;</code>
			 */
			SOFTMAX_LOSS(32, 21),
			/**
			 * <code>SPLIT = 22;</code>
			 */
			SPLIT(33, 22),
			/**
			 * <code>SLICE = 33;</code>
			 */
			SLICE(34, 33),
			/**
			 * <code>TANH = 23;</code>
			 */
			TANH(35, 23),
			/**
			 * <code>WINDOW_DATA = 24;</code>
			 */
			WINDOW_DATA(36, 24),
			/**
			 * <code>THRESHOLD = 31;</code>
			 */
			THRESHOLD(37, 31), ;

			/**
			 * <code>NONE = 0;</code>
			 *
			 * <pre>
			 * "NONE" layer type is 0th enum element so that we don't cause confusion
			 * by defaulting to an existent LayerType (instead, should usually error if
			 * the type is unspecified).
			 * </pre>
			 */
			public static final int NONE_VALUE = 0;
			/**
			 * <code>ABSVAL = 35;</code>
			 */
			public static final int ABSVAL_VALUE = 35;
			/**
			 * <code>ACCURACY = 1;</code>
			 */
			public static final int ACCURACY_VALUE = 1;
			/**
			 * <code>ARGMAX = 30;</code>
			 */
			public static final int ARGMAX_VALUE = 30;
			/**
			 * <code>BNLL = 2;</code>
			 */
			public static final int BNLL_VALUE = 2;
			/**
			 * <code>CONCAT = 3;</code>
			 */
			public static final int CONCAT_VALUE = 3;
			/**
			 * <code>CONTRASTIVE_LOSS = 37;</code>
			 */
			public static final int CONTRASTIVE_LOSS_VALUE = 37;
			/**
			 * <code>CONVOLUTION = 4;</code>
			 */
			public static final int CONVOLUTION_VALUE = 4;
			/**
			 * <code>DATA = 5;</code>
			 */
			public static final int DATA_VALUE = 5;
			/**
			 * <code>DROPOUT = 6;</code>
			 */
			public static final int DROPOUT_VALUE = 6;
			/**
			 * <code>DUMMY_DATA = 32;</code>
			 */
			public static final int DUMMY_DATA_VALUE = 32;
			/**
			 * <code>EUCLIDEAN_LOSS = 7;</code>
			 */
			public static final int EUCLIDEAN_LOSS_VALUE = 7;
			/**
			 * <code>ELTWISE = 25;</code>
			 */
			public static final int ELTWISE_VALUE = 25;
			/**
			 * <code>FLATTEN = 8;</code>
			 */
			public static final int FLATTEN_VALUE = 8;
			/**
			 * <code>HDF5_DATA = 9;</code>
			 */
			public static final int HDF5_DATA_VALUE = 9;
			/**
			 * <code>HDF5_OUTPUT = 10;</code>
			 */
			public static final int HDF5_OUTPUT_VALUE = 10;
			/**
			 * <code>HINGE_LOSS = 28;</code>
			 */
			public static final int HINGE_LOSS_VALUE = 28;
			/**
			 * <code>IM2COL = 11;</code>
			 */
			public static final int IM2COL_VALUE = 11;
			/**
			 * <code>IMAGE_DATA = 12;</code>
			 */
			public static final int IMAGE_DATA_VALUE = 12;
			/**
			 * <code>INFOGAIN_LOSS = 13;</code>
			 */
			public static final int INFOGAIN_LOSS_VALUE = 13;
			/**
			 * <code>INNER_PRODUCT = 14;</code>
			 */
			public static final int INNER_PRODUCT_VALUE = 14;
			/**
			 * <code>LRN = 15;</code>
			 */
			public static final int LRN_VALUE = 15;
			/**
			 * <code>MEMORY_DATA = 29;</code>
			 */
			public static final int MEMORY_DATA_VALUE = 29;
			/**
			 * <code>MULTINOMIAL_LOGISTIC_LOSS = 16;</code>
			 */
			public static final int MULTINOMIAL_LOGISTIC_LOSS_VALUE = 16;
			/**
			 * <code>MVN = 34;</code>
			 */
			public static final int MVN_VALUE = 34;
			/**
			 * <code>POOLING = 17;</code>
			 */
			public static final int POOLING_VALUE = 17;
			/**
			 * <code>POWER = 26;</code>
			 */
			public static final int POWER_VALUE = 26;
			/**
			 * <code>RELU = 18;</code>
			 */
			public static final int RELU_VALUE = 18;
			/**
			 * <code>SIGMOID = 19;</code>
			 */
			public static final int SIGMOID_VALUE = 19;
			/**
			 * <code>SIGMOID_CROSS_ENTROPY_LOSS = 27;</code>
			 */
			public static final int SIGMOID_CROSS_ENTROPY_LOSS_VALUE = 27;
			/**
			 * <code>SILENCE = 36;</code>
			 */
			public static final int SILENCE_VALUE = 36;
			/**
			 * <code>SOFTMAX = 20;</code>
			 */
			public static final int SOFTMAX_VALUE = 20;
			/**
			 * <code>SOFTMAX_LOSS = 21;</code>
			 */
			public static final int SOFTMAX_LOSS_VALUE = 21;
			/**
			 * <code>SPLIT = 22;</code>
			 */
			public static final int SPLIT_VALUE = 22;
			/**
			 * <code>SLICE = 33;</code>
			 */
			public static final int SLICE_VALUE = 33;
			/**
			 * <code>TANH = 23;</code>
			 */
			public static final int TANH_VALUE = 23;
			/**
			 * <code>WINDOW_DATA = 24;</code>
			 */
			public static final int WINDOW_DATA_VALUE = 24;
			/**
			 * <code>THRESHOLD = 31;</code>
			 */
			public static final int THRESHOLD_VALUE = 31;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static LayerType valueOf(int value)
			{
				switch (value) {
				case 0:
					return NONE;
				case 35:
					return ABSVAL;
				case 1:
					return ACCURACY;
				case 30:
					return ARGMAX;
				case 2:
					return BNLL;
				case 3:
					return CONCAT;
				case 37:
					return CONTRASTIVE_LOSS;
				case 4:
					return CONVOLUTION;
				case 5:
					return DATA;
				case 6:
					return DROPOUT;
				case 32:
					return DUMMY_DATA;
				case 7:
					return EUCLIDEAN_LOSS;
				case 25:
					return ELTWISE;
				case 8:
					return FLATTEN;
				case 9:
					return HDF5_DATA;
				case 10:
					return HDF5_OUTPUT;
				case 28:
					return HINGE_LOSS;
				case 11:
					return IM2COL;
				case 12:
					return IMAGE_DATA;
				case 13:
					return INFOGAIN_LOSS;
				case 14:
					return INNER_PRODUCT;
				case 15:
					return LRN;
				case 29:
					return MEMORY_DATA;
				case 16:
					return MULTINOMIAL_LOGISTIC_LOSS;
				case 34:
					return MVN;
				case 17:
					return POOLING;
				case 26:
					return POWER;
				case 18:
					return RELU;
				case 19:
					return SIGMOID;
				case 27:
					return SIGMOID_CROSS_ENTROPY_LOSS;
				case 36:
					return SILENCE;
				case 20:
					return SOFTMAX;
				case 21:
					return SOFTMAX_LOSS;
				case 22:
					return SPLIT;
				case 33:
					return SLICE;
				case 23:
					return TANH;
				case 24:
					return WINDOW_DATA;
				case 31:
					return THRESHOLD;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<LayerType>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<LayerType> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<LayerType>()
					{
						@Override
						public LayerType findValueByNumber(int number)
						{
							return LayerType.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final LayerType[] VALUES = values();

			public static LayerType valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private LayerType(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.LayerParameter.LayerType)
		}

		/**
		 * Protobuf enum {@code caffe.LayerParameter.DimCheckMode}
		 */
		public enum DimCheckMode
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>STRICT = 0;</code>
			 *
			 * <pre>
			 * STRICT (default) requires that num, channels, height, width each match.
			 * </pre>
			 */
			STRICT(0, 0),
			/**
			 * <code>PERMISSIVE = 1;</code>
			 *
			 * <pre>
			 * PERMISSIVE requires only the count (num*channels*height*width) to match.
			 * </pre>
			 */
			PERMISSIVE(1, 1), ;

			/**
			 * <code>STRICT = 0;</code>
			 *
			 * <pre>
			 * STRICT (default) requires that num, channels, height, width each match.
			 * </pre>
			 */
			public static final int STRICT_VALUE = 0;
			/**
			 * <code>PERMISSIVE = 1;</code>
			 *
			 * <pre>
			 * PERMISSIVE requires only the count (num*channels*height*width) to match.
			 * </pre>
			 */
			public static final int PERMISSIVE_VALUE = 1;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static DimCheckMode valueOf(int value)
			{
				switch (value) {
				case 0:
					return STRICT;
				case 1:
					return PERMISSIVE;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<DimCheckMode>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<DimCheckMode> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<DimCheckMode>()
					{
						@Override
						public DimCheckMode findValueByNumber(int number)
						{
							return DimCheckMode.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.getDescriptor().getEnumTypes().get(1);
			}

			private static final DimCheckMode[] VALUES = values();

			public static DimCheckMode valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private DimCheckMode(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.LayerParameter.DimCheckMode)
		}

		private int bitField0_;
		public static final int BOTTOM_FIELD_NUMBER = 2;
		private com.google.protobuf.LazyStringList bottom_;

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getBottomList()
		{
			return bottom_;
		}

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		@Override
		public int getBottomCount()
		{
			return bottom_.size();
		}

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		@Override
		public java.lang.String getBottom(int index)
		{
			return bottom_.get(index);
		}

		/**
		 * <code>repeated string bottom = 2;</code>
		 *
		 * <pre>
		 * the name of the bottom blobs
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getBottomBytes(int index)
		{
			return bottom_.getByteString(index);
		}

		public static final int TOP_FIELD_NUMBER = 3;
		private com.google.protobuf.LazyStringList top_;

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getTopList()
		{
			return top_;
		}

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		@Override
		public int getTopCount()
		{
			return top_.size();
		}

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		@Override
		public java.lang.String getTop(int index)
		{
			return top_.get(index);
		}

		/**
		 * <code>repeated string top = 3;</code>
		 *
		 * <pre>
		 * the name of the top blobs
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getTopBytes(int index)
		{
			return top_.getByteString(index);
		}

		public static final int NAME_FIELD_NUMBER = 4;
		private java.lang.Object name_;

		/**
		 * <code>optional string name = 4;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		@Override
		public boolean hasName()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string name = 4;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		@Override
		public java.lang.String getName()
		{
			java.lang.Object ref = name_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					name_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string name = 4;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getNameBytes()
		{
			java.lang.Object ref = name_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				name_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int INCLUDE_FIELD_NUMBER = 32;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> include_;

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> getIncludeList()
		{
			return include_;
		}

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
				getIncludeOrBuilderList()
		{
			return include_;
		}

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		@Override
		public int getIncludeCount()
		{
			return include_.size();
		}

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getInclude(int index)
		{
			return include_.get(index);
		}

		/**
		 * <code>repeated .caffe.NetStateRule include = 32;</code>
		 *
		 * <pre>
		 * Rules controlling whether and when a layer is included in the network,
		 * based on the current NetState.  You may specify a non-zero number of rules
		 * to include OR exclude, but not both.  If no include or exclude rules are
		 * specified, the layer is always included.  If the current NetState meets
		 * ANY (i.e., one or more) of the specified rules, the layer is
		 * included/excluded.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder getIncludeOrBuilder(
				int index)
		{
			return include_.get(index);
		}

		public static final int EXCLUDE_FIELD_NUMBER = 33;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> exclude_;

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> getExcludeList()
		{
			return exclude_;
		}

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
				getExcludeOrBuilderList()
		{
			return exclude_;
		}

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		@Override
		public int getExcludeCount()
		{
			return exclude_.size();
		}

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getExclude(int index)
		{
			return exclude_.get(index);
		}

		/**
		 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder getExcludeOrBuilder(
				int index)
		{
			return exclude_.get(index);
		}

		public static final int TYPE_FIELD_NUMBER = 5;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType type_;

		/**
		 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
		 *
		 * <pre>
		 * the layer type from the enum above
		 * </pre>
		 */
		@Override
		public boolean hasType()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
		 *
		 * <pre>
		 * the layer type from the enum above
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType getType()
		{
			return type_;
		}

		public static final int BLOBS_FIELD_NUMBER = 6;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> blobs_;

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getBlobsList()
		{
			return blobs_;
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getBlobsOrBuilderList()
		{
			return blobs_;
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public int getBlobsCount()
		{
			return blobs_.size();
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index)
		{
			return blobs_.get(index);
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 6;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
				int index)
		{
			return blobs_.get(index);
		}

		public static final int PARAM_FIELD_NUMBER = 1001;
		private com.google.protobuf.LazyStringList param_;

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ProtocolStringList
				getParamList()
		{
			return param_;
		}

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		@Override
		public int getParamCount()
		{
			return param_.size();
		}

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		@Override
		public java.lang.String getParam(int index)
		{
			return param_.get(index);
		}

		/**
		 * <code>repeated string param = 1001;</code>
		 *
		 * <pre>
		 * The names of the parameter blobs -- useful for sharing parameters among
		 * layers (but never required).
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getParamBytes(int index)
		{
			return param_.getByteString(index);
		}

		public static final int BLOB_SHARE_MODE_FIELD_NUMBER = 1002;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode> blobShareMode_;

		/**
		 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
		 *
		 * <pre>
		 * Whether to require shared weights to have the same shape, or just the same
		 * count -- defaults to STRICT if unspecified.
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode> getBlobShareModeList()
		{
			return blobShareMode_;
		}

		/**
		 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
		 *
		 * <pre>
		 * Whether to require shared weights to have the same shape, or just the same
		 * count -- defaults to STRICT if unspecified.
		 * </pre>
		 */
		@Override
		public int getBlobShareModeCount()
		{
			return blobShareMode_.size();
		}

		/**
		 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
		 *
		 * <pre>
		 * Whether to require shared weights to have the same shape, or just the same
		 * count -- defaults to STRICT if unspecified.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode getBlobShareMode(int index)
		{
			return blobShareMode_.get(index);
		}

		public static final int BLOBS_LR_FIELD_NUMBER = 7;
		private java.util.List<java.lang.Float> blobsLr_;

		/**
		 * <code>repeated float blobs_lr = 7;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getBlobsLrList()
		{
			return blobsLr_;
		}

		/**
		 * <code>repeated float blobs_lr = 7;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		@Override
		public int getBlobsLrCount()
		{
			return blobsLr_.size();
		}

		/**
		 * <code>repeated float blobs_lr = 7;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		@Override
		public float getBlobsLr(int index)
		{
			return blobsLr_.get(index);
		}

		public static final int WEIGHT_DECAY_FIELD_NUMBER = 8;
		private java.util.List<java.lang.Float> weightDecay_;

		/**
		 * <code>repeated float weight_decay = 8;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getWeightDecayList()
		{
			return weightDecay_;
		}

		/**
		 * <code>repeated float weight_decay = 8;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		@Override
		public int getWeightDecayCount()
		{
			return weightDecay_.size();
		}

		/**
		 * <code>repeated float weight_decay = 8;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		@Override
		public float getWeightDecay(int index)
		{
			return weightDecay_.get(index);
		}

		public static final int LOSS_WEIGHT_FIELD_NUMBER = 35;
		private java.util.List<java.lang.Float> lossWeight_;

		/**
		 * <code>repeated float loss_weight = 35;</code>
		 *
		 * <pre>
		 * The amount of weight to assign each top blob in the objective.
		 * Each layer assigns a default value, usually of either 0 or 1,
		 * to each top blob.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getLossWeightList()
		{
			return lossWeight_;
		}

		/**
		 * <code>repeated float loss_weight = 35;</code>
		 *
		 * <pre>
		 * The amount of weight to assign each top blob in the objective.
		 * Each layer assigns a default value, usually of either 0 or 1,
		 * to each top blob.
		 * </pre>
		 */
		@Override
		public int getLossWeightCount()
		{
			return lossWeight_.size();
		}

		/**
		 * <code>repeated float loss_weight = 35;</code>
		 *
		 * <pre>
		 * The amount of weight to assign each top blob in the objective.
		 * Each layer assigns a default value, usually of either 0 or 1,
		 * to each top blob.
		 * </pre>
		 */
		@Override
		public float getLossWeight(int index)
		{
			return lossWeight_.get(index);
		}

		public static final int ACCURACY_PARAM_FIELD_NUMBER = 27;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter accuracyParam_;

		/**
		 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
		 */
		@Override
		public boolean hasAccuracyParam()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter getAccuracyParam()
		{
			return accuracyParam_;
		}

		/**
		 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder getAccuracyParamOrBuilder()
		{
			return accuracyParam_;
		}

		public static final int ARGMAX_PARAM_FIELD_NUMBER = 23;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter argmaxParam_;

		/**
		 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
		 */
		@Override
		public boolean hasArgmaxParam()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter getArgmaxParam()
		{
			return argmaxParam_;
		}

		/**
		 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder getArgmaxParamOrBuilder()
		{
			return argmaxParam_;
		}

		public static final int CONCAT_PARAM_FIELD_NUMBER = 9;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter concatParam_;

		/**
		 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
		 */
		@Override
		public boolean hasConcatParam()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter getConcatParam()
		{
			return concatParam_;
		}

		/**
		 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder getConcatParamOrBuilder()
		{
			return concatParam_;
		}

		public static final int CONTRASTIVE_LOSS_PARAM_FIELD_NUMBER = 40;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter contrastiveLossParam_;

		/**
		 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
		 */
		@Override
		public boolean hasContrastiveLossParam()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter getContrastiveLossParam()
		{
			return contrastiveLossParam_;
		}

		/**
		 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder getContrastiveLossParamOrBuilder()
		{
			return contrastiveLossParam_;
		}

		public static final int CONVOLUTION_PARAM_FIELD_NUMBER = 10;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter convolutionParam_;

		/**
		 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
		 */
		@Override
		public boolean hasConvolutionParam()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter getConvolutionParam()
		{
			return convolutionParam_;
		}

		/**
		 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder getConvolutionParamOrBuilder()
		{
			return convolutionParam_;
		}

		public static final int DATA_PARAM_FIELD_NUMBER = 11;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter dataParam_;

		/**
		 * <code>optional .caffe.DataParameter data_param = 11;</code>
		 */
		@Override
		public boolean hasDataParam()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional .caffe.DataParameter data_param = 11;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter getDataParam()
		{
			return dataParam_;
		}

		/**
		 * <code>optional .caffe.DataParameter data_param = 11;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder getDataParamOrBuilder()
		{
			return dataParam_;
		}

		public static final int DROPOUT_PARAM_FIELD_NUMBER = 12;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter dropoutParam_;

		/**
		 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
		 */
		@Override
		public boolean hasDropoutParam()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter getDropoutParam()
		{
			return dropoutParam_;
		}

		/**
		 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder getDropoutParamOrBuilder()
		{
			return dropoutParam_;
		}

		public static final int DUMMY_DATA_PARAM_FIELD_NUMBER = 26;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter dummyDataParam_;

		/**
		 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
		 */
		@Override
		public boolean hasDummyDataParam()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter getDummyDataParam()
		{
			return dummyDataParam_;
		}

		/**
		 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder getDummyDataParamOrBuilder()
		{
			return dummyDataParam_;
		}

		public static final int ELTWISE_PARAM_FIELD_NUMBER = 24;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter eltwiseParam_;

		/**
		 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
		 */
		@Override
		public boolean hasEltwiseParam()
		{
			return ((bitField0_ & 0x00000400) == 0x00000400);
		}

		/**
		 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter getEltwiseParam()
		{
			return eltwiseParam_;
		}

		/**
		 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder getEltwiseParamOrBuilder()
		{
			return eltwiseParam_;
		}

		public static final int HDF5_DATA_PARAM_FIELD_NUMBER = 13;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter hdf5DataParam_;

		/**
		 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
		 */
		@Override
		public boolean hasHdf5DataParam()
		{
			return ((bitField0_ & 0x00000800) == 0x00000800);
		}

		/**
		 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter getHdf5DataParam()
		{
			return hdf5DataParam_;
		}

		/**
		 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder getHdf5DataParamOrBuilder()
		{
			return hdf5DataParam_;
		}

		public static final int HDF5_OUTPUT_PARAM_FIELD_NUMBER = 14;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter hdf5OutputParam_;

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
		 */
		@Override
		public boolean hasHdf5OutputParam()
		{
			return ((bitField0_ & 0x00001000) == 0x00001000);
		}

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getHdf5OutputParam()
		{
			return hdf5OutputParam_;
		}

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder getHdf5OutputParamOrBuilder()
		{
			return hdf5OutputParam_;
		}

		public static final int HINGE_LOSS_PARAM_FIELD_NUMBER = 29;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter hingeLossParam_;

		/**
		 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
		 */
		@Override
		public boolean hasHingeLossParam()
		{
			return ((bitField0_ & 0x00002000) == 0x00002000);
		}

		/**
		 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter getHingeLossParam()
		{
			return hingeLossParam_;
		}

		/**
		 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder getHingeLossParamOrBuilder()
		{
			return hingeLossParam_;
		}

		public static final int IMAGE_DATA_PARAM_FIELD_NUMBER = 15;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter imageDataParam_;

		/**
		 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
		 */
		@Override
		public boolean hasImageDataParam()
		{
			return ((bitField0_ & 0x00004000) == 0x00004000);
		}

		/**
		 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter getImageDataParam()
		{
			return imageDataParam_;
		}

		/**
		 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder getImageDataParamOrBuilder()
		{
			return imageDataParam_;
		}

		public static final int INFOGAIN_LOSS_PARAM_FIELD_NUMBER = 16;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter infogainLossParam_;

		/**
		 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
		 */
		@Override
		public boolean hasInfogainLossParam()
		{
			return ((bitField0_ & 0x00008000) == 0x00008000);
		}

		/**
		 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter getInfogainLossParam()
		{
			return infogainLossParam_;
		}

		/**
		 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder getInfogainLossParamOrBuilder()
		{
			return infogainLossParam_;
		}

		public static final int INNER_PRODUCT_PARAM_FIELD_NUMBER = 17;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter innerProductParam_;

		/**
		 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
		 */
		@Override
		public boolean hasInnerProductParam()
		{
			return ((bitField0_ & 0x00010000) == 0x00010000);
		}

		/**
		 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter getInnerProductParam()
		{
			return innerProductParam_;
		}

		/**
		 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder getInnerProductParamOrBuilder()
		{
			return innerProductParam_;
		}

		public static final int LRN_PARAM_FIELD_NUMBER = 18;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter lrnParam_;

		/**
		 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
		 */
		@Override
		public boolean hasLrnParam()
		{
			return ((bitField0_ & 0x00020000) == 0x00020000);
		}

		/**
		 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter getLrnParam()
		{
			return lrnParam_;
		}

		/**
		 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder getLrnParamOrBuilder()
		{
			return lrnParam_;
		}

		public static final int MEMORY_DATA_PARAM_FIELD_NUMBER = 22;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter memoryDataParam_;

		/**
		 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
		 */
		@Override
		public boolean hasMemoryDataParam()
		{
			return ((bitField0_ & 0x00040000) == 0x00040000);
		}

		/**
		 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter getMemoryDataParam()
		{
			return memoryDataParam_;
		}

		/**
		 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder getMemoryDataParamOrBuilder()
		{
			return memoryDataParam_;
		}

		public static final int MVN_PARAM_FIELD_NUMBER = 34;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter mvnParam_;

		/**
		 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
		 */
		@Override
		public boolean hasMvnParam()
		{
			return ((bitField0_ & 0x00080000) == 0x00080000);
		}

		/**
		 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter getMvnParam()
		{
			return mvnParam_;
		}

		/**
		 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder getMvnParamOrBuilder()
		{
			return mvnParam_;
		}

		public static final int POOLING_PARAM_FIELD_NUMBER = 19;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter poolingParam_;

		/**
		 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
		 */
		@Override
		public boolean hasPoolingParam()
		{
			return ((bitField0_ & 0x00100000) == 0x00100000);
		}

		/**
		 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter getPoolingParam()
		{
			return poolingParam_;
		}

		/**
		 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder getPoolingParamOrBuilder()
		{
			return poolingParam_;
		}

		public static final int POWER_PARAM_FIELD_NUMBER = 21;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter powerParam_;

		/**
		 * <code>optional .caffe.PowerParameter power_param = 21;</code>
		 */
		@Override
		public boolean hasPowerParam()
		{
			return ((bitField0_ & 0x00200000) == 0x00200000);
		}

		/**
		 * <code>optional .caffe.PowerParameter power_param = 21;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter getPowerParam()
		{
			return powerParam_;
		}

		/**
		 * <code>optional .caffe.PowerParameter power_param = 21;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder getPowerParamOrBuilder()
		{
			return powerParam_;
		}

		public static final int RELU_PARAM_FIELD_NUMBER = 30;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter reluParam_;

		/**
		 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
		 */
		@Override
		public boolean hasReluParam()
		{
			return ((bitField0_ & 0x00400000) == 0x00400000);
		}

		/**
		 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter getReluParam()
		{
			return reluParam_;
		}

		/**
		 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder getReluParamOrBuilder()
		{
			return reluParam_;
		}

		public static final int SIGMOID_PARAM_FIELD_NUMBER = 38;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter sigmoidParam_;

		/**
		 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
		 */
		@Override
		public boolean hasSigmoidParam()
		{
			return ((bitField0_ & 0x00800000) == 0x00800000);
		}

		/**
		 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter getSigmoidParam()
		{
			return sigmoidParam_;
		}

		/**
		 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder getSigmoidParamOrBuilder()
		{
			return sigmoidParam_;
		}

		public static final int SOFTMAX_PARAM_FIELD_NUMBER = 39;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter softmaxParam_;

		/**
		 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
		 */
		@Override
		public boolean hasSoftmaxParam()
		{
			return ((bitField0_ & 0x01000000) == 0x01000000);
		}

		/**
		 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter getSoftmaxParam()
		{
			return softmaxParam_;
		}

		/**
		 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder getSoftmaxParamOrBuilder()
		{
			return softmaxParam_;
		}

		public static final int SLICE_PARAM_FIELD_NUMBER = 31;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter sliceParam_;

		/**
		 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
		 */
		@Override
		public boolean hasSliceParam()
		{
			return ((bitField0_ & 0x02000000) == 0x02000000);
		}

		/**
		 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter getSliceParam()
		{
			return sliceParam_;
		}

		/**
		 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder getSliceParamOrBuilder()
		{
			return sliceParam_;
		}

		public static final int TANH_PARAM_FIELD_NUMBER = 37;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter tanhParam_;

		/**
		 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
		 */
		@Override
		public boolean hasTanhParam()
		{
			return ((bitField0_ & 0x04000000) == 0x04000000);
		}

		/**
		 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter getTanhParam()
		{
			return tanhParam_;
		}

		/**
		 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder getTanhParamOrBuilder()
		{
			return tanhParam_;
		}

		public static final int THRESHOLD_PARAM_FIELD_NUMBER = 25;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter thresholdParam_;

		/**
		 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
		 */
		@Override
		public boolean hasThresholdParam()
		{
			return ((bitField0_ & 0x08000000) == 0x08000000);
		}

		/**
		 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter getThresholdParam()
		{
			return thresholdParam_;
		}

		/**
		 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder getThresholdParamOrBuilder()
		{
			return thresholdParam_;
		}

		public static final int WINDOW_DATA_PARAM_FIELD_NUMBER = 20;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter windowDataParam_;

		/**
		 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
		 */
		@Override
		public boolean hasWindowDataParam()
		{
			return ((bitField0_ & 0x10000000) == 0x10000000);
		}

		/**
		 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter getWindowDataParam()
		{
			return windowDataParam_;
		}

		/**
		 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder getWindowDataParamOrBuilder()
		{
			return windowDataParam_;
		}

		public static final int TRANSFORM_PARAM_FIELD_NUMBER = 36;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter transformParam_;

		/**
		 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
		 *
		 * <pre>
		 * Parameters for data pre-processing.
		 * </pre>
		 */
		@Override
		public boolean hasTransformParam()
		{
			return ((bitField0_ & 0x20000000) == 0x20000000);
		}

		/**
		 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
		 *
		 * <pre>
		 * Parameters for data pre-processing.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter getTransformParam()
		{
			return transformParam_;
		}

		/**
		 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
		 *
		 * <pre>
		 * Parameters for data pre-processing.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder getTransformParamOrBuilder()
		{
			return transformParam_;
		}

		public static final int LAYER_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter layer_;

		/**
		 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
		 *
		 * <pre>
		 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
		 * This should never be used by any code except to upgrade to the new
		 * LayerParameter specification.
		 * </pre>
		 */
		@Override
		public boolean hasLayer()
		{
			return ((bitField0_ & 0x40000000) == 0x40000000);
		}

		/**
		 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
		 *
		 * <pre>
		 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
		 * This should never be used by any code except to upgrade to the new
		 * LayerParameter specification.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter getLayer()
		{
			return layer_;
		}

		/**
		 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
		 *
		 * <pre>
		 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
		 * This should never be used by any code except to upgrade to the new
		 * LayerParameter specification.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder getLayerOrBuilder()
		{
			return layer_;
		}

		private void initFields()
		{
			bottom_ = com.google.protobuf.LazyStringArrayList.EMPTY;
			top_ = com.google.protobuf.LazyStringArrayList.EMPTY;
			name_ = "";
			include_ = java.util.Collections.emptyList();
			exclude_ = java.util.Collections.emptyList();
			type_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType.NONE;
			blobs_ = java.util.Collections.emptyList();
			param_ = com.google.protobuf.LazyStringArrayList.EMPTY;
			blobShareMode_ = java.util.Collections.emptyList();
			blobsLr_ = java.util.Collections.emptyList();
			weightDecay_ = java.util.Collections.emptyList();
			lossWeight_ = java.util.Collections.emptyList();
			accuracyParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.getDefaultInstance();
			argmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.getDefaultInstance();
			concatParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.getDefaultInstance();
			contrastiveLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.getDefaultInstance();
			convolutionParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDefaultInstance();
			dataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDefaultInstance();
			dropoutParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.getDefaultInstance();
			dummyDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.getDefaultInstance();
			eltwiseParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDefaultInstance();
			hdf5DataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.getDefaultInstance();
			hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
			hingeLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDefaultInstance();
			imageDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.getDefaultInstance();
			infogainLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.getDefaultInstance();
			innerProductParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.getDefaultInstance();
			lrnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDefaultInstance();
			memoryDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.getDefaultInstance();
			mvnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.getDefaultInstance();
			poolingParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDefaultInstance();
			powerParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.getDefaultInstance();
			reluParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDefaultInstance();
			sigmoidParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDefaultInstance();
			softmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDefaultInstance();
			sliceParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.getDefaultInstance();
			tanhParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDefaultInstance();
			thresholdParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.getDefaultInstance();
			windowDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.getDefaultInstance();
			transformParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.getDefaultInstance();
			layer_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDefaultInstance();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x40000000) == 0x40000000))
			{
				output.writeMessage(1, layer_);
			}
			for (int i = 0; i < bottom_.size(); i++)
			{
				output.writeBytes(2, bottom_.getByteString(i));
			}
			for (int i = 0; i < top_.size(); i++)
			{
				output.writeBytes(3, top_.getByteString(i));
			}
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(4, getNameBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeEnum(5, type_.getNumber());
			}
			for (int i = 0; i < blobs_.size(); i++)
			{
				output.writeMessage(6, blobs_.get(i));
			}
			for (int i = 0; i < blobsLr_.size(); i++)
			{
				output.writeFloat(7, blobsLr_.get(i));
			}
			for (int i = 0; i < weightDecay_.size(); i++)
			{
				output.writeFloat(8, weightDecay_.get(i));
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeMessage(9, concatParam_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeMessage(10, convolutionParam_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeMessage(11, dataParam_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeMessage(12, dropoutParam_);
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				output.writeMessage(13, hdf5DataParam_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				output.writeMessage(14, hdf5OutputParam_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				output.writeMessage(15, imageDataParam_);
			}
			if (((bitField0_ & 0x00008000) == 0x00008000))
			{
				output.writeMessage(16, infogainLossParam_);
			}
			if (((bitField0_ & 0x00010000) == 0x00010000))
			{
				output.writeMessage(17, innerProductParam_);
			}
			if (((bitField0_ & 0x00020000) == 0x00020000))
			{
				output.writeMessage(18, lrnParam_);
			}
			if (((bitField0_ & 0x00100000) == 0x00100000))
			{
				output.writeMessage(19, poolingParam_);
			}
			if (((bitField0_ & 0x10000000) == 0x10000000))
			{
				output.writeMessage(20, windowDataParam_);
			}
			if (((bitField0_ & 0x00200000) == 0x00200000))
			{
				output.writeMessage(21, powerParam_);
			}
			if (((bitField0_ & 0x00040000) == 0x00040000))
			{
				output.writeMessage(22, memoryDataParam_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeMessage(23, argmaxParam_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				output.writeMessage(24, eltwiseParam_);
			}
			if (((bitField0_ & 0x08000000) == 0x08000000))
			{
				output.writeMessage(25, thresholdParam_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeMessage(26, dummyDataParam_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeMessage(27, accuracyParam_);
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				output.writeMessage(29, hingeLossParam_);
			}
			if (((bitField0_ & 0x00400000) == 0x00400000))
			{
				output.writeMessage(30, reluParam_);
			}
			if (((bitField0_ & 0x02000000) == 0x02000000))
			{
				output.writeMessage(31, sliceParam_);
			}
			for (int i = 0; i < include_.size(); i++)
			{
				output.writeMessage(32, include_.get(i));
			}
			for (int i = 0; i < exclude_.size(); i++)
			{
				output.writeMessage(33, exclude_.get(i));
			}
			if (((bitField0_ & 0x00080000) == 0x00080000))
			{
				output.writeMessage(34, mvnParam_);
			}
			for (int i = 0; i < lossWeight_.size(); i++)
			{
				output.writeFloat(35, lossWeight_.get(i));
			}
			if (((bitField0_ & 0x20000000) == 0x20000000))
			{
				output.writeMessage(36, transformParam_);
			}
			if (((bitField0_ & 0x04000000) == 0x04000000))
			{
				output.writeMessage(37, tanhParam_);
			}
			if (((bitField0_ & 0x00800000) == 0x00800000))
			{
				output.writeMessage(38, sigmoidParam_);
			}
			if (((bitField0_ & 0x01000000) == 0x01000000))
			{
				output.writeMessage(39, softmaxParam_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeMessage(40, contrastiveLossParam_);
			}
			for (int i = 0; i < param_.size(); i++)
			{
				output.writeBytes(1001, param_.getByteString(i));
			}
			for (int i = 0; i < blobShareMode_.size(); i++)
			{
				output.writeEnum(1002, blobShareMode_.get(i).getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x40000000) == 0x40000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(1, layer_);
			}
			{
				int dataSize = 0;
				for (int i = 0; i < bottom_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(bottom_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getBottomList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < top_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(top_.getByteString(i));
				}
				size += dataSize;
				size += 1 * getTopList().size();
			}
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(4, getNameBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(5, type_.getNumber());
			}
			for (int i = 0; i < blobs_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(6, blobs_.get(i));
			}
			{
				int dataSize = 0;
				dataSize = 4 * getBlobsLrList().size();
				size += dataSize;
				size += 1 * getBlobsLrList().size();
			}
			{
				int dataSize = 0;
				dataSize = 4 * getWeightDecayList().size();
				size += dataSize;
				size += 1 * getWeightDecayList().size();
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(9, concatParam_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(10, convolutionParam_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(11, dataParam_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(12, dropoutParam_);
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(13, hdf5DataParam_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(14, hdf5OutputParam_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(15, imageDataParam_);
			}
			if (((bitField0_ & 0x00008000) == 0x00008000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(16, infogainLossParam_);
			}
			if (((bitField0_ & 0x00010000) == 0x00010000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(17, innerProductParam_);
			}
			if (((bitField0_ & 0x00020000) == 0x00020000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(18, lrnParam_);
			}
			if (((bitField0_ & 0x00100000) == 0x00100000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(19, poolingParam_);
			}
			if (((bitField0_ & 0x10000000) == 0x10000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(20, windowDataParam_);
			}
			if (((bitField0_ & 0x00200000) == 0x00200000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(21, powerParam_);
			}
			if (((bitField0_ & 0x00040000) == 0x00040000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(22, memoryDataParam_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(23, argmaxParam_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(24, eltwiseParam_);
			}
			if (((bitField0_ & 0x08000000) == 0x08000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(25, thresholdParam_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(26, dummyDataParam_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(27, accuracyParam_);
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(29, hingeLossParam_);
			}
			if (((bitField0_ & 0x00400000) == 0x00400000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(30, reluParam_);
			}
			if (((bitField0_ & 0x02000000) == 0x02000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(31, sliceParam_);
			}
			for (int i = 0; i < include_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(32, include_.get(i));
			}
			for (int i = 0; i < exclude_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(33, exclude_.get(i));
			}
			if (((bitField0_ & 0x00080000) == 0x00080000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(34, mvnParam_);
			}
			{
				int dataSize = 0;
				dataSize = 4 * getLossWeightList().size();
				size += dataSize;
				size += 2 * getLossWeightList().size();
			}
			if (((bitField0_ & 0x20000000) == 0x20000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(36, transformParam_);
			}
			if (((bitField0_ & 0x04000000) == 0x04000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(37, tanhParam_);
			}
			if (((bitField0_ & 0x00800000) == 0x00800000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(38, sigmoidParam_);
			}
			if (((bitField0_ & 0x01000000) == 0x01000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(39, softmaxParam_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(40, contrastiveLossParam_);
			}
			{
				int dataSize = 0;
				for (int i = 0; i < param_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeBytesSizeNoTag(param_.getByteString(i));
				}
				size += dataSize;
				size += 2 * getParamList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < blobShareMode_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeEnumSizeNoTag(blobShareMode_.get(i).getNumber());
				}
				size += dataSize;
				size += 2 * blobShareMode_.size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.LayerParameter}
		 *
		 * <pre>
		 * NOTE
		 * Update the next available ID when you add a new LayerParameter field.
		 * LayerParameter next available ID: 41 (last added: contrastive_loss_param)
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.LayerParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LayerParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LayerParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getIncludeFieldBuilder();
					getExcludeFieldBuilder();
					getBlobsFieldBuilder();
					getAccuracyParamFieldBuilder();
					getArgmaxParamFieldBuilder();
					getConcatParamFieldBuilder();
					getContrastiveLossParamFieldBuilder();
					getConvolutionParamFieldBuilder();
					getDataParamFieldBuilder();
					getDropoutParamFieldBuilder();
					getDummyDataParamFieldBuilder();
					getEltwiseParamFieldBuilder();
					getHdf5DataParamFieldBuilder();
					getHdf5OutputParamFieldBuilder();
					getHingeLossParamFieldBuilder();
					getImageDataParamFieldBuilder();
					getInfogainLossParamFieldBuilder();
					getInnerProductParamFieldBuilder();
					getLrnParamFieldBuilder();
					getMemoryDataParamFieldBuilder();
					getMvnParamFieldBuilder();
					getPoolingParamFieldBuilder();
					getPowerParamFieldBuilder();
					getReluParamFieldBuilder();
					getSigmoidParamFieldBuilder();
					getSoftmaxParamFieldBuilder();
					getSliceParamFieldBuilder();
					getTanhParamFieldBuilder();
					getThresholdParamFieldBuilder();
					getWindowDataParamFieldBuilder();
					getTransformParamFieldBuilder();
					getLayerFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				bottom_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000001);
				top_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000002);
				name_ = "";
				bitField0_ = (bitField0_ & ~0x00000004);
				if (includeBuilder_ == null)
				{
					include_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000008);
				} else
				{
					includeBuilder_.clear();
				}
				if (excludeBuilder_ == null)
				{
					exclude_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000010);
				} else
				{
					excludeBuilder_.clear();
				}
				type_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType.NONE;
				bitField0_ = (bitField0_ & ~0x00000020);
				if (blobsBuilder_ == null)
				{
					blobs_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000040);
				} else
				{
					blobsBuilder_.clear();
				}
				param_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000080);
				blobShareMode_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000100);
				blobsLr_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000200);
				weightDecay_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000400);
				lossWeight_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000800);
				if (accuracyParamBuilder_ == null)
				{
					accuracyParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.getDefaultInstance();
				} else
				{
					accuracyParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00001000);
				if (argmaxParamBuilder_ == null)
				{
					argmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.getDefaultInstance();
				} else
				{
					argmaxParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00002000);
				if (concatParamBuilder_ == null)
				{
					concatParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.getDefaultInstance();
				} else
				{
					concatParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00004000);
				if (contrastiveLossParamBuilder_ == null)
				{
					contrastiveLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.getDefaultInstance();
				} else
				{
					contrastiveLossParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00008000);
				if (convolutionParamBuilder_ == null)
				{
					convolutionParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDefaultInstance();
				} else
				{
					convolutionParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00010000);
				if (dataParamBuilder_ == null)
				{
					dataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDefaultInstance();
				} else
				{
					dataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00020000);
				if (dropoutParamBuilder_ == null)
				{
					dropoutParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.getDefaultInstance();
				} else
				{
					dropoutParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00040000);
				if (dummyDataParamBuilder_ == null)
				{
					dummyDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.getDefaultInstance();
				} else
				{
					dummyDataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00080000);
				if (eltwiseParamBuilder_ == null)
				{
					eltwiseParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDefaultInstance();
				} else
				{
					eltwiseParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00100000);
				if (hdf5DataParamBuilder_ == null)
				{
					hdf5DataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.getDefaultInstance();
				} else
				{
					hdf5DataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00200000);
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
				} else
				{
					hdf5OutputParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00400000);
				if (hingeLossParamBuilder_ == null)
				{
					hingeLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDefaultInstance();
				} else
				{
					hingeLossParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00800000);
				if (imageDataParamBuilder_ == null)
				{
					imageDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.getDefaultInstance();
				} else
				{
					imageDataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x01000000);
				if (infogainLossParamBuilder_ == null)
				{
					infogainLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.getDefaultInstance();
				} else
				{
					infogainLossParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x02000000);
				if (innerProductParamBuilder_ == null)
				{
					innerProductParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.getDefaultInstance();
				} else
				{
					innerProductParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x04000000);
				if (lrnParamBuilder_ == null)
				{
					lrnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDefaultInstance();
				} else
				{
					lrnParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x08000000);
				if (memoryDataParamBuilder_ == null)
				{
					memoryDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.getDefaultInstance();
				} else
				{
					memoryDataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x10000000);
				if (mvnParamBuilder_ == null)
				{
					mvnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.getDefaultInstance();
				} else
				{
					mvnParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x20000000);
				if (poolingParamBuilder_ == null)
				{
					poolingParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDefaultInstance();
				} else
				{
					poolingParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x40000000);
				if (powerParamBuilder_ == null)
				{
					powerParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.getDefaultInstance();
				} else
				{
					powerParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x80000000);
				if (reluParamBuilder_ == null)
				{
					reluParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDefaultInstance();
				} else
				{
					reluParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000001);
				if (sigmoidParamBuilder_ == null)
				{
					sigmoidParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDefaultInstance();
				} else
				{
					sigmoidParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000002);
				if (softmaxParamBuilder_ == null)
				{
					softmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDefaultInstance();
				} else
				{
					softmaxParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000004);
				if (sliceParamBuilder_ == null)
				{
					sliceParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.getDefaultInstance();
				} else
				{
					sliceParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000008);
				if (tanhParamBuilder_ == null)
				{
					tanhParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDefaultInstance();
				} else
				{
					tanhParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000010);
				if (thresholdParamBuilder_ == null)
				{
					thresholdParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.getDefaultInstance();
				} else
				{
					thresholdParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000020);
				if (windowDataParamBuilder_ == null)
				{
					windowDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.getDefaultInstance();
				} else
				{
					windowDataParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000040);
				if (transformParamBuilder_ == null)
				{
					transformParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.getDefaultInstance();
				} else
				{
					transformParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000080);
				if (layerBuilder_ == null)
				{
					layer_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDefaultInstance();
				} else
				{
					layerBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000100);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LayerParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter(this);
				int from_bitField0_ = bitField0_;
				int from_bitField1_ = bitField1_;
				int to_bitField0_ = 0;
				if (((bitField0_ & 0x00000001) == 0x00000001))
				{
					bottom_ = bottom_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000001);
				}
				result.bottom_ = bottom_;
				if (((bitField0_ & 0x00000002) == 0x00000002))
				{
					top_ = top_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000002);
				}
				result.top_ = top_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.name_ = name_;
				if (includeBuilder_ == null)
				{
					if (((bitField0_ & 0x00000008) == 0x00000008))
					{
						include_ = java.util.Collections.unmodifiableList(include_);
						bitField0_ = (bitField0_ & ~0x00000008);
					}
					result.include_ = include_;
				} else
				{
					result.include_ = includeBuilder_.build();
				}
				if (excludeBuilder_ == null)
				{
					if (((bitField0_ & 0x00000010) == 0x00000010))
					{
						exclude_ = java.util.Collections.unmodifiableList(exclude_);
						bitField0_ = (bitField0_ & ~0x00000010);
					}
					result.exclude_ = exclude_;
				} else
				{
					result.exclude_ = excludeBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.type_ = type_;
				if (blobsBuilder_ == null)
				{
					if (((bitField0_ & 0x00000040) == 0x00000040))
					{
						blobs_ = java.util.Collections.unmodifiableList(blobs_);
						bitField0_ = (bitField0_ & ~0x00000040);
					}
					result.blobs_ = blobs_;
				} else
				{
					result.blobs_ = blobsBuilder_.build();
				}
				if (((bitField0_ & 0x00000080) == 0x00000080))
				{
					param_ = param_.getUnmodifiableView();
					bitField0_ = (bitField0_ & ~0x00000080);
				}
				result.param_ = param_;
				if (((bitField0_ & 0x00000100) == 0x00000100))
				{
					blobShareMode_ = java.util.Collections.unmodifiableList(blobShareMode_);
					bitField0_ = (bitField0_ & ~0x00000100);
				}
				result.blobShareMode_ = blobShareMode_;
				if (((bitField0_ & 0x00000200) == 0x00000200))
				{
					blobsLr_ = java.util.Collections.unmodifiableList(blobsLr_);
					bitField0_ = (bitField0_ & ~0x00000200);
				}
				result.blobsLr_ = blobsLr_;
				if (((bitField0_ & 0x00000400) == 0x00000400))
				{
					weightDecay_ = java.util.Collections.unmodifiableList(weightDecay_);
					bitField0_ = (bitField0_ & ~0x00000400);
				}
				result.weightDecay_ = weightDecay_;
				if (((bitField0_ & 0x00000800) == 0x00000800))
				{
					lossWeight_ = java.util.Collections.unmodifiableList(lossWeight_);
					bitField0_ = (bitField0_ & ~0x00000800);
				}
				result.lossWeight_ = lossWeight_;
				if (((from_bitField0_ & 0x00001000) == 0x00001000))
				{
					to_bitField0_ |= 0x00000004;
				}
				if (accuracyParamBuilder_ == null)
				{
					result.accuracyParam_ = accuracyParam_;
				} else
				{
					result.accuracyParam_ = accuracyParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00002000) == 0x00002000))
				{
					to_bitField0_ |= 0x00000008;
				}
				if (argmaxParamBuilder_ == null)
				{
					result.argmaxParam_ = argmaxParam_;
				} else
				{
					result.argmaxParam_ = argmaxParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00004000) == 0x00004000))
				{
					to_bitField0_ |= 0x00000010;
				}
				if (concatParamBuilder_ == null)
				{
					result.concatParam_ = concatParam_;
				} else
				{
					result.concatParam_ = concatParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00008000) == 0x00008000))
				{
					to_bitField0_ |= 0x00000020;
				}
				if (contrastiveLossParamBuilder_ == null)
				{
					result.contrastiveLossParam_ = contrastiveLossParam_;
				} else
				{
					result.contrastiveLossParam_ = contrastiveLossParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00010000) == 0x00010000))
				{
					to_bitField0_ |= 0x00000040;
				}
				if (convolutionParamBuilder_ == null)
				{
					result.convolutionParam_ = convolutionParam_;
				} else
				{
					result.convolutionParam_ = convolutionParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00020000) == 0x00020000))
				{
					to_bitField0_ |= 0x00000080;
				}
				if (dataParamBuilder_ == null)
				{
					result.dataParam_ = dataParam_;
				} else
				{
					result.dataParam_ = dataParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00040000) == 0x00040000))
				{
					to_bitField0_ |= 0x00000100;
				}
				if (dropoutParamBuilder_ == null)
				{
					result.dropoutParam_ = dropoutParam_;
				} else
				{
					result.dropoutParam_ = dropoutParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00080000) == 0x00080000))
				{
					to_bitField0_ |= 0x00000200;
				}
				if (dummyDataParamBuilder_ == null)
				{
					result.dummyDataParam_ = dummyDataParam_;
				} else
				{
					result.dummyDataParam_ = dummyDataParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00100000) == 0x00100000))
				{
					to_bitField0_ |= 0x00000400;
				}
				if (eltwiseParamBuilder_ == null)
				{
					result.eltwiseParam_ = eltwiseParam_;
				} else
				{
					result.eltwiseParam_ = eltwiseParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00200000) == 0x00200000))
				{
					to_bitField0_ |= 0x00000800;
				}
				if (hdf5DataParamBuilder_ == null)
				{
					result.hdf5DataParam_ = hdf5DataParam_;
				} else
				{
					result.hdf5DataParam_ = hdf5DataParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00400000) == 0x00400000))
				{
					to_bitField0_ |= 0x00001000;
				}
				if (hdf5OutputParamBuilder_ == null)
				{
					result.hdf5OutputParam_ = hdf5OutputParam_;
				} else
				{
					result.hdf5OutputParam_ = hdf5OutputParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x00800000) == 0x00800000))
				{
					to_bitField0_ |= 0x00002000;
				}
				if (hingeLossParamBuilder_ == null)
				{
					result.hingeLossParam_ = hingeLossParam_;
				} else
				{
					result.hingeLossParam_ = hingeLossParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x01000000) == 0x01000000))
				{
					to_bitField0_ |= 0x00004000;
				}
				if (imageDataParamBuilder_ == null)
				{
					result.imageDataParam_ = imageDataParam_;
				} else
				{
					result.imageDataParam_ = imageDataParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x02000000) == 0x02000000))
				{
					to_bitField0_ |= 0x00008000;
				}
				if (infogainLossParamBuilder_ == null)
				{
					result.infogainLossParam_ = infogainLossParam_;
				} else
				{
					result.infogainLossParam_ = infogainLossParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x04000000) == 0x04000000))
				{
					to_bitField0_ |= 0x00010000;
				}
				if (innerProductParamBuilder_ == null)
				{
					result.innerProductParam_ = innerProductParam_;
				} else
				{
					result.innerProductParam_ = innerProductParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x08000000) == 0x08000000))
				{
					to_bitField0_ |= 0x00020000;
				}
				if (lrnParamBuilder_ == null)
				{
					result.lrnParam_ = lrnParam_;
				} else
				{
					result.lrnParam_ = lrnParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x10000000) == 0x10000000))
				{
					to_bitField0_ |= 0x00040000;
				}
				if (memoryDataParamBuilder_ == null)
				{
					result.memoryDataParam_ = memoryDataParam_;
				} else
				{
					result.memoryDataParam_ = memoryDataParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x20000000) == 0x20000000))
				{
					to_bitField0_ |= 0x00080000;
				}
				if (mvnParamBuilder_ == null)
				{
					result.mvnParam_ = mvnParam_;
				} else
				{
					result.mvnParam_ = mvnParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x40000000) == 0x40000000))
				{
					to_bitField0_ |= 0x00100000;
				}
				if (poolingParamBuilder_ == null)
				{
					result.poolingParam_ = poolingParam_;
				} else
				{
					result.poolingParam_ = poolingParamBuilder_.build();
				}
				if (((from_bitField0_ & 0x80000000) == 0x80000000))
				{
					to_bitField0_ |= 0x00200000;
				}
				if (powerParamBuilder_ == null)
				{
					result.powerParam_ = powerParam_;
				} else
				{
					result.powerParam_ = powerParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00400000;
				}
				if (reluParamBuilder_ == null)
				{
					result.reluParam_ = reluParam_;
				} else
				{
					result.reluParam_ = reluParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00800000;
				}
				if (sigmoidParamBuilder_ == null)
				{
					result.sigmoidParam_ = sigmoidParam_;
				} else
				{
					result.sigmoidParam_ = sigmoidParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x01000000;
				}
				if (softmaxParamBuilder_ == null)
				{
					result.softmaxParam_ = softmaxParam_;
				} else
				{
					result.softmaxParam_ = softmaxParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x02000000;
				}
				if (sliceParamBuilder_ == null)
				{
					result.sliceParam_ = sliceParam_;
				} else
				{
					result.sliceParam_ = sliceParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x04000000;
				}
				if (tanhParamBuilder_ == null)
				{
					result.tanhParam_ = tanhParam_;
				} else
				{
					result.tanhParam_ = tanhParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x08000000;
				}
				if (thresholdParamBuilder_ == null)
				{
					result.thresholdParam_ = thresholdParam_;
				} else
				{
					result.thresholdParam_ = thresholdParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x10000000;
				}
				if (windowDataParamBuilder_ == null)
				{
					result.windowDataParam_ = windowDataParam_;
				} else
				{
					result.windowDataParam_ = windowDataParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x20000000;
				}
				if (transformParamBuilder_ == null)
				{
					result.transformParam_ = transformParam_;
				} else
				{
					result.transformParam_ = transformParamBuilder_.build();
				}
				if (((from_bitField1_ & 0x00000100) == 0x00000100))
				{
					to_bitField0_ |= 0x40000000;
				}
				if (layerBuilder_ == null)
				{
					result.layer_ = layer_;
				} else
				{
					result.layer_ = layerBuilder_.build();
				}
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.getDefaultInstance())
					return this;
				if (!other.bottom_.isEmpty())
				{
					if (bottom_.isEmpty())
					{
						bottom_ = other.bottom_;
						bitField0_ = (bitField0_ & ~0x00000001);
					} else
					{
						ensureBottomIsMutable();
						bottom_.addAll(other.bottom_);
					}
					onChanged();
				}
				if (!other.top_.isEmpty())
				{
					if (top_.isEmpty())
					{
						top_ = other.top_;
						bitField0_ = (bitField0_ & ~0x00000002);
					} else
					{
						ensureTopIsMutable();
						top_.addAll(other.top_);
					}
					onChanged();
				}
				if (other.hasName())
				{
					bitField0_ |= 0x00000004;
					name_ = other.name_;
					onChanged();
				}
				if (includeBuilder_ == null)
				{
					if (!other.include_.isEmpty())
					{
						if (include_.isEmpty())
						{
							include_ = other.include_;
							bitField0_ = (bitField0_ & ~0x00000008);
						} else
						{
							ensureIncludeIsMutable();
							include_.addAll(other.include_);
						}
						onChanged();
					}
				} else
				{
					if (!other.include_.isEmpty())
					{
						if (includeBuilder_.isEmpty())
						{
							includeBuilder_.dispose();
							includeBuilder_ = null;
							include_ = other.include_;
							bitField0_ = (bitField0_ & ~0x00000008);
							includeBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getIncludeFieldBuilder() : null;
						} else
						{
							includeBuilder_.addAllMessages(other.include_);
						}
					}
				}
				if (excludeBuilder_ == null)
				{
					if (!other.exclude_.isEmpty())
					{
						if (exclude_.isEmpty())
						{
							exclude_ = other.exclude_;
							bitField0_ = (bitField0_ & ~0x00000010);
						} else
						{
							ensureExcludeIsMutable();
							exclude_.addAll(other.exclude_);
						}
						onChanged();
					}
				} else
				{
					if (!other.exclude_.isEmpty())
					{
						if (excludeBuilder_.isEmpty())
						{
							excludeBuilder_.dispose();
							excludeBuilder_ = null;
							exclude_ = other.exclude_;
							bitField0_ = (bitField0_ & ~0x00000010);
							excludeBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getExcludeFieldBuilder() : null;
						} else
						{
							excludeBuilder_.addAllMessages(other.exclude_);
						}
					}
				}
				if (other.hasType())
				{
					setType(other.getType());
				}
				if (blobsBuilder_ == null)
				{
					if (!other.blobs_.isEmpty())
					{
						if (blobs_.isEmpty())
						{
							blobs_ = other.blobs_;
							bitField0_ = (bitField0_ & ~0x00000040);
						} else
						{
							ensureBlobsIsMutable();
							blobs_.addAll(other.blobs_);
						}
						onChanged();
					}
				} else
				{
					if (!other.blobs_.isEmpty())
					{
						if (blobsBuilder_.isEmpty())
						{
							blobsBuilder_.dispose();
							blobsBuilder_ = null;
							blobs_ = other.blobs_;
							bitField0_ = (bitField0_ & ~0x00000040);
							blobsBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getBlobsFieldBuilder() : null;
						} else
						{
							blobsBuilder_.addAllMessages(other.blobs_);
						}
					}
				}
				if (!other.param_.isEmpty())
				{
					if (param_.isEmpty())
					{
						param_ = other.param_;
						bitField0_ = (bitField0_ & ~0x00000080);
					} else
					{
						ensureParamIsMutable();
						param_.addAll(other.param_);
					}
					onChanged();
				}
				if (!other.blobShareMode_.isEmpty())
				{
					if (blobShareMode_.isEmpty())
					{
						blobShareMode_ = other.blobShareMode_;
						bitField0_ = (bitField0_ & ~0x00000100);
					} else
					{
						ensureBlobShareModeIsMutable();
						blobShareMode_.addAll(other.blobShareMode_);
					}
					onChanged();
				}
				if (!other.blobsLr_.isEmpty())
				{
					if (blobsLr_.isEmpty())
					{
						blobsLr_ = other.blobsLr_;
						bitField0_ = (bitField0_ & ~0x00000200);
					} else
					{
						ensureBlobsLrIsMutable();
						blobsLr_.addAll(other.blobsLr_);
					}
					onChanged();
				}
				if (!other.weightDecay_.isEmpty())
				{
					if (weightDecay_.isEmpty())
					{
						weightDecay_ = other.weightDecay_;
						bitField0_ = (bitField0_ & ~0x00000400);
					} else
					{
						ensureWeightDecayIsMutable();
						weightDecay_.addAll(other.weightDecay_);
					}
					onChanged();
				}
				if (!other.lossWeight_.isEmpty())
				{
					if (lossWeight_.isEmpty())
					{
						lossWeight_ = other.lossWeight_;
						bitField0_ = (bitField0_ & ~0x00000800);
					} else
					{
						ensureLossWeightIsMutable();
						lossWeight_.addAll(other.lossWeight_);
					}
					onChanged();
				}
				if (other.hasAccuracyParam())
				{
					mergeAccuracyParam(other.getAccuracyParam());
				}
				if (other.hasArgmaxParam())
				{
					mergeArgmaxParam(other.getArgmaxParam());
				}
				if (other.hasConcatParam())
				{
					mergeConcatParam(other.getConcatParam());
				}
				if (other.hasContrastiveLossParam())
				{
					mergeContrastiveLossParam(other.getContrastiveLossParam());
				}
				if (other.hasConvolutionParam())
				{
					mergeConvolutionParam(other.getConvolutionParam());
				}
				if (other.hasDataParam())
				{
					mergeDataParam(other.getDataParam());
				}
				if (other.hasDropoutParam())
				{
					mergeDropoutParam(other.getDropoutParam());
				}
				if (other.hasDummyDataParam())
				{
					mergeDummyDataParam(other.getDummyDataParam());
				}
				if (other.hasEltwiseParam())
				{
					mergeEltwiseParam(other.getEltwiseParam());
				}
				if (other.hasHdf5DataParam())
				{
					mergeHdf5DataParam(other.getHdf5DataParam());
				}
				if (other.hasHdf5OutputParam())
				{
					mergeHdf5OutputParam(other.getHdf5OutputParam());
				}
				if (other.hasHingeLossParam())
				{
					mergeHingeLossParam(other.getHingeLossParam());
				}
				if (other.hasImageDataParam())
				{
					mergeImageDataParam(other.getImageDataParam());
				}
				if (other.hasInfogainLossParam())
				{
					mergeInfogainLossParam(other.getInfogainLossParam());
				}
				if (other.hasInnerProductParam())
				{
					mergeInnerProductParam(other.getInnerProductParam());
				}
				if (other.hasLrnParam())
				{
					mergeLrnParam(other.getLrnParam());
				}
				if (other.hasMemoryDataParam())
				{
					mergeMemoryDataParam(other.getMemoryDataParam());
				}
				if (other.hasMvnParam())
				{
					mergeMvnParam(other.getMvnParam());
				}
				if (other.hasPoolingParam())
				{
					mergePoolingParam(other.getPoolingParam());
				}
				if (other.hasPowerParam())
				{
					mergePowerParam(other.getPowerParam());
				}
				if (other.hasReluParam())
				{
					mergeReluParam(other.getReluParam());
				}
				if (other.hasSigmoidParam())
				{
					mergeSigmoidParam(other.getSigmoidParam());
				}
				if (other.hasSoftmaxParam())
				{
					mergeSoftmaxParam(other.getSoftmaxParam());
				}
				if (other.hasSliceParam())
				{
					mergeSliceParam(other.getSliceParam());
				}
				if (other.hasTanhParam())
				{
					mergeTanhParam(other.getTanhParam());
				}
				if (other.hasThresholdParam())
				{
					mergeThresholdParam(other.getThresholdParam());
				}
				if (other.hasWindowDataParam())
				{
					mergeWindowDataParam(other.getWindowDataParam());
				}
				if (other.hasTransformParam())
				{
					mergeTransformParam(other.getTransformParam());
				}
				if (other.hasLayer())
				{
					mergeLayer(other.getLayer());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;
			private int bitField1_;

			private com.google.protobuf.LazyStringList bottom_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureBottomIsMutable()
			{
				if (!((bitField0_ & 0x00000001) == 0x00000001))
				{
					bottom_ = new com.google.protobuf.LazyStringArrayList(bottom_);
					bitField0_ |= 0x00000001;
				}
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getBottomList()
			{
				return bottom_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			@Override
			public int getBottomCount()
			{
				return bottom_.size();
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			@Override
			public java.lang.String getBottom(int index)
			{
				return bottom_.get(index);
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getBottomBytes(int index)
			{
				return bottom_.getByteString(index);
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			public Builder setBottom(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureBottomIsMutable();
				bottom_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			public Builder addBottom(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureBottomIsMutable();
				bottom_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			public Builder addAllBottom(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureBottomIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, bottom_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			public Builder clearBottom()
			{
				bottom_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000001);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string bottom = 2;</code>
			 *
			 * <pre>
			 * the name of the bottom blobs
			 * </pre>
			 */
			public Builder addBottomBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureBottomIsMutable();
				bottom_.add(value);
				onChanged();
				return this;
			}

			private com.google.protobuf.LazyStringList top_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureTopIsMutable()
			{
				if (!((bitField0_ & 0x00000002) == 0x00000002))
				{
					top_ = new com.google.protobuf.LazyStringArrayList(top_);
					bitField0_ |= 0x00000002;
				}
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getTopList()
			{
				return top_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			@Override
			public int getTopCount()
			{
				return top_.size();
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			@Override
			public java.lang.String getTop(int index)
			{
				return top_.get(index);
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getTopBytes(int index)
			{
				return top_.getByteString(index);
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			public Builder setTop(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureTopIsMutable();
				top_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			public Builder addTop(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureTopIsMutable();
				top_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			public Builder addAllTop(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureTopIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, top_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			public Builder clearTop()
			{
				top_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000002);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string top = 3;</code>
			 *
			 * <pre>
			 * the name of the top blobs
			 * </pre>
			 */
			public Builder addTopBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureTopIsMutable();
				top_.add(value);
				onChanged();
				return this;
			}

			private java.lang.Object name_ = "";

			/**
			 * <code>optional string name = 4;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			@Override
			public boolean hasName()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional string name = 4;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			@Override
			public java.lang.String getName()
			{
				java.lang.Object ref = name_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						name_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string name = 4;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getNameBytes()
			{
				java.lang.Object ref = name_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					name_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string name = 4;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			public Builder setName(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				name_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string name = 4;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			public Builder clearName()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				name_ = getDefaultInstance().getName();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string name = 4;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			public Builder setNameBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				name_ = value;
				onChanged();
				return this;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> include_ =
					java.util.Collections.emptyList();

			private void ensureIncludeIsMutable()
			{
				if (!((bitField0_ & 0x00000008) == 0x00000008))
				{
					include_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule>(include_);
					bitField0_ |= 0x00000008;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder> includeBuilder_;

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> getIncludeList()
			{
				if (includeBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(include_);
				} else
				{
					return includeBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			@Override
			public int getIncludeCount()
			{
				if (includeBuilder_ == null)
				{
					return include_.size();
				} else
				{
					return includeBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getInclude(int index)
			{
				if (includeBuilder_ == null)
				{
					return include_.get(index);
				} else
				{
					return includeBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder setInclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule value)
			{
				if (includeBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureIncludeIsMutable();
					include_.set(index, value);
					onChanged();
				} else
				{
					includeBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder setInclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder builderForValue)
			{
				if (includeBuilder_ == null)
				{
					ensureIncludeIsMutable();
					include_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					includeBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder addInclude(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule value)
			{
				if (includeBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureIncludeIsMutable();
					include_.add(value);
					onChanged();
				} else
				{
					includeBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder addInclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule value)
			{
				if (includeBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureIncludeIsMutable();
					include_.add(index, value);
					onChanged();
				} else
				{
					includeBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder addInclude(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder builderForValue)
			{
				if (includeBuilder_ == null)
				{
					ensureIncludeIsMutable();
					include_.add(builderForValue.build());
					onChanged();
				} else
				{
					includeBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder addInclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder builderForValue)
			{
				if (includeBuilder_ == null)
				{
					ensureIncludeIsMutable();
					include_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					includeBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder addAllInclude(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> values)
			{
				if (includeBuilder_ == null)
				{
					ensureIncludeIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, include_);
					onChanged();
				} else
				{
					includeBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder clearInclude()
			{
				if (includeBuilder_ == null)
				{
					include_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000008);
					onChanged();
				} else
				{
					includeBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public Builder removeInclude(int index)
			{
				if (includeBuilder_ == null)
				{
					ensureIncludeIsMutable();
					include_.remove(index);
					onChanged();
				} else
				{
					includeBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder getIncludeBuilder(
					int index)
			{
				return getIncludeFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder getIncludeOrBuilder(
					int index)
			{
				if (includeBuilder_ == null)
				{
					return include_.get(index);
				} else
				{
					return includeBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
					getIncludeOrBuilderList()
			{
				if (includeBuilder_ != null)
				{
					return includeBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(include_);
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder addIncludeBuilder()
			{
				return getIncludeFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder addIncludeBuilder(
					int index)
			{
				return getIncludeFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetStateRule include = 32;</code>
			 *
			 * <pre>
			 * Rules controlling whether and when a layer is included in the network,
			 * based on the current NetState.  You may specify a non-zero number of rules
			 * to include OR exclude, but not both.  If no include or exclude rules are
			 * specified, the layer is always included.  If the current NetState meets
			 * ANY (i.e., one or more) of the specified rules, the layer is
			 * included/excluded.
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder>
					getIncludeBuilderList()
			{
				return getIncludeFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
					getIncludeFieldBuilder()
			{
				if (includeBuilder_ == null)
				{
					includeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>(
									include_,
									((bitField0_ & 0x00000008) == 0x00000008),
									getParentForChildren(),
									isClean());
					include_ = null;
				}
				return includeBuilder_;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> exclude_ =
					java.util.Collections.emptyList();

			private void ensureExcludeIsMutable()
			{
				if (!((bitField0_ & 0x00000010) == 0x00000010))
				{
					exclude_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule>(exclude_);
					bitField0_ |= 0x00000010;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder> excludeBuilder_;

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> getExcludeList()
			{
				if (excludeBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(exclude_);
				} else
				{
					return excludeBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			@Override
			public int getExcludeCount()
			{
				if (excludeBuilder_ == null)
				{
					return exclude_.size();
				} else
				{
					return excludeBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule getExclude(int index)
			{
				if (excludeBuilder_ == null)
				{
					return exclude_.get(index);
				} else
				{
					return excludeBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder setExclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule value)
			{
				if (excludeBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureExcludeIsMutable();
					exclude_.set(index, value);
					onChanged();
				} else
				{
					excludeBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder setExclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder builderForValue)
			{
				if (excludeBuilder_ == null)
				{
					ensureExcludeIsMutable();
					exclude_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					excludeBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder addExclude(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule value)
			{
				if (excludeBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureExcludeIsMutable();
					exclude_.add(value);
					onChanged();
				} else
				{
					excludeBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder addExclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule value)
			{
				if (excludeBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureExcludeIsMutable();
					exclude_.add(index, value);
					onChanged();
				} else
				{
					excludeBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder addExclude(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder builderForValue)
			{
				if (excludeBuilder_ == null)
				{
					ensureExcludeIsMutable();
					exclude_.add(builderForValue.build());
					onChanged();
				} else
				{
					excludeBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder addExclude(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder builderForValue)
			{
				if (excludeBuilder_ == null)
				{
					ensureExcludeIsMutable();
					exclude_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					excludeBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder addAllExclude(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule> values)
			{
				if (excludeBuilder_ == null)
				{
					ensureExcludeIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, exclude_);
					onChanged();
				} else
				{
					excludeBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder clearExclude()
			{
				if (excludeBuilder_ == null)
				{
					exclude_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000010);
					onChanged();
				} else
				{
					excludeBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public Builder removeExclude(int index)
			{
				if (excludeBuilder_ == null)
				{
					ensureExcludeIsMutable();
					exclude_.remove(index);
					onChanged();
				} else
				{
					excludeBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder getExcludeBuilder(
					int index)
			{
				return getExcludeFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder getExcludeOrBuilder(
					int index)
			{
				if (excludeBuilder_ == null)
				{
					return exclude_.get(index);
				} else
				{
					return excludeBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
					getExcludeOrBuilderList()
			{
				if (excludeBuilder_ != null)
				{
					return excludeBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(exclude_);
				}
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder addExcludeBuilder()
			{
				return getExcludeFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder addExcludeBuilder(
					int index)
			{
				return getExcludeFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.NetStateRule exclude = 33;</code>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder>
					getExcludeBuilderList()
			{
				return getExcludeFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>
					getExcludeFieldBuilder()
			{
				if (excludeBuilder_ == null)
				{
					excludeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRule.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.NetStateRuleOrBuilder>(
									exclude_,
									((bitField0_ & 0x00000010) == 0x00000010),
									getParentForChildren(),
									isClean());
					exclude_ = null;
				}
				return excludeBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType type_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType.NONE;

			/**
			 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
			 *
			 * <pre>
			 * the layer type from the enum above
			 * </pre>
			 */
			@Override
			public boolean hasType()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
			 *
			 * <pre>
			 * the layer type from the enum above
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType getType()
			{
				return type_;
			}

			/**
			 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
			 *
			 * <pre>
			 * the layer type from the enum above
			 * </pre>
			 */
			public Builder setType(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000020;
				type_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.LayerParameter.LayerType type = 5;</code>
			 *
			 * <pre>
			 * the layer type from the enum above
			 * </pre>
			 */
			public Builder clearType()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				type_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.LayerType.NONE;
				onChanged();
				return this;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> blobs_ =
					java.util.Collections.emptyList();

			private void ensureBlobsIsMutable()
			{
				if (!((bitField0_ & 0x00000040) == 0x00000040))
				{
					blobs_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>(blobs_);
					bitField0_ |= 0x00000040;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder> blobsBuilder_;

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getBlobsList()
			{
				if (blobsBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(blobs_);
				} else
				{
					return blobsBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public int getBlobsCount()
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.size();
				} else
				{
					return blobsBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index)
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.get(index);
				} else
				{
					return blobsBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder setBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.set(index, value);
					onChanged();
				} else
				{
					blobsBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder setBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.add(value);
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.add(index, value);
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.add(builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addAllBlobs(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> values)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, blobs_);
					onChanged();
				} else
				{
					blobsBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder clearBlobs()
			{
				if (blobsBuilder_ == null)
				{
					blobs_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000040);
					onChanged();
				} else
				{
					blobsBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder removeBlobs(int index)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.remove(index);
					onChanged();
				} else
				{
					blobsBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder getBlobsBuilder(
					int index)
			{
				return getBlobsFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
					int index)
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.get(index);
				} else
				{
					return blobsBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getBlobsOrBuilderList()
			{
				if (blobsBuilder_ != null)
				{
					return blobsBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(blobs_);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addBlobsBuilder()
			{
				return getBlobsFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addBlobsBuilder(
					int index)
			{
				return getBlobsFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 6;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder>
					getBlobsBuilderList()
			{
				return getBlobsFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getBlobsFieldBuilder()
			{
				if (blobsBuilder_ == null)
				{
					blobsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>(
									blobs_,
									((bitField0_ & 0x00000040) == 0x00000040),
									getParentForChildren(),
									isClean());
					blobs_ = null;
				}
				return blobsBuilder_;
			}

			private com.google.protobuf.LazyStringList param_ = com.google.protobuf.LazyStringArrayList.EMPTY;

			private void ensureParamIsMutable()
			{
				if (!((bitField0_ & 0x00000080) == 0x00000080))
				{
					param_ = new com.google.protobuf.LazyStringArrayList(param_);
					bitField0_ |= 0x00000080;
				}
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ProtocolStringList
					getParamList()
			{
				return param_.getUnmodifiableView();
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			@Override
			public int getParamCount()
			{
				return param_.size();
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			@Override
			public java.lang.String getParam(int index)
			{
				return param_.get(index);
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getParamBytes(int index)
			{
				return param_.getByteString(index);
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			public Builder setParam(
					int index, java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureParamIsMutable();
				param_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			public Builder addParam(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureParamIsMutable();
				param_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			public Builder addAllParam(
					java.lang.Iterable<java.lang.String> values)
			{
				ensureParamIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, param_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			public Builder clearParam()
			{
				param_ = com.google.protobuf.LazyStringArrayList.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000080);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated string param = 1001;</code>
			 *
			 * <pre>
			 * The names of the parameter blobs -- useful for sharing parameters among
			 * layers (but never required).
			 * </pre>
			 */
			public Builder addParamBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureParamIsMutable();
				param_.add(value);
				onChanged();
				return this;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode> blobShareMode_ =
					java.util.Collections.emptyList();

			private void ensureBlobShareModeIsMutable()
			{
				if (!((bitField0_ & 0x00000100) == 0x00000100))
				{
					blobShareMode_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode>(blobShareMode_);
					bitField0_ |= 0x00000100;
				}
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode> getBlobShareModeList()
			{
				return java.util.Collections.unmodifiableList(blobShareMode_);
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			@Override
			public int getBlobShareModeCount()
			{
				return blobShareMode_.size();
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode getBlobShareMode(int index)
			{
				return blobShareMode_.get(index);
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			public Builder setBlobShareMode(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureBlobShareModeIsMutable();
				blobShareMode_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			public Builder addBlobShareMode(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				ensureBlobShareModeIsMutable();
				blobShareMode_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			public Builder addAllBlobShareMode(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LayerParameter.DimCheckMode> values)
			{
				ensureBlobShareModeIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, blobShareMode_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated .caffe.LayerParameter.DimCheckMode blob_share_mode = 1002;</code>
			 *
			 * <pre>
			 * Whether to require shared weights to have the same shape, or just the same
			 * count -- defaults to STRICT if unspecified.
			 * </pre>
			 */
			public Builder clearBlobShareMode()
			{
				blobShareMode_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000100);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> blobsLr_ = java.util.Collections.emptyList();

			private void ensureBlobsLrIsMutable()
			{
				if (!((bitField0_ & 0x00000200) == 0x00000200))
				{
					blobsLr_ = new java.util.ArrayList<java.lang.Float>(blobsLr_);
					bitField0_ |= 0x00000200;
				}
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getBlobsLrList()
			{
				return java.util.Collections.unmodifiableList(blobsLr_);
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			@Override
			public int getBlobsLrCount()
			{
				return blobsLr_.size();
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			@Override
			public float getBlobsLr(int index)
			{
				return blobsLr_.get(index);
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder setBlobsLr(
					int index, float value)
			{
				ensureBlobsLrIsMutable();
				blobsLr_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder addBlobsLr(float value)
			{
				ensureBlobsLrIsMutable();
				blobsLr_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder addAllBlobsLr(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureBlobsLrIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, blobsLr_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float blobs_lr = 7;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder clearBlobsLr()
			{
				blobsLr_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000200);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> weightDecay_ = java.util.Collections.emptyList();

			private void ensureWeightDecayIsMutable()
			{
				if (!((bitField0_ & 0x00000400) == 0x00000400))
				{
					weightDecay_ = new java.util.ArrayList<java.lang.Float>(weightDecay_);
					bitField0_ |= 0x00000400;
				}
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getWeightDecayList()
			{
				return java.util.Collections.unmodifiableList(weightDecay_);
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			@Override
			public int getWeightDecayCount()
			{
				return weightDecay_.size();
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			@Override
			public float getWeightDecay(int index)
			{
				return weightDecay_.get(index);
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder setWeightDecay(
					int index, float value)
			{
				ensureWeightDecayIsMutable();
				weightDecay_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder addWeightDecay(float value)
			{
				ensureWeightDecayIsMutable();
				weightDecay_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder addAllWeightDecay(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureWeightDecayIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, weightDecay_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float weight_decay = 8;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder clearWeightDecay()
			{
				weightDecay_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000400);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> lossWeight_ = java.util.Collections.emptyList();

			private void ensureLossWeightIsMutable()
			{
				if (!((bitField0_ & 0x00000800) == 0x00000800))
				{
					lossWeight_ = new java.util.ArrayList<java.lang.Float>(lossWeight_);
					bitField0_ |= 0x00000800;
				}
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getLossWeightList()
			{
				return java.util.Collections.unmodifiableList(lossWeight_);
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			@Override
			public int getLossWeightCount()
			{
				return lossWeight_.size();
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			@Override
			public float getLossWeight(int index)
			{
				return lossWeight_.get(index);
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			public Builder setLossWeight(
					int index, float value)
			{
				ensureLossWeightIsMutable();
				lossWeight_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			public Builder addLossWeight(float value)
			{
				ensureLossWeightIsMutable();
				lossWeight_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			public Builder addAllLossWeight(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureLossWeightIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, lossWeight_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float loss_weight = 35;</code>
			 *
			 * <pre>
			 * The amount of weight to assign each top blob in the objective.
			 * Each layer assigns a default value, usually of either 0 or 1,
			 * to each top blob.
			 * </pre>
			 */
			public Builder clearLossWeight()
			{
				lossWeight_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000800);
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter accuracyParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder> accuracyParamBuilder_;

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			@Override
			public boolean hasAccuracyParam()
			{
				return ((bitField0_ & 0x00001000) == 0x00001000);
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter getAccuracyParam()
			{
				if (accuracyParamBuilder_ == null)
				{
					return accuracyParam_;
				} else
				{
					return accuracyParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			public Builder setAccuracyParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter value)
			{
				if (accuracyParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					accuracyParam_ = value;
					onChanged();
				} else
				{
					accuracyParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00001000;
				return this;
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			public Builder setAccuracyParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder builderForValue)
			{
				if (accuracyParamBuilder_ == null)
				{
					accuracyParam_ = builderForValue.build();
					onChanged();
				} else
				{
					accuracyParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00001000;
				return this;
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			public Builder mergeAccuracyParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter value)
			{
				if (accuracyParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00001000) == 0x00001000) &&
							accuracyParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.getDefaultInstance())
					{
						accuracyParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.newBuilder(accuracyParam_).mergeFrom(value).buildPartial();
					} else
					{
						accuracyParam_ = value;
					}
					onChanged();
				} else
				{
					accuracyParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00001000;
				return this;
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			public Builder clearAccuracyParam()
			{
				if (accuracyParamBuilder_ == null)
				{
					accuracyParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.getDefaultInstance();
					onChanged();
				} else
				{
					accuracyParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00001000);
				return this;
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder getAccuracyParamBuilder()
			{
				bitField0_ |= 0x00001000;
				onChanged();
				return getAccuracyParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder getAccuracyParamOrBuilder()
			{
				if (accuracyParamBuilder_ != null)
				{
					return accuracyParamBuilder_.getMessageOrBuilder();
				} else
				{
					return accuracyParam_;
				}
			}

			/**
			 * <code>optional .caffe.AccuracyParameter accuracy_param = 27;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder>
					getAccuracyParamFieldBuilder()
			{
				if (accuracyParamBuilder_ == null)
				{
					accuracyParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder>(
									getAccuracyParam(),
									getParentForChildren(),
									isClean());
					accuracyParam_ = null;
				}
				return accuracyParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter argmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder> argmaxParamBuilder_;

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			@Override
			public boolean hasArgmaxParam()
			{
				return ((bitField0_ & 0x00002000) == 0x00002000);
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter getArgmaxParam()
			{
				if (argmaxParamBuilder_ == null)
				{
					return argmaxParam_;
				} else
				{
					return argmaxParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			public Builder setArgmaxParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter value)
			{
				if (argmaxParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					argmaxParam_ = value;
					onChanged();
				} else
				{
					argmaxParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00002000;
				return this;
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			public Builder setArgmaxParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder builderForValue)
			{
				if (argmaxParamBuilder_ == null)
				{
					argmaxParam_ = builderForValue.build();
					onChanged();
				} else
				{
					argmaxParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00002000;
				return this;
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			public Builder mergeArgmaxParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter value)
			{
				if (argmaxParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00002000) == 0x00002000) &&
							argmaxParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.getDefaultInstance())
					{
						argmaxParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.newBuilder(argmaxParam_).mergeFrom(value).buildPartial();
					} else
					{
						argmaxParam_ = value;
					}
					onChanged();
				} else
				{
					argmaxParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00002000;
				return this;
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			public Builder clearArgmaxParam()
			{
				if (argmaxParamBuilder_ == null)
				{
					argmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.getDefaultInstance();
					onChanged();
				} else
				{
					argmaxParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00002000);
				return this;
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder getArgmaxParamBuilder()
			{
				bitField0_ |= 0x00002000;
				onChanged();
				return getArgmaxParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder getArgmaxParamOrBuilder()
			{
				if (argmaxParamBuilder_ != null)
				{
					return argmaxParamBuilder_.getMessageOrBuilder();
				} else
				{
					return argmaxParam_;
				}
			}

			/**
			 * <code>optional .caffe.ArgMaxParameter argmax_param = 23;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder>
					getArgmaxParamFieldBuilder()
			{
				if (argmaxParamBuilder_ == null)
				{
					argmaxParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder>(
									getArgmaxParam(),
									getParentForChildren(),
									isClean());
					argmaxParam_ = null;
				}
				return argmaxParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter concatParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder> concatParamBuilder_;

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			@Override
			public boolean hasConcatParam()
			{
				return ((bitField0_ & 0x00004000) == 0x00004000);
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter getConcatParam()
			{
				if (concatParamBuilder_ == null)
				{
					return concatParam_;
				} else
				{
					return concatParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			public Builder setConcatParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter value)
			{
				if (concatParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					concatParam_ = value;
					onChanged();
				} else
				{
					concatParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00004000;
				return this;
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			public Builder setConcatParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder builderForValue)
			{
				if (concatParamBuilder_ == null)
				{
					concatParam_ = builderForValue.build();
					onChanged();
				} else
				{
					concatParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00004000;
				return this;
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			public Builder mergeConcatParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter value)
			{
				if (concatParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00004000) == 0x00004000) &&
							concatParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.getDefaultInstance())
					{
						concatParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.newBuilder(concatParam_).mergeFrom(value).buildPartial();
					} else
					{
						concatParam_ = value;
					}
					onChanged();
				} else
				{
					concatParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00004000;
				return this;
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			public Builder clearConcatParam()
			{
				if (concatParamBuilder_ == null)
				{
					concatParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.getDefaultInstance();
					onChanged();
				} else
				{
					concatParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00004000);
				return this;
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder getConcatParamBuilder()
			{
				bitField0_ |= 0x00004000;
				onChanged();
				return getConcatParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder getConcatParamOrBuilder()
			{
				if (concatParamBuilder_ != null)
				{
					return concatParamBuilder_.getMessageOrBuilder();
				} else
				{
					return concatParam_;
				}
			}

			/**
			 * <code>optional .caffe.ConcatParameter concat_param = 9;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder>
					getConcatParamFieldBuilder()
			{
				if (concatParamBuilder_ == null)
				{
					concatParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder>(
									getConcatParam(),
									getParentForChildren(),
									isClean());
					concatParam_ = null;
				}
				return concatParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter contrastiveLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder> contrastiveLossParamBuilder_;

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			@Override
			public boolean hasContrastiveLossParam()
			{
				return ((bitField0_ & 0x00008000) == 0x00008000);
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter getContrastiveLossParam()
			{
				if (contrastiveLossParamBuilder_ == null)
				{
					return contrastiveLossParam_;
				} else
				{
					return contrastiveLossParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			public Builder setContrastiveLossParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter value)
			{
				if (contrastiveLossParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					contrastiveLossParam_ = value;
					onChanged();
				} else
				{
					contrastiveLossParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00008000;
				return this;
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			public Builder setContrastiveLossParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder builderForValue)
			{
				if (contrastiveLossParamBuilder_ == null)
				{
					contrastiveLossParam_ = builderForValue.build();
					onChanged();
				} else
				{
					contrastiveLossParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00008000;
				return this;
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			public Builder mergeContrastiveLossParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter value)
			{
				if (contrastiveLossParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00008000) == 0x00008000) &&
							contrastiveLossParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.getDefaultInstance())
					{
						contrastiveLossParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.newBuilder(contrastiveLossParam_).mergeFrom(value).buildPartial();
					} else
					{
						contrastiveLossParam_ = value;
					}
					onChanged();
				} else
				{
					contrastiveLossParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00008000;
				return this;
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			public Builder clearContrastiveLossParam()
			{
				if (contrastiveLossParamBuilder_ == null)
				{
					contrastiveLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.getDefaultInstance();
					onChanged();
				} else
				{
					contrastiveLossParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00008000);
				return this;
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder getContrastiveLossParamBuilder()
			{
				bitField0_ |= 0x00008000;
				onChanged();
				return getContrastiveLossParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder getContrastiveLossParamOrBuilder()
			{
				if (contrastiveLossParamBuilder_ != null)
				{
					return contrastiveLossParamBuilder_.getMessageOrBuilder();
				} else
				{
					return contrastiveLossParam_;
				}
			}

			/**
			 * <code>optional .caffe.ContrastiveLossParameter contrastive_loss_param = 40;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder>
					getContrastiveLossParamFieldBuilder()
			{
				if (contrastiveLossParamBuilder_ == null)
				{
					contrastiveLossParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder>(
									getContrastiveLossParam(),
									getParentForChildren(),
									isClean());
					contrastiveLossParam_ = null;
				}
				return contrastiveLossParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter convolutionParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder> convolutionParamBuilder_;

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			@Override
			public boolean hasConvolutionParam()
			{
				return ((bitField0_ & 0x00010000) == 0x00010000);
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter getConvolutionParam()
			{
				if (convolutionParamBuilder_ == null)
				{
					return convolutionParam_;
				} else
				{
					return convolutionParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			public Builder setConvolutionParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter value)
			{
				if (convolutionParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					convolutionParam_ = value;
					onChanged();
				} else
				{
					convolutionParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00010000;
				return this;
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			public Builder setConvolutionParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder builderForValue)
			{
				if (convolutionParamBuilder_ == null)
				{
					convolutionParam_ = builderForValue.build();
					onChanged();
				} else
				{
					convolutionParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00010000;
				return this;
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			public Builder mergeConvolutionParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter value)
			{
				if (convolutionParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00010000) == 0x00010000) &&
							convolutionParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDefaultInstance())
					{
						convolutionParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.newBuilder(convolutionParam_).mergeFrom(value).buildPartial();
					} else
					{
						convolutionParam_ = value;
					}
					onChanged();
				} else
				{
					convolutionParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00010000;
				return this;
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			public Builder clearConvolutionParam()
			{
				if (convolutionParamBuilder_ == null)
				{
					convolutionParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDefaultInstance();
					onChanged();
				} else
				{
					convolutionParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00010000);
				return this;
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder getConvolutionParamBuilder()
			{
				bitField0_ |= 0x00010000;
				onChanged();
				return getConvolutionParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder getConvolutionParamOrBuilder()
			{
				if (convolutionParamBuilder_ != null)
				{
					return convolutionParamBuilder_.getMessageOrBuilder();
				} else
				{
					return convolutionParam_;
				}
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter convolution_param = 10;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder>
					getConvolutionParamFieldBuilder()
			{
				if (convolutionParamBuilder_ == null)
				{
					convolutionParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder>(
									getConvolutionParam(),
									getParentForChildren(),
									isClean());
					convolutionParam_ = null;
				}
				return convolutionParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter dataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder> dataParamBuilder_;

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			@Override
			public boolean hasDataParam()
			{
				return ((bitField0_ & 0x00020000) == 0x00020000);
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter getDataParam()
			{
				if (dataParamBuilder_ == null)
				{
					return dataParam_;
				} else
				{
					return dataParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			public Builder setDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter value)
			{
				if (dataParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					dataParam_ = value;
					onChanged();
				} else
				{
					dataParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00020000;
				return this;
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			public Builder setDataParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder builderForValue)
			{
				if (dataParamBuilder_ == null)
				{
					dataParam_ = builderForValue.build();
					onChanged();
				} else
				{
					dataParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00020000;
				return this;
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			public Builder mergeDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter value)
			{
				if (dataParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00020000) == 0x00020000) &&
							dataParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDefaultInstance())
					{
						dataParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.newBuilder(dataParam_).mergeFrom(value).buildPartial();
					} else
					{
						dataParam_ = value;
					}
					onChanged();
				} else
				{
					dataParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00020000;
				return this;
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			public Builder clearDataParam()
			{
				if (dataParamBuilder_ == null)
				{
					dataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDefaultInstance();
					onChanged();
				} else
				{
					dataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00020000);
				return this;
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder getDataParamBuilder()
			{
				bitField0_ |= 0x00020000;
				onChanged();
				return getDataParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder getDataParamOrBuilder()
			{
				if (dataParamBuilder_ != null)
				{
					return dataParamBuilder_.getMessageOrBuilder();
				} else
				{
					return dataParam_;
				}
			}

			/**
			 * <code>optional .caffe.DataParameter data_param = 11;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder>
					getDataParamFieldBuilder()
			{
				if (dataParamBuilder_ == null)
				{
					dataParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder>(
									getDataParam(),
									getParentForChildren(),
									isClean());
					dataParam_ = null;
				}
				return dataParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter dropoutParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder> dropoutParamBuilder_;

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			@Override
			public boolean hasDropoutParam()
			{
				return ((bitField0_ & 0x00040000) == 0x00040000);
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter getDropoutParam()
			{
				if (dropoutParamBuilder_ == null)
				{
					return dropoutParam_;
				} else
				{
					return dropoutParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			public Builder setDropoutParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter value)
			{
				if (dropoutParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					dropoutParam_ = value;
					onChanged();
				} else
				{
					dropoutParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00040000;
				return this;
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			public Builder setDropoutParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder builderForValue)
			{
				if (dropoutParamBuilder_ == null)
				{
					dropoutParam_ = builderForValue.build();
					onChanged();
				} else
				{
					dropoutParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00040000;
				return this;
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			public Builder mergeDropoutParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter value)
			{
				if (dropoutParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00040000) == 0x00040000) &&
							dropoutParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.getDefaultInstance())
					{
						dropoutParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.newBuilder(dropoutParam_).mergeFrom(value).buildPartial();
					} else
					{
						dropoutParam_ = value;
					}
					onChanged();
				} else
				{
					dropoutParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00040000;
				return this;
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			public Builder clearDropoutParam()
			{
				if (dropoutParamBuilder_ == null)
				{
					dropoutParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.getDefaultInstance();
					onChanged();
				} else
				{
					dropoutParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00040000);
				return this;
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder getDropoutParamBuilder()
			{
				bitField0_ |= 0x00040000;
				onChanged();
				return getDropoutParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder getDropoutParamOrBuilder()
			{
				if (dropoutParamBuilder_ != null)
				{
					return dropoutParamBuilder_.getMessageOrBuilder();
				} else
				{
					return dropoutParam_;
				}
			}

			/**
			 * <code>optional .caffe.DropoutParameter dropout_param = 12;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder>
					getDropoutParamFieldBuilder()
			{
				if (dropoutParamBuilder_ == null)
				{
					dropoutParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder>(
									getDropoutParam(),
									getParentForChildren(),
									isClean());
					dropoutParam_ = null;
				}
				return dropoutParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter dummyDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder> dummyDataParamBuilder_;

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			@Override
			public boolean hasDummyDataParam()
			{
				return ((bitField0_ & 0x00080000) == 0x00080000);
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter getDummyDataParam()
			{
				if (dummyDataParamBuilder_ == null)
				{
					return dummyDataParam_;
				} else
				{
					return dummyDataParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			public Builder setDummyDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter value)
			{
				if (dummyDataParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					dummyDataParam_ = value;
					onChanged();
				} else
				{
					dummyDataParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00080000;
				return this;
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			public Builder setDummyDataParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder builderForValue)
			{
				if (dummyDataParamBuilder_ == null)
				{
					dummyDataParam_ = builderForValue.build();
					onChanged();
				} else
				{
					dummyDataParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00080000;
				return this;
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			public Builder mergeDummyDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter value)
			{
				if (dummyDataParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00080000) == 0x00080000) &&
							dummyDataParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.getDefaultInstance())
					{
						dummyDataParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.newBuilder(dummyDataParam_).mergeFrom(value).buildPartial();
					} else
					{
						dummyDataParam_ = value;
					}
					onChanged();
				} else
				{
					dummyDataParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00080000;
				return this;
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			public Builder clearDummyDataParam()
			{
				if (dummyDataParamBuilder_ == null)
				{
					dummyDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.getDefaultInstance();
					onChanged();
				} else
				{
					dummyDataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00080000);
				return this;
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder getDummyDataParamBuilder()
			{
				bitField0_ |= 0x00080000;
				onChanged();
				return getDummyDataParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder getDummyDataParamOrBuilder()
			{
				if (dummyDataParamBuilder_ != null)
				{
					return dummyDataParamBuilder_.getMessageOrBuilder();
				} else
				{
					return dummyDataParam_;
				}
			}

			/**
			 * <code>optional .caffe.DummyDataParameter dummy_data_param = 26;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder>
					getDummyDataParamFieldBuilder()
			{
				if (dummyDataParamBuilder_ == null)
				{
					dummyDataParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder>(
									getDummyDataParam(),
									getParentForChildren(),
									isClean());
					dummyDataParam_ = null;
				}
				return dummyDataParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter eltwiseParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder> eltwiseParamBuilder_;

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			@Override
			public boolean hasEltwiseParam()
			{
				return ((bitField0_ & 0x00100000) == 0x00100000);
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter getEltwiseParam()
			{
				if (eltwiseParamBuilder_ == null)
				{
					return eltwiseParam_;
				} else
				{
					return eltwiseParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			public Builder setEltwiseParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter value)
			{
				if (eltwiseParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					eltwiseParam_ = value;
					onChanged();
				} else
				{
					eltwiseParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00100000;
				return this;
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			public Builder setEltwiseParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder builderForValue)
			{
				if (eltwiseParamBuilder_ == null)
				{
					eltwiseParam_ = builderForValue.build();
					onChanged();
				} else
				{
					eltwiseParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00100000;
				return this;
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			public Builder mergeEltwiseParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter value)
			{
				if (eltwiseParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00100000) == 0x00100000) &&
							eltwiseParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDefaultInstance())
					{
						eltwiseParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.newBuilder(eltwiseParam_).mergeFrom(value).buildPartial();
					} else
					{
						eltwiseParam_ = value;
					}
					onChanged();
				} else
				{
					eltwiseParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00100000;
				return this;
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			public Builder clearEltwiseParam()
			{
				if (eltwiseParamBuilder_ == null)
				{
					eltwiseParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDefaultInstance();
					onChanged();
				} else
				{
					eltwiseParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00100000);
				return this;
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder getEltwiseParamBuilder()
			{
				bitField0_ |= 0x00100000;
				onChanged();
				return getEltwiseParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder getEltwiseParamOrBuilder()
			{
				if (eltwiseParamBuilder_ != null)
				{
					return eltwiseParamBuilder_.getMessageOrBuilder();
				} else
				{
					return eltwiseParam_;
				}
			}

			/**
			 * <code>optional .caffe.EltwiseParameter eltwise_param = 24;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder>
					getEltwiseParamFieldBuilder()
			{
				if (eltwiseParamBuilder_ == null)
				{
					eltwiseParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder>(
									getEltwiseParam(),
									getParentForChildren(),
									isClean());
					eltwiseParam_ = null;
				}
				return eltwiseParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter hdf5DataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder> hdf5DataParamBuilder_;

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			@Override
			public boolean hasHdf5DataParam()
			{
				return ((bitField0_ & 0x00200000) == 0x00200000);
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter getHdf5DataParam()
			{
				if (hdf5DataParamBuilder_ == null)
				{
					return hdf5DataParam_;
				} else
				{
					return hdf5DataParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			public Builder setHdf5DataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter value)
			{
				if (hdf5DataParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					hdf5DataParam_ = value;
					onChanged();
				} else
				{
					hdf5DataParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00200000;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			public Builder setHdf5DataParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder builderForValue)
			{
				if (hdf5DataParamBuilder_ == null)
				{
					hdf5DataParam_ = builderForValue.build();
					onChanged();
				} else
				{
					hdf5DataParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00200000;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			public Builder mergeHdf5DataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter value)
			{
				if (hdf5DataParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00200000) == 0x00200000) &&
							hdf5DataParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.getDefaultInstance())
					{
						hdf5DataParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.newBuilder(hdf5DataParam_).mergeFrom(value).buildPartial();
					} else
					{
						hdf5DataParam_ = value;
					}
					onChanged();
				} else
				{
					hdf5DataParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00200000;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			public Builder clearHdf5DataParam()
			{
				if (hdf5DataParamBuilder_ == null)
				{
					hdf5DataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.getDefaultInstance();
					onChanged();
				} else
				{
					hdf5DataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00200000);
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder getHdf5DataParamBuilder()
			{
				bitField0_ |= 0x00200000;
				onChanged();
				return getHdf5DataParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder getHdf5DataParamOrBuilder()
			{
				if (hdf5DataParamBuilder_ != null)
				{
					return hdf5DataParamBuilder_.getMessageOrBuilder();
				} else
				{
					return hdf5DataParam_;
				}
			}

			/**
			 * <code>optional .caffe.HDF5DataParameter hdf5_data_param = 13;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder>
					getHdf5DataParamFieldBuilder()
			{
				if (hdf5DataParamBuilder_ == null)
				{
					hdf5DataParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder>(
									getHdf5DataParam(),
									getParentForChildren(),
									isClean());
					hdf5DataParam_ = null;
				}
				return hdf5DataParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder> hdf5OutputParamBuilder_;

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			@Override
			public boolean hasHdf5OutputParam()
			{
				return ((bitField0_ & 0x00400000) == 0x00400000);
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getHdf5OutputParam()
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					return hdf5OutputParam_;
				} else
				{
					return hdf5OutputParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			public Builder setHdf5OutputParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter value)
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					hdf5OutputParam_ = value;
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00400000;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			public Builder setHdf5OutputParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder builderForValue)
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParam_ = builderForValue.build();
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00400000;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			public Builder mergeHdf5OutputParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter value)
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00400000) == 0x00400000) &&
							hdf5OutputParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance())
					{
						hdf5OutputParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.newBuilder(hdf5OutputParam_).mergeFrom(value).buildPartial();
					} else
					{
						hdf5OutputParam_ = value;
					}
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00400000;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			public Builder clearHdf5OutputParam()
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00400000);
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder getHdf5OutputParamBuilder()
			{
				bitField0_ |= 0x00400000;
				onChanged();
				return getHdf5OutputParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder getHdf5OutputParamOrBuilder()
			{
				if (hdf5OutputParamBuilder_ != null)
				{
					return hdf5OutputParamBuilder_.getMessageOrBuilder();
				} else
				{
					return hdf5OutputParam_;
				}
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 14;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder>
					getHdf5OutputParamFieldBuilder()
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder>(
									getHdf5OutputParam(),
									getParentForChildren(),
									isClean());
					hdf5OutputParam_ = null;
				}
				return hdf5OutputParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter hingeLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder> hingeLossParamBuilder_;

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			@Override
			public boolean hasHingeLossParam()
			{
				return ((bitField0_ & 0x00800000) == 0x00800000);
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter getHingeLossParam()
			{
				if (hingeLossParamBuilder_ == null)
				{
					return hingeLossParam_;
				} else
				{
					return hingeLossParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			public Builder setHingeLossParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter value)
			{
				if (hingeLossParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					hingeLossParam_ = value;
					onChanged();
				} else
				{
					hingeLossParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00800000;
				return this;
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			public Builder setHingeLossParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder builderForValue)
			{
				if (hingeLossParamBuilder_ == null)
				{
					hingeLossParam_ = builderForValue.build();
					onChanged();
				} else
				{
					hingeLossParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00800000;
				return this;
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			public Builder mergeHingeLossParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter value)
			{
				if (hingeLossParamBuilder_ == null)
				{
					if (((bitField0_ & 0x00800000) == 0x00800000) &&
							hingeLossParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDefaultInstance())
					{
						hingeLossParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.newBuilder(hingeLossParam_).mergeFrom(value).buildPartial();
					} else
					{
						hingeLossParam_ = value;
					}
					onChanged();
				} else
				{
					hingeLossParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00800000;
				return this;
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			public Builder clearHingeLossParam()
			{
				if (hingeLossParamBuilder_ == null)
				{
					hingeLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDefaultInstance();
					onChanged();
				} else
				{
					hingeLossParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00800000);
				return this;
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder getHingeLossParamBuilder()
			{
				bitField0_ |= 0x00800000;
				onChanged();
				return getHingeLossParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder getHingeLossParamOrBuilder()
			{
				if (hingeLossParamBuilder_ != null)
				{
					return hingeLossParamBuilder_.getMessageOrBuilder();
				} else
				{
					return hingeLossParam_;
				}
			}

			/**
			 * <code>optional .caffe.HingeLossParameter hinge_loss_param = 29;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder>
					getHingeLossParamFieldBuilder()
			{
				if (hingeLossParamBuilder_ == null)
				{
					hingeLossParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder>(
									getHingeLossParam(),
									getParentForChildren(),
									isClean());
					hingeLossParam_ = null;
				}
				return hingeLossParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter imageDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder> imageDataParamBuilder_;

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			@Override
			public boolean hasImageDataParam()
			{
				return ((bitField0_ & 0x01000000) == 0x01000000);
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter getImageDataParam()
			{
				if (imageDataParamBuilder_ == null)
				{
					return imageDataParam_;
				} else
				{
					return imageDataParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			public Builder setImageDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter value)
			{
				if (imageDataParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					imageDataParam_ = value;
					onChanged();
				} else
				{
					imageDataParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x01000000;
				return this;
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			public Builder setImageDataParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder builderForValue)
			{
				if (imageDataParamBuilder_ == null)
				{
					imageDataParam_ = builderForValue.build();
					onChanged();
				} else
				{
					imageDataParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x01000000;
				return this;
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			public Builder mergeImageDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter value)
			{
				if (imageDataParamBuilder_ == null)
				{
					if (((bitField0_ & 0x01000000) == 0x01000000) &&
							imageDataParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.getDefaultInstance())
					{
						imageDataParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.newBuilder(imageDataParam_).mergeFrom(value).buildPartial();
					} else
					{
						imageDataParam_ = value;
					}
					onChanged();
				} else
				{
					imageDataParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x01000000;
				return this;
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			public Builder clearImageDataParam()
			{
				if (imageDataParamBuilder_ == null)
				{
					imageDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.getDefaultInstance();
					onChanged();
				} else
				{
					imageDataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x01000000);
				return this;
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder getImageDataParamBuilder()
			{
				bitField0_ |= 0x01000000;
				onChanged();
				return getImageDataParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder getImageDataParamOrBuilder()
			{
				if (imageDataParamBuilder_ != null)
				{
					return imageDataParamBuilder_.getMessageOrBuilder();
				} else
				{
					return imageDataParam_;
				}
			}

			/**
			 * <code>optional .caffe.ImageDataParameter image_data_param = 15;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder>
					getImageDataParamFieldBuilder()
			{
				if (imageDataParamBuilder_ == null)
				{
					imageDataParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder>(
									getImageDataParam(),
									getParentForChildren(),
									isClean());
					imageDataParam_ = null;
				}
				return imageDataParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter infogainLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder> infogainLossParamBuilder_;

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			@Override
			public boolean hasInfogainLossParam()
			{
				return ((bitField0_ & 0x02000000) == 0x02000000);
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter getInfogainLossParam()
			{
				if (infogainLossParamBuilder_ == null)
				{
					return infogainLossParam_;
				} else
				{
					return infogainLossParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			public Builder setInfogainLossParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter value)
			{
				if (infogainLossParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					infogainLossParam_ = value;
					onChanged();
				} else
				{
					infogainLossParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x02000000;
				return this;
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			public Builder setInfogainLossParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder builderForValue)
			{
				if (infogainLossParamBuilder_ == null)
				{
					infogainLossParam_ = builderForValue.build();
					onChanged();
				} else
				{
					infogainLossParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x02000000;
				return this;
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			public Builder mergeInfogainLossParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter value)
			{
				if (infogainLossParamBuilder_ == null)
				{
					if (((bitField0_ & 0x02000000) == 0x02000000) &&
							infogainLossParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.getDefaultInstance())
					{
						infogainLossParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.newBuilder(infogainLossParam_).mergeFrom(value).buildPartial();
					} else
					{
						infogainLossParam_ = value;
					}
					onChanged();
				} else
				{
					infogainLossParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x02000000;
				return this;
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			public Builder clearInfogainLossParam()
			{
				if (infogainLossParamBuilder_ == null)
				{
					infogainLossParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.getDefaultInstance();
					onChanged();
				} else
				{
					infogainLossParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x02000000);
				return this;
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder getInfogainLossParamBuilder()
			{
				bitField0_ |= 0x02000000;
				onChanged();
				return getInfogainLossParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder getInfogainLossParamOrBuilder()
			{
				if (infogainLossParamBuilder_ != null)
				{
					return infogainLossParamBuilder_.getMessageOrBuilder();
				} else
				{
					return infogainLossParam_;
				}
			}

			/**
			 * <code>optional .caffe.InfogainLossParameter infogain_loss_param = 16;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder>
					getInfogainLossParamFieldBuilder()
			{
				if (infogainLossParamBuilder_ == null)
				{
					infogainLossParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder>(
									getInfogainLossParam(),
									getParentForChildren(),
									isClean());
					infogainLossParam_ = null;
				}
				return infogainLossParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter innerProductParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder> innerProductParamBuilder_;

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			@Override
			public boolean hasInnerProductParam()
			{
				return ((bitField0_ & 0x04000000) == 0x04000000);
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter getInnerProductParam()
			{
				if (innerProductParamBuilder_ == null)
				{
					return innerProductParam_;
				} else
				{
					return innerProductParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			public Builder setInnerProductParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter value)
			{
				if (innerProductParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					innerProductParam_ = value;
					onChanged();
				} else
				{
					innerProductParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x04000000;
				return this;
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			public Builder setInnerProductParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder builderForValue)
			{
				if (innerProductParamBuilder_ == null)
				{
					innerProductParam_ = builderForValue.build();
					onChanged();
				} else
				{
					innerProductParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x04000000;
				return this;
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			public Builder mergeInnerProductParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter value)
			{
				if (innerProductParamBuilder_ == null)
				{
					if (((bitField0_ & 0x04000000) == 0x04000000) &&
							innerProductParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.getDefaultInstance())
					{
						innerProductParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.newBuilder(innerProductParam_).mergeFrom(value).buildPartial();
					} else
					{
						innerProductParam_ = value;
					}
					onChanged();
				} else
				{
					innerProductParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x04000000;
				return this;
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			public Builder clearInnerProductParam()
			{
				if (innerProductParamBuilder_ == null)
				{
					innerProductParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.getDefaultInstance();
					onChanged();
				} else
				{
					innerProductParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x04000000);
				return this;
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder getInnerProductParamBuilder()
			{
				bitField0_ |= 0x04000000;
				onChanged();
				return getInnerProductParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder getInnerProductParamOrBuilder()
			{
				if (innerProductParamBuilder_ != null)
				{
					return innerProductParamBuilder_.getMessageOrBuilder();
				} else
				{
					return innerProductParam_;
				}
			}

			/**
			 * <code>optional .caffe.InnerProductParameter inner_product_param = 17;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder>
					getInnerProductParamFieldBuilder()
			{
				if (innerProductParamBuilder_ == null)
				{
					innerProductParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder>(
									getInnerProductParam(),
									getParentForChildren(),
									isClean());
					innerProductParam_ = null;
				}
				return innerProductParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter lrnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder> lrnParamBuilder_;

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			@Override
			public boolean hasLrnParam()
			{
				return ((bitField0_ & 0x08000000) == 0x08000000);
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter getLrnParam()
			{
				if (lrnParamBuilder_ == null)
				{
					return lrnParam_;
				} else
				{
					return lrnParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			public Builder setLrnParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter value)
			{
				if (lrnParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					lrnParam_ = value;
					onChanged();
				} else
				{
					lrnParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x08000000;
				return this;
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			public Builder setLrnParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder builderForValue)
			{
				if (lrnParamBuilder_ == null)
				{
					lrnParam_ = builderForValue.build();
					onChanged();
				} else
				{
					lrnParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x08000000;
				return this;
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			public Builder mergeLrnParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter value)
			{
				if (lrnParamBuilder_ == null)
				{
					if (((bitField0_ & 0x08000000) == 0x08000000) &&
							lrnParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDefaultInstance())
					{
						lrnParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.newBuilder(lrnParam_).mergeFrom(value).buildPartial();
					} else
					{
						lrnParam_ = value;
					}
					onChanged();
				} else
				{
					lrnParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x08000000;
				return this;
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			public Builder clearLrnParam()
			{
				if (lrnParamBuilder_ == null)
				{
					lrnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDefaultInstance();
					onChanged();
				} else
				{
					lrnParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x08000000);
				return this;
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder getLrnParamBuilder()
			{
				bitField0_ |= 0x08000000;
				onChanged();
				return getLrnParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder getLrnParamOrBuilder()
			{
				if (lrnParamBuilder_ != null)
				{
					return lrnParamBuilder_.getMessageOrBuilder();
				} else
				{
					return lrnParam_;
				}
			}

			/**
			 * <code>optional .caffe.LRNParameter lrn_param = 18;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder>
					getLrnParamFieldBuilder()
			{
				if (lrnParamBuilder_ == null)
				{
					lrnParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder>(
									getLrnParam(),
									getParentForChildren(),
									isClean());
					lrnParam_ = null;
				}
				return lrnParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter memoryDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder> memoryDataParamBuilder_;

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			@Override
			public boolean hasMemoryDataParam()
			{
				return ((bitField0_ & 0x10000000) == 0x10000000);
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter getMemoryDataParam()
			{
				if (memoryDataParamBuilder_ == null)
				{
					return memoryDataParam_;
				} else
				{
					return memoryDataParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			public Builder setMemoryDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter value)
			{
				if (memoryDataParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					memoryDataParam_ = value;
					onChanged();
				} else
				{
					memoryDataParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x10000000;
				return this;
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			public Builder setMemoryDataParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder builderForValue)
			{
				if (memoryDataParamBuilder_ == null)
				{
					memoryDataParam_ = builderForValue.build();
					onChanged();
				} else
				{
					memoryDataParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x10000000;
				return this;
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			public Builder mergeMemoryDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter value)
			{
				if (memoryDataParamBuilder_ == null)
				{
					if (((bitField0_ & 0x10000000) == 0x10000000) &&
							memoryDataParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.getDefaultInstance())
					{
						memoryDataParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.newBuilder(memoryDataParam_).mergeFrom(value).buildPartial();
					} else
					{
						memoryDataParam_ = value;
					}
					onChanged();
				} else
				{
					memoryDataParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x10000000;
				return this;
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			public Builder clearMemoryDataParam()
			{
				if (memoryDataParamBuilder_ == null)
				{
					memoryDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.getDefaultInstance();
					onChanged();
				} else
				{
					memoryDataParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x10000000);
				return this;
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder getMemoryDataParamBuilder()
			{
				bitField0_ |= 0x10000000;
				onChanged();
				return getMemoryDataParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder getMemoryDataParamOrBuilder()
			{
				if (memoryDataParamBuilder_ != null)
				{
					return memoryDataParamBuilder_.getMessageOrBuilder();
				} else
				{
					return memoryDataParam_;
				}
			}

			/**
			 * <code>optional .caffe.MemoryDataParameter memory_data_param = 22;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder>
					getMemoryDataParamFieldBuilder()
			{
				if (memoryDataParamBuilder_ == null)
				{
					memoryDataParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder>(
									getMemoryDataParam(),
									getParentForChildren(),
									isClean());
					memoryDataParam_ = null;
				}
				return memoryDataParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter mvnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder> mvnParamBuilder_;

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			@Override
			public boolean hasMvnParam()
			{
				return ((bitField0_ & 0x20000000) == 0x20000000);
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter getMvnParam()
			{
				if (mvnParamBuilder_ == null)
				{
					return mvnParam_;
				} else
				{
					return mvnParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			public Builder setMvnParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter value)
			{
				if (mvnParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					mvnParam_ = value;
					onChanged();
				} else
				{
					mvnParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x20000000;
				return this;
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			public Builder setMvnParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder builderForValue)
			{
				if (mvnParamBuilder_ == null)
				{
					mvnParam_ = builderForValue.build();
					onChanged();
				} else
				{
					mvnParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x20000000;
				return this;
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			public Builder mergeMvnParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter value)
			{
				if (mvnParamBuilder_ == null)
				{
					if (((bitField0_ & 0x20000000) == 0x20000000) &&
							mvnParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.getDefaultInstance())
					{
						mvnParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.newBuilder(mvnParam_).mergeFrom(value).buildPartial();
					} else
					{
						mvnParam_ = value;
					}
					onChanged();
				} else
				{
					mvnParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x20000000;
				return this;
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			public Builder clearMvnParam()
			{
				if (mvnParamBuilder_ == null)
				{
					mvnParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.getDefaultInstance();
					onChanged();
				} else
				{
					mvnParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x20000000);
				return this;
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder getMvnParamBuilder()
			{
				bitField0_ |= 0x20000000;
				onChanged();
				return getMvnParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder getMvnParamOrBuilder()
			{
				if (mvnParamBuilder_ != null)
				{
					return mvnParamBuilder_.getMessageOrBuilder();
				} else
				{
					return mvnParam_;
				}
			}

			/**
			 * <code>optional .caffe.MVNParameter mvn_param = 34;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder>
					getMvnParamFieldBuilder()
			{
				if (mvnParamBuilder_ == null)
				{
					mvnParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder>(
									getMvnParam(),
									getParentForChildren(),
									isClean());
					mvnParam_ = null;
				}
				return mvnParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter poolingParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder> poolingParamBuilder_;

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			@Override
			public boolean hasPoolingParam()
			{
				return ((bitField0_ & 0x40000000) == 0x40000000);
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter getPoolingParam()
			{
				if (poolingParamBuilder_ == null)
				{
					return poolingParam_;
				} else
				{
					return poolingParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			public Builder setPoolingParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter value)
			{
				if (poolingParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					poolingParam_ = value;
					onChanged();
				} else
				{
					poolingParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x40000000;
				return this;
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			public Builder setPoolingParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder builderForValue)
			{
				if (poolingParamBuilder_ == null)
				{
					poolingParam_ = builderForValue.build();
					onChanged();
				} else
				{
					poolingParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x40000000;
				return this;
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			public Builder mergePoolingParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter value)
			{
				if (poolingParamBuilder_ == null)
				{
					if (((bitField0_ & 0x40000000) == 0x40000000) &&
							poolingParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDefaultInstance())
					{
						poolingParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.newBuilder(poolingParam_).mergeFrom(value).buildPartial();
					} else
					{
						poolingParam_ = value;
					}
					onChanged();
				} else
				{
					poolingParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x40000000;
				return this;
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			public Builder clearPoolingParam()
			{
				if (poolingParamBuilder_ == null)
				{
					poolingParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDefaultInstance();
					onChanged();
				} else
				{
					poolingParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x40000000);
				return this;
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder getPoolingParamBuilder()
			{
				bitField0_ |= 0x40000000;
				onChanged();
				return getPoolingParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder getPoolingParamOrBuilder()
			{
				if (poolingParamBuilder_ != null)
				{
					return poolingParamBuilder_.getMessageOrBuilder();
				} else
				{
					return poolingParam_;
				}
			}

			/**
			 * <code>optional .caffe.PoolingParameter pooling_param = 19;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder>
					getPoolingParamFieldBuilder()
			{
				if (poolingParamBuilder_ == null)
				{
					poolingParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder>(
									getPoolingParam(),
									getParentForChildren(),
									isClean());
					poolingParam_ = null;
				}
				return poolingParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter powerParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder> powerParamBuilder_;

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			@Override
			public boolean hasPowerParam()
			{
				return ((bitField0_ & 0x80000000) == 0x80000000);
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter getPowerParam()
			{
				if (powerParamBuilder_ == null)
				{
					return powerParam_;
				} else
				{
					return powerParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			public Builder setPowerParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter value)
			{
				if (powerParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					powerParam_ = value;
					onChanged();
				} else
				{
					powerParamBuilder_.setMessage(value);
				}
				bitField0_ |= 0x80000000;
				return this;
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			public Builder setPowerParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder builderForValue)
			{
				if (powerParamBuilder_ == null)
				{
					powerParam_ = builderForValue.build();
					onChanged();
				} else
				{
					powerParamBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x80000000;
				return this;
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			public Builder mergePowerParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter value)
			{
				if (powerParamBuilder_ == null)
				{
					if (((bitField0_ & 0x80000000) == 0x80000000) &&
							powerParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.getDefaultInstance())
					{
						powerParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.newBuilder(powerParam_).mergeFrom(value).buildPartial();
					} else
					{
						powerParam_ = value;
					}
					onChanged();
				} else
				{
					powerParamBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x80000000;
				return this;
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			public Builder clearPowerParam()
			{
				if (powerParamBuilder_ == null)
				{
					powerParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					powerParamBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x80000000);
				return this;
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder getPowerParamBuilder()
			{
				bitField0_ |= 0x80000000;
				onChanged();
				return getPowerParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder getPowerParamOrBuilder()
			{
				if (powerParamBuilder_ != null)
				{
					return powerParamBuilder_.getMessageOrBuilder();
				} else
				{
					return powerParam_;
				}
			}

			/**
			 * <code>optional .caffe.PowerParameter power_param = 21;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder>
					getPowerParamFieldBuilder()
			{
				if (powerParamBuilder_ == null)
				{
					powerParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder>(
									getPowerParam(),
									getParentForChildren(),
									isClean());
					powerParam_ = null;
				}
				return powerParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter reluParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder> reluParamBuilder_;

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			@Override
			public boolean hasReluParam()
			{
				return ((bitField1_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter getReluParam()
			{
				if (reluParamBuilder_ == null)
				{
					return reluParam_;
				} else
				{
					return reluParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			public Builder setReluParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter value)
			{
				if (reluParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					reluParam_ = value;
					onChanged();
				} else
				{
					reluParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000001;
				return this;
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			public Builder setReluParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder builderForValue)
			{
				if (reluParamBuilder_ == null)
				{
					reluParam_ = builderForValue.build();
					onChanged();
				} else
				{
					reluParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000001;
				return this;
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			public Builder mergeReluParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter value)
			{
				if (reluParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000001) == 0x00000001) &&
							reluParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDefaultInstance())
					{
						reluParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.newBuilder(reluParam_).mergeFrom(value).buildPartial();
					} else
					{
						reluParam_ = value;
					}
					onChanged();
				} else
				{
					reluParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000001;
				return this;
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			public Builder clearReluParam()
			{
				if (reluParamBuilder_ == null)
				{
					reluParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDefaultInstance();
					onChanged();
				} else
				{
					reluParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000001);
				return this;
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder getReluParamBuilder()
			{
				bitField1_ |= 0x00000001;
				onChanged();
				return getReluParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder getReluParamOrBuilder()
			{
				if (reluParamBuilder_ != null)
				{
					return reluParamBuilder_.getMessageOrBuilder();
				} else
				{
					return reluParam_;
				}
			}

			/**
			 * <code>optional .caffe.ReLUParameter relu_param = 30;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder>
					getReluParamFieldBuilder()
			{
				if (reluParamBuilder_ == null)
				{
					reluParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder>(
									getReluParam(),
									getParentForChildren(),
									isClean());
					reluParam_ = null;
				}
				return reluParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter sigmoidParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder> sigmoidParamBuilder_;

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			@Override
			public boolean hasSigmoidParam()
			{
				return ((bitField1_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter getSigmoidParam()
			{
				if (sigmoidParamBuilder_ == null)
				{
					return sigmoidParam_;
				} else
				{
					return sigmoidParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			public Builder setSigmoidParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter value)
			{
				if (sigmoidParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					sigmoidParam_ = value;
					onChanged();
				} else
				{
					sigmoidParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000002;
				return this;
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			public Builder setSigmoidParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder builderForValue)
			{
				if (sigmoidParamBuilder_ == null)
				{
					sigmoidParam_ = builderForValue.build();
					onChanged();
				} else
				{
					sigmoidParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000002;
				return this;
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			public Builder mergeSigmoidParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter value)
			{
				if (sigmoidParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000002) == 0x00000002) &&
							sigmoidParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDefaultInstance())
					{
						sigmoidParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.newBuilder(sigmoidParam_).mergeFrom(value).buildPartial();
					} else
					{
						sigmoidParam_ = value;
					}
					onChanged();
				} else
				{
					sigmoidParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000002;
				return this;
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			public Builder clearSigmoidParam()
			{
				if (sigmoidParamBuilder_ == null)
				{
					sigmoidParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDefaultInstance();
					onChanged();
				} else
				{
					sigmoidParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000002);
				return this;
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder getSigmoidParamBuilder()
			{
				bitField1_ |= 0x00000002;
				onChanged();
				return getSigmoidParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder getSigmoidParamOrBuilder()
			{
				if (sigmoidParamBuilder_ != null)
				{
					return sigmoidParamBuilder_.getMessageOrBuilder();
				} else
				{
					return sigmoidParam_;
				}
			}

			/**
			 * <code>optional .caffe.SigmoidParameter sigmoid_param = 38;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder>
					getSigmoidParamFieldBuilder()
			{
				if (sigmoidParamBuilder_ == null)
				{
					sigmoidParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder>(
									getSigmoidParam(),
									getParentForChildren(),
									isClean());
					sigmoidParam_ = null;
				}
				return sigmoidParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter softmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder> softmaxParamBuilder_;

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			@Override
			public boolean hasSoftmaxParam()
			{
				return ((bitField1_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter getSoftmaxParam()
			{
				if (softmaxParamBuilder_ == null)
				{
					return softmaxParam_;
				} else
				{
					return softmaxParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			public Builder setSoftmaxParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter value)
			{
				if (softmaxParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					softmaxParam_ = value;
					onChanged();
				} else
				{
					softmaxParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000004;
				return this;
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			public Builder setSoftmaxParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder builderForValue)
			{
				if (softmaxParamBuilder_ == null)
				{
					softmaxParam_ = builderForValue.build();
					onChanged();
				} else
				{
					softmaxParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000004;
				return this;
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			public Builder mergeSoftmaxParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter value)
			{
				if (softmaxParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000004) == 0x00000004) &&
							softmaxParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDefaultInstance())
					{
						softmaxParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.newBuilder(softmaxParam_).mergeFrom(value).buildPartial();
					} else
					{
						softmaxParam_ = value;
					}
					onChanged();
				} else
				{
					softmaxParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000004;
				return this;
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			public Builder clearSoftmaxParam()
			{
				if (softmaxParamBuilder_ == null)
				{
					softmaxParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDefaultInstance();
					onChanged();
				} else
				{
					softmaxParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000004);
				return this;
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder getSoftmaxParamBuilder()
			{
				bitField1_ |= 0x00000004;
				onChanged();
				return getSoftmaxParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder getSoftmaxParamOrBuilder()
			{
				if (softmaxParamBuilder_ != null)
				{
					return softmaxParamBuilder_.getMessageOrBuilder();
				} else
				{
					return softmaxParam_;
				}
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter softmax_param = 39;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder>
					getSoftmaxParamFieldBuilder()
			{
				if (softmaxParamBuilder_ == null)
				{
					softmaxParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder>(
									getSoftmaxParam(),
									getParentForChildren(),
									isClean());
					softmaxParam_ = null;
				}
				return softmaxParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter sliceParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder> sliceParamBuilder_;

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			@Override
			public boolean hasSliceParam()
			{
				return ((bitField1_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter getSliceParam()
			{
				if (sliceParamBuilder_ == null)
				{
					return sliceParam_;
				} else
				{
					return sliceParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			public Builder setSliceParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter value)
			{
				if (sliceParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					sliceParam_ = value;
					onChanged();
				} else
				{
					sliceParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000008;
				return this;
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			public Builder setSliceParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder builderForValue)
			{
				if (sliceParamBuilder_ == null)
				{
					sliceParam_ = builderForValue.build();
					onChanged();
				} else
				{
					sliceParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000008;
				return this;
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			public Builder mergeSliceParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter value)
			{
				if (sliceParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000008) == 0x00000008) &&
							sliceParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.getDefaultInstance())
					{
						sliceParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.newBuilder(sliceParam_).mergeFrom(value).buildPartial();
					} else
					{
						sliceParam_ = value;
					}
					onChanged();
				} else
				{
					sliceParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000008;
				return this;
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			public Builder clearSliceParam()
			{
				if (sliceParamBuilder_ == null)
				{
					sliceParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.getDefaultInstance();
					onChanged();
				} else
				{
					sliceParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000008);
				return this;
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder getSliceParamBuilder()
			{
				bitField1_ |= 0x00000008;
				onChanged();
				return getSliceParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder getSliceParamOrBuilder()
			{
				if (sliceParamBuilder_ != null)
				{
					return sliceParamBuilder_.getMessageOrBuilder();
				} else
				{
					return sliceParam_;
				}
			}

			/**
			 * <code>optional .caffe.SliceParameter slice_param = 31;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder>
					getSliceParamFieldBuilder()
			{
				if (sliceParamBuilder_ == null)
				{
					sliceParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder>(
									getSliceParam(),
									getParentForChildren(),
									isClean());
					sliceParam_ = null;
				}
				return sliceParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter tanhParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder> tanhParamBuilder_;

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			@Override
			public boolean hasTanhParam()
			{
				return ((bitField1_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter getTanhParam()
			{
				if (tanhParamBuilder_ == null)
				{
					return tanhParam_;
				} else
				{
					return tanhParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			public Builder setTanhParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter value)
			{
				if (tanhParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					tanhParam_ = value;
					onChanged();
				} else
				{
					tanhParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			public Builder setTanhParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder builderForValue)
			{
				if (tanhParamBuilder_ == null)
				{
					tanhParam_ = builderForValue.build();
					onChanged();
				} else
				{
					tanhParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			public Builder mergeTanhParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter value)
			{
				if (tanhParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000010) == 0x00000010) &&
							tanhParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDefaultInstance())
					{
						tanhParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.newBuilder(tanhParam_).mergeFrom(value).buildPartial();
					} else
					{
						tanhParam_ = value;
					}
					onChanged();
				} else
				{
					tanhParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			public Builder clearTanhParam()
			{
				if (tanhParamBuilder_ == null)
				{
					tanhParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDefaultInstance();
					onChanged();
				} else
				{
					tanhParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000010);
				return this;
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder getTanhParamBuilder()
			{
				bitField1_ |= 0x00000010;
				onChanged();
				return getTanhParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder getTanhParamOrBuilder()
			{
				if (tanhParamBuilder_ != null)
				{
					return tanhParamBuilder_.getMessageOrBuilder();
				} else
				{
					return tanhParam_;
				}
			}

			/**
			 * <code>optional .caffe.TanHParameter tanh_param = 37;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder>
					getTanhParamFieldBuilder()
			{
				if (tanhParamBuilder_ == null)
				{
					tanhParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder>(
									getTanhParam(),
									getParentForChildren(),
									isClean());
					tanhParam_ = null;
				}
				return tanhParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter thresholdParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder> thresholdParamBuilder_;

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			@Override
			public boolean hasThresholdParam()
			{
				return ((bitField1_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter getThresholdParam()
			{
				if (thresholdParamBuilder_ == null)
				{
					return thresholdParam_;
				} else
				{
					return thresholdParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			public Builder setThresholdParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter value)
			{
				if (thresholdParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					thresholdParam_ = value;
					onChanged();
				} else
				{
					thresholdParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			public Builder setThresholdParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder builderForValue)
			{
				if (thresholdParamBuilder_ == null)
				{
					thresholdParam_ = builderForValue.build();
					onChanged();
				} else
				{
					thresholdParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			public Builder mergeThresholdParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter value)
			{
				if (thresholdParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000020) == 0x00000020) &&
							thresholdParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.getDefaultInstance())
					{
						thresholdParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.newBuilder(thresholdParam_).mergeFrom(value).buildPartial();
					} else
					{
						thresholdParam_ = value;
					}
					onChanged();
				} else
				{
					thresholdParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			public Builder clearThresholdParam()
			{
				if (thresholdParamBuilder_ == null)
				{
					thresholdParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.getDefaultInstance();
					onChanged();
				} else
				{
					thresholdParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000020);
				return this;
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder getThresholdParamBuilder()
			{
				bitField1_ |= 0x00000020;
				onChanged();
				return getThresholdParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder getThresholdParamOrBuilder()
			{
				if (thresholdParamBuilder_ != null)
				{
					return thresholdParamBuilder_.getMessageOrBuilder();
				} else
				{
					return thresholdParam_;
				}
			}

			/**
			 * <code>optional .caffe.ThresholdParameter threshold_param = 25;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder>
					getThresholdParamFieldBuilder()
			{
				if (thresholdParamBuilder_ == null)
				{
					thresholdParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder>(
									getThresholdParam(),
									getParentForChildren(),
									isClean());
					thresholdParam_ = null;
				}
				return thresholdParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter windowDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder> windowDataParamBuilder_;

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			@Override
			public boolean hasWindowDataParam()
			{
				return ((bitField1_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter getWindowDataParam()
			{
				if (windowDataParamBuilder_ == null)
				{
					return windowDataParam_;
				} else
				{
					return windowDataParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			public Builder setWindowDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter value)
			{
				if (windowDataParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					windowDataParam_ = value;
					onChanged();
				} else
				{
					windowDataParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000040;
				return this;
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			public Builder setWindowDataParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder builderForValue)
			{
				if (windowDataParamBuilder_ == null)
				{
					windowDataParam_ = builderForValue.build();
					onChanged();
				} else
				{
					windowDataParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000040;
				return this;
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			public Builder mergeWindowDataParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter value)
			{
				if (windowDataParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000040) == 0x00000040) &&
							windowDataParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.getDefaultInstance())
					{
						windowDataParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.newBuilder(windowDataParam_).mergeFrom(value).buildPartial();
					} else
					{
						windowDataParam_ = value;
					}
					onChanged();
				} else
				{
					windowDataParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000040;
				return this;
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			public Builder clearWindowDataParam()
			{
				if (windowDataParamBuilder_ == null)
				{
					windowDataParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.getDefaultInstance();
					onChanged();
				} else
				{
					windowDataParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000040);
				return this;
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder getWindowDataParamBuilder()
			{
				bitField1_ |= 0x00000040;
				onChanged();
				return getWindowDataParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder getWindowDataParamOrBuilder()
			{
				if (windowDataParamBuilder_ != null)
				{
					return windowDataParamBuilder_.getMessageOrBuilder();
				} else
				{
					return windowDataParam_;
				}
			}

			/**
			 * <code>optional .caffe.WindowDataParameter window_data_param = 20;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder>
					getWindowDataParamFieldBuilder()
			{
				if (windowDataParamBuilder_ == null)
				{
					windowDataParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder>(
									getWindowDataParam(),
									getParentForChildren(),
									isClean());
					windowDataParam_ = null;
				}
				return windowDataParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter transformParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder> transformParamBuilder_;

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			@Override
			public boolean hasTransformParam()
			{
				return ((bitField1_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter getTransformParam()
			{
				if (transformParamBuilder_ == null)
				{
					return transformParam_;
				} else
				{
					return transformParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			public Builder setTransformParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter value)
			{
				if (transformParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					transformParam_ = value;
					onChanged();
				} else
				{
					transformParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000080;
				return this;
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			public Builder setTransformParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder builderForValue)
			{
				if (transformParamBuilder_ == null)
				{
					transformParam_ = builderForValue.build();
					onChanged();
				} else
				{
					transformParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000080;
				return this;
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			public Builder mergeTransformParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter value)
			{
				if (transformParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000080) == 0x00000080) &&
							transformParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.getDefaultInstance())
					{
						transformParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.newBuilder(transformParam_).mergeFrom(value).buildPartial();
					} else
					{
						transformParam_ = value;
					}
					onChanged();
				} else
				{
					transformParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000080;
				return this;
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			public Builder clearTransformParam()
			{
				if (transformParamBuilder_ == null)
				{
					transformParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.getDefaultInstance();
					onChanged();
				} else
				{
					transformParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000080);
				return this;
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder getTransformParamBuilder()
			{
				bitField1_ |= 0x00000080;
				onChanged();
				return getTransformParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder getTransformParamOrBuilder()
			{
				if (transformParamBuilder_ != null)
				{
					return transformParamBuilder_.getMessageOrBuilder();
				} else
				{
					return transformParam_;
				}
			}

			/**
			 * <code>optional .caffe.TransformationParameter transform_param = 36;</code>
			 *
			 * <pre>
			 * Parameters for data pre-processing.
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder>
					getTransformParamFieldBuilder()
			{
				if (transformParamBuilder_ == null)
				{
					transformParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder>(
									getTransformParam(),
									getParentForChildren(),
									isClean());
					transformParam_ = null;
				}
				return transformParamBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter layer_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder> layerBuilder_;

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			@Override
			public boolean hasLayer()
			{
				return ((bitField1_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter getLayer()
			{
				if (layerBuilder_ == null)
				{
					return layer_;
				} else
				{
					return layerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			public Builder setLayer(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter value)
			{
				if (layerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					layer_ = value;
					onChanged();
				} else
				{
					layerBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000100;
				return this;
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			public Builder setLayer(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder builderForValue)
			{
				if (layerBuilder_ == null)
				{
					layer_ = builderForValue.build();
					onChanged();
				} else
				{
					layerBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000100;
				return this;
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			public Builder mergeLayer(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter value)
			{
				if (layerBuilder_ == null)
				{
					if (((bitField1_ & 0x00000100) == 0x00000100) &&
							layer_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDefaultInstance())
					{
						layer_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.newBuilder(layer_).mergeFrom(value).buildPartial();
					} else
					{
						layer_ = value;
					}
					onChanged();
				} else
				{
					layerBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000100;
				return this;
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			public Builder clearLayer()
			{
				if (layerBuilder_ == null)
				{
					layer_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					layerBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000100);
				return this;
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder getLayerBuilder()
			{
				bitField1_ |= 0x00000100;
				onChanged();
				return getLayerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder getLayerOrBuilder()
			{
				if (layerBuilder_ != null)
				{
					return layerBuilder_.getMessageOrBuilder();
				} else
				{
					return layer_;
				}
			}

			/**
			 * <code>optional .caffe.V0LayerParameter layer = 1;</code>
			 *
			 * <pre>
			 * DEPRECATED: The layer parameters specified as a V0LayerParameter.
			 * This should never be used by any code except to upgrade to the new
			 * LayerParameter specification.
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder>
					getLayerFieldBuilder()
			{
				if (layerBuilder_ == null)
				{
					layerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder>(
									getLayer(),
									getParentForChildren(),
									isClean());
					layer_ = null;
				}
				return layerBuilder_;
			}

			// @@protoc_insertion_point(builder_scope:caffe.LayerParameter)
		}

		static
		{
			defaultInstance = new LayerParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.LayerParameter)
	}

	public interface TransformationParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.TransformationParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional float scale = 1 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		boolean hasScale();

		/**
		 * <code>optional float scale = 1 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		float getScale();

		/**
		 * <code>optional bool mirror = 2 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		boolean hasMirror();

		/**
		 * <code>optional bool mirror = 2 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		boolean getMirror();

		/**
		 * <code>optional uint32 crop_size = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		boolean hasCropSize();

		/**
		 * <code>optional uint32 crop_size = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		int getCropSize();

		/**
		 * <code>optional string mean_file = 4;</code>
		 */
		boolean hasMeanFile();

		/**
		 * <code>optional string mean_file = 4;</code>
		 */
		java.lang.String getMeanFile();

		/**
		 * <code>optional string mean_file = 4;</code>
		 */
		com.google.protobuf.ByteString
				getMeanFileBytes();
	}

	/**
	 * Protobuf type {@code caffe.TransformationParameter}
	 *
	 * <pre>
	 * Message that stores parameters used to apply transformation
	 * to the data layer's data
	 * </pre>
	 */
	public static final class TransformationParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.TransformationParameter)
			TransformationParameterOrBuilder
	{
		// Use TransformationParameter.newBuilder() to construct.
		private TransformationParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private TransformationParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final TransformationParameter defaultInstance;

		public static TransformationParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public TransformationParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private TransformationParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 13:
					{
						bitField0_ |= 0x00000001;
						scale_ = input.readFloat();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						mirror_ = input.readBool();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						cropSize_ = input.readUInt32();
						break;
					}
					case 34:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000008;
						meanFile_ = bs;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TransformationParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TransformationParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<TransformationParameter> PARSER =
				new com.google.protobuf.AbstractParser<TransformationParameter>()
				{
					@Override
					public TransformationParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new TransformationParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<TransformationParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int SCALE_FIELD_NUMBER = 1;
		private float scale_;

		/**
		 * <code>optional float scale = 1 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		@Override
		public boolean hasScale()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional float scale = 1 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		@Override
		public float getScale()
		{
			return scale_;
		}

		public static final int MIRROR_FIELD_NUMBER = 2;
		private boolean mirror_;

		/**
		 * <code>optional bool mirror = 2 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		@Override
		public boolean hasMirror()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bool mirror = 2 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		@Override
		public boolean getMirror()
		{
			return mirror_;
		}

		public static final int CROP_SIZE_FIELD_NUMBER = 3;
		private int cropSize_;

		/**
		 * <code>optional uint32 crop_size = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		@Override
		public boolean hasCropSize()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 crop_size = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		@Override
		public int getCropSize()
		{
			return cropSize_;
		}

		public static final int MEAN_FILE_FIELD_NUMBER = 4;
		private java.lang.Object meanFile_;

		/**
		 * <code>optional string mean_file = 4;</code>
		 */
		@Override
		public boolean hasMeanFile()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional string mean_file = 4;</code>
		 */
		@Override
		public java.lang.String getMeanFile()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					meanFile_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string mean_file = 4;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getMeanFileBytes()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				meanFile_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		private void initFields()
		{
			scale_ = 1F;
			mirror_ = false;
			cropSize_ = 0;
			meanFile_ = "";
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeFloat(1, scale_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBool(2, mirror_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(3, cropSize_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeBytes(4, getMeanFileBytes());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(1, scale_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(2, mirror_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(3, cropSize_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(4, getMeanFileBytes());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.TransformationParameter}
		 *
		 * <pre>
		 * Message that stores parameters used to apply transformation
		 * to the data layer's data
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.TransformationParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TransformationParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TransformationParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				scale_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000001);
				mirror_ = false;
				bitField0_ = (bitField0_ & ~0x00000002);
				cropSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				meanFile_ = "";
				bitField0_ = (bitField0_ & ~0x00000008);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TransformationParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter(
						this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.scale_ = scale_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.mirror_ = mirror_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.cropSize_ = cropSize_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.meanFile_ = meanFile_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter.getDefaultInstance())
					return this;
				if (other.hasScale())
				{
					setScale(other.getScale());
				}
				if (other.hasMirror())
				{
					setMirror(other.getMirror());
				}
				if (other.hasCropSize())
				{
					setCropSize(other.getCropSize());
				}
				if (other.hasMeanFile())
				{
					bitField0_ |= 0x00000008;
					meanFile_ = other.meanFile_;
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TransformationParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private float scale_ = 1F;

			/**
			 * <code>optional float scale = 1 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			@Override
			public boolean hasScale()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional float scale = 1 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			@Override
			public float getScale()
			{
				return scale_;
			}

			/**
			 * <code>optional float scale = 1 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			public Builder setScale(float value)
			{
				bitField0_ |= 0x00000001;
				scale_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float scale = 1 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			public Builder clearScale()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				scale_ = 1F;
				onChanged();
				return this;
			}

			private boolean mirror_;

			/**
			 * <code>optional bool mirror = 2 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			@Override
			public boolean hasMirror()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional bool mirror = 2 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			@Override
			public boolean getMirror()
			{
				return mirror_;
			}

			/**
			 * <code>optional bool mirror = 2 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			public Builder setMirror(boolean value)
			{
				bitField0_ |= 0x00000002;
				mirror_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool mirror = 2 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			public Builder clearMirror()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				mirror_ = false;
				onChanged();
				return this;
			}

			private int cropSize_;

			/**
			 * <code>optional uint32 crop_size = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			@Override
			public boolean hasCropSize()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 crop_size = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			@Override
			public int getCropSize()
			{
				return cropSize_;
			}

			/**
			 * <code>optional uint32 crop_size = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			public Builder setCropSize(int value)
			{
				bitField0_ |= 0x00000004;
				cropSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 crop_size = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			public Builder clearCropSize()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				cropSize_ = 0;
				onChanged();
				return this;
			}

			private java.lang.Object meanFile_ = "";

			/**
			 * <code>optional string mean_file = 4;</code>
			 */
			@Override
			public boolean hasMeanFile()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional string mean_file = 4;</code>
			 */
			@Override
			public java.lang.String getMeanFile()
			{
				java.lang.Object ref = meanFile_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						meanFile_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 4;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getMeanFileBytes()
			{
				java.lang.Object ref = meanFile_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					meanFile_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 4;</code>
			 */
			public Builder setMeanFile(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000008;
				meanFile_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 4;</code>
			 */
			public Builder clearMeanFile()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				meanFile_ = getDefaultInstance().getMeanFile();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 4;</code>
			 */
			public Builder setMeanFileBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000008;
				meanFile_ = value;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.TransformationParameter)
		}

		static
		{
			defaultInstance = new TransformationParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.TransformationParameter)
	}

	public interface AccuracyParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.AccuracyParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 top_k = 1 [default = 1];</code>
		 *
		 * <pre>
		 * When computing accuracy, count as correct by comparing the true label to
		 * the top k scoring classes.  By default, only compare to the top scoring
		 * class (i.e. argmax).
		 * </pre>
		 */
		boolean hasTopK();

		/**
		 * <code>optional uint32 top_k = 1 [default = 1];</code>
		 *
		 * <pre>
		 * When computing accuracy, count as correct by comparing the true label to
		 * the top k scoring classes.  By default, only compare to the top scoring
		 * class (i.e. argmax).
		 * </pre>
		 */
		int getTopK();
	}

	/**
	 * Protobuf type {@code caffe.AccuracyParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by AccuracyLayer
	 * </pre>
	 */
	public static final class AccuracyParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.AccuracyParameter)
			AccuracyParameterOrBuilder
	{
		// Use AccuracyParameter.newBuilder() to construct.
		private AccuracyParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private AccuracyParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final AccuracyParameter defaultInstance;

		public static AccuracyParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public AccuracyParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private AccuracyParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						topK_ = input.readUInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_AccuracyParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_AccuracyParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<AccuracyParameter> PARSER =
				new com.google.protobuf.AbstractParser<AccuracyParameter>()
				{
					@Override
					public AccuracyParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new AccuracyParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<AccuracyParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int TOP_K_FIELD_NUMBER = 1;
		private int topK_;

		/**
		 * <code>optional uint32 top_k = 1 [default = 1];</code>
		 *
		 * <pre>
		 * When computing accuracy, count as correct by comparing the true label to
		 * the top k scoring classes.  By default, only compare to the top scoring
		 * class (i.e. argmax).
		 * </pre>
		 */
		@Override
		public boolean hasTopK()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 top_k = 1 [default = 1];</code>
		 *
		 * <pre>
		 * When computing accuracy, count as correct by comparing the true label to
		 * the top k scoring classes.  By default, only compare to the top scoring
		 * class (i.e. argmax).
		 * </pre>
		 */
		@Override
		public int getTopK()
		{
			return topK_;
		}

		private void initFields()
		{
			topK_ = 1;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, topK_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, topK_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.AccuracyParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by AccuracyLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.AccuracyParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_AccuracyParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_AccuracyParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				topK_ = 1;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_AccuracyParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.topK_ = topK_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter.getDefaultInstance())
					return this;
				if (other.hasTopK())
				{
					setTopK(other.getTopK());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.AccuracyParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int topK_ = 1;

			/**
			 * <code>optional uint32 top_k = 1 [default = 1];</code>
			 *
			 * <pre>
			 * When computing accuracy, count as correct by comparing the true label to
			 * the top k scoring classes.  By default, only compare to the top scoring
			 * class (i.e. argmax).
			 * </pre>
			 */
			@Override
			public boolean hasTopK()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 top_k = 1 [default = 1];</code>
			 *
			 * <pre>
			 * When computing accuracy, count as correct by comparing the true label to
			 * the top k scoring classes.  By default, only compare to the top scoring
			 * class (i.e. argmax).
			 * </pre>
			 */
			@Override
			public int getTopK()
			{
				return topK_;
			}

			/**
			 * <code>optional uint32 top_k = 1 [default = 1];</code>
			 *
			 * <pre>
			 * When computing accuracy, count as correct by comparing the true label to
			 * the top k scoring classes.  By default, only compare to the top scoring
			 * class (i.e. argmax).
			 * </pre>
			 */
			public Builder setTopK(int value)
			{
				bitField0_ |= 0x00000001;
				topK_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 top_k = 1 [default = 1];</code>
			 *
			 * <pre>
			 * When computing accuracy, count as correct by comparing the true label to
			 * the top k scoring classes.  By default, only compare to the top scoring
			 * class (i.e. argmax).
			 * </pre>
			 */
			public Builder clearTopK()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				topK_ = 1;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.AccuracyParameter)
		}

		static
		{
			defaultInstance = new AccuracyParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)
	}

	public interface ArgMaxParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ArgMaxParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional bool out_max_val = 1 [default = false];</code>
		 *
		 * <pre>
		 * If true produce pairs (argmax, maxval)
		 * </pre>
		 */
		boolean hasOutMaxVal();

		/**
		 * <code>optional bool out_max_val = 1 [default = false];</code>
		 *
		 * <pre>
		 * If true produce pairs (argmax, maxval)
		 * </pre>
		 */
		boolean getOutMaxVal();

		/**
		 * <code>optional uint32 top_k = 2 [default = 1];</code>
		 */
		boolean hasTopK();

		/**
		 * <code>optional uint32 top_k = 2 [default = 1];</code>
		 */
		int getTopK();
	}

	/**
	 * Protobuf type {@code caffe.ArgMaxParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ArgMaxLayer
	 * </pre>
	 */
	public static final class ArgMaxParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ArgMaxParameter)
			ArgMaxParameterOrBuilder
	{
		// Use ArgMaxParameter.newBuilder() to construct.
		private ArgMaxParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ArgMaxParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ArgMaxParameter defaultInstance;

		public static ArgMaxParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ArgMaxParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ArgMaxParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						outMaxVal_ = input.readBool();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						topK_ = input.readUInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ArgMaxParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ArgMaxParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ArgMaxParameter> PARSER =
				new com.google.protobuf.AbstractParser<ArgMaxParameter>()
				{
					@Override
					public ArgMaxParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ArgMaxParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ArgMaxParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int OUT_MAX_VAL_FIELD_NUMBER = 1;
		private boolean outMaxVal_;

		/**
		 * <code>optional bool out_max_val = 1 [default = false];</code>
		 *
		 * <pre>
		 * If true produce pairs (argmax, maxval)
		 * </pre>
		 */
		@Override
		public boolean hasOutMaxVal()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional bool out_max_val = 1 [default = false];</code>
		 *
		 * <pre>
		 * If true produce pairs (argmax, maxval)
		 * </pre>
		 */
		@Override
		public boolean getOutMaxVal()
		{
			return outMaxVal_;
		}

		public static final int TOP_K_FIELD_NUMBER = 2;
		private int topK_;

		/**
		 * <code>optional uint32 top_k = 2 [default = 1];</code>
		 */
		@Override
		public boolean hasTopK()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint32 top_k = 2 [default = 1];</code>
		 */
		@Override
		public int getTopK()
		{
			return topK_;
		}

		private void initFields()
		{
			outMaxVal_ = false;
			topK_ = 1;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBool(1, outMaxVal_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeUInt32(2, topK_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(1, outMaxVal_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(2, topK_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ArgMaxParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ArgMaxLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ArgMaxParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ArgMaxParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ArgMaxParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				outMaxVal_ = false;
				bitField0_ = (bitField0_ & ~0x00000001);
				topK_ = 1;
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ArgMaxParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.outMaxVal_ = outMaxVal_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.topK_ = topK_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter.getDefaultInstance())
					return this;
				if (other.hasOutMaxVal())
				{
					setOutMaxVal(other.getOutMaxVal());
				}
				if (other.hasTopK())
				{
					setTopK(other.getTopK());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ArgMaxParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private boolean outMaxVal_;

			/**
			 * <code>optional bool out_max_val = 1 [default = false];</code>
			 *
			 * <pre>
			 * If true produce pairs (argmax, maxval)
			 * </pre>
			 */
			@Override
			public boolean hasOutMaxVal()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional bool out_max_val = 1 [default = false];</code>
			 *
			 * <pre>
			 * If true produce pairs (argmax, maxval)
			 * </pre>
			 */
			@Override
			public boolean getOutMaxVal()
			{
				return outMaxVal_;
			}

			/**
			 * <code>optional bool out_max_val = 1 [default = false];</code>
			 *
			 * <pre>
			 * If true produce pairs (argmax, maxval)
			 * </pre>
			 */
			public Builder setOutMaxVal(boolean value)
			{
				bitField0_ |= 0x00000001;
				outMaxVal_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool out_max_val = 1 [default = false];</code>
			 *
			 * <pre>
			 * If true produce pairs (argmax, maxval)
			 * </pre>
			 */
			public Builder clearOutMaxVal()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				outMaxVal_ = false;
				onChanged();
				return this;
			}

			private int topK_ = 1;

			/**
			 * <code>optional uint32 top_k = 2 [default = 1];</code>
			 */
			@Override
			public boolean hasTopK()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint32 top_k = 2 [default = 1];</code>
			 */
			@Override
			public int getTopK()
			{
				return topK_;
			}

			/**
			 * <code>optional uint32 top_k = 2 [default = 1];</code>
			 */
			public Builder setTopK(int value)
			{
				bitField0_ |= 0x00000002;
				topK_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 top_k = 2 [default = 1];</code>
			 */
			public Builder clearTopK()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				topK_ = 1;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ArgMaxParameter)
		}

		static
		{
			defaultInstance = new ArgMaxParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)
	}

	public interface ConcatParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ConcatParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * Concat Layer needs to specify the dimension along the concat will happen,
		 * the other dimensions must be the same for all the bottom blobs
		 * By default it will concatenate blobs along channels dimension
		 * </pre>
		 */
		boolean hasConcatDim();

		/**
		 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * Concat Layer needs to specify the dimension along the concat will happen,
		 * the other dimensions must be the same for all the bottom blobs
		 * By default it will concatenate blobs along channels dimension
		 * </pre>
		 */
		int getConcatDim();
	}

	/**
	 * Protobuf type {@code caffe.ConcatParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ConcatLayer
	 * </pre>
	 */
	public static final class ConcatParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ConcatParameter)
			ConcatParameterOrBuilder
	{
		// Use ConcatParameter.newBuilder() to construct.
		private ConcatParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ConcatParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ConcatParameter defaultInstance;

		public static ConcatParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ConcatParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ConcatParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						concatDim_ = input.readUInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConcatParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConcatParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ConcatParameter> PARSER =
				new com.google.protobuf.AbstractParser<ConcatParameter>()
				{
					@Override
					public ConcatParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ConcatParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ConcatParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int CONCAT_DIM_FIELD_NUMBER = 1;
		private int concatDim_;

		/**
		 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * Concat Layer needs to specify the dimension along the concat will happen,
		 * the other dimensions must be the same for all the bottom blobs
		 * By default it will concatenate blobs along channels dimension
		 * </pre>
		 */
		@Override
		public boolean hasConcatDim()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * Concat Layer needs to specify the dimension along the concat will happen,
		 * the other dimensions must be the same for all the bottom blobs
		 * By default it will concatenate blobs along channels dimension
		 * </pre>
		 */
		@Override
		public int getConcatDim()
		{
			return concatDim_;
		}

		private void initFields()
		{
			concatDim_ = 1;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, concatDim_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, concatDim_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ConcatParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ConcatLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ConcatParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConcatParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConcatParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				concatDim_ = 1;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConcatParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.concatDim_ = concatDim_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter.getDefaultInstance())
					return this;
				if (other.hasConcatDim())
				{
					setConcatDim(other.getConcatDim());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConcatParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int concatDim_ = 1;

			/**
			 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * Concat Layer needs to specify the dimension along the concat will happen,
			 * the other dimensions must be the same for all the bottom blobs
			 * By default it will concatenate blobs along channels dimension
			 * </pre>
			 */
			@Override
			public boolean hasConcatDim()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * Concat Layer needs to specify the dimension along the concat will happen,
			 * the other dimensions must be the same for all the bottom blobs
			 * By default it will concatenate blobs along channels dimension
			 * </pre>
			 */
			@Override
			public int getConcatDim()
			{
				return concatDim_;
			}

			/**
			 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * Concat Layer needs to specify the dimension along the concat will happen,
			 * the other dimensions must be the same for all the bottom blobs
			 * By default it will concatenate blobs along channels dimension
			 * </pre>
			 */
			public Builder setConcatDim(int value)
			{
				bitField0_ |= 0x00000001;
				concatDim_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 concat_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * Concat Layer needs to specify the dimension along the concat will happen,
			 * the other dimensions must be the same for all the bottom blobs
			 * By default it will concatenate blobs along channels dimension
			 * </pre>
			 */
			public Builder clearConcatDim()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				concatDim_ = 1;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ConcatParameter)
		}

		static
		{
			defaultInstance = new ConcatParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ConcatParameter)
	}

	public interface ContrastiveLossParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ContrastiveLossParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional float margin = 1 [default = 1];</code>
		 *
		 * <pre>
		 * margin for dissimilar pair
		 * </pre>
		 */
		boolean hasMargin();

		/**
		 * <code>optional float margin = 1 [default = 1];</code>
		 *
		 * <pre>
		 * margin for dissimilar pair
		 * </pre>
		 */
		float getMargin();
	}

	/**
	 * Protobuf type {@code caffe.ContrastiveLossParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ContrastiveLossLayer
	 * </pre>
	 */
	public static final class ContrastiveLossParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ContrastiveLossParameter)
			ContrastiveLossParameterOrBuilder
	{
		// Use ContrastiveLossParameter.newBuilder() to construct.
		private ContrastiveLossParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ContrastiveLossParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ContrastiveLossParameter defaultInstance;

		public static ContrastiveLossParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ContrastiveLossParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ContrastiveLossParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 13:
					{
						bitField0_ |= 0x00000001;
						margin_ = input.readFloat();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ContrastiveLossParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ContrastiveLossParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ContrastiveLossParameter> PARSER =
				new com.google.protobuf.AbstractParser<ContrastiveLossParameter>()
				{
					@Override
					public ContrastiveLossParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ContrastiveLossParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ContrastiveLossParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int MARGIN_FIELD_NUMBER = 1;
		private float margin_;

		/**
		 * <code>optional float margin = 1 [default = 1];</code>
		 *
		 * <pre>
		 * margin for dissimilar pair
		 * </pre>
		 */
		@Override
		public boolean hasMargin()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional float margin = 1 [default = 1];</code>
		 *
		 * <pre>
		 * margin for dissimilar pair
		 * </pre>
		 */
		@Override
		public float getMargin()
		{
			return margin_;
		}

		private void initFields()
		{
			margin_ = 1F;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeFloat(1, margin_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(1, margin_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ContrastiveLossParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ContrastiveLossLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ContrastiveLossParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ContrastiveLossParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ContrastiveLossParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				margin_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ContrastiveLossParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter(
						this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.margin_ = margin_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter.getDefaultInstance())
					return this;
				if (other.hasMargin())
				{
					setMargin(other.getMargin());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ContrastiveLossParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private float margin_ = 1F;

			/**
			 * <code>optional float margin = 1 [default = 1];</code>
			 *
			 * <pre>
			 * margin for dissimilar pair
			 * </pre>
			 */
			@Override
			public boolean hasMargin()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional float margin = 1 [default = 1];</code>
			 *
			 * <pre>
			 * margin for dissimilar pair
			 * </pre>
			 */
			@Override
			public float getMargin()
			{
				return margin_;
			}

			/**
			 * <code>optional float margin = 1 [default = 1];</code>
			 *
			 * <pre>
			 * margin for dissimilar pair
			 * </pre>
			 */
			public Builder setMargin(float value)
			{
				bitField0_ |= 0x00000001;
				margin_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float margin = 1 [default = 1];</code>
			 *
			 * <pre>
			 * margin for dissimilar pair
			 * </pre>
			 */
			public Builder clearMargin()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				margin_ = 1F;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ContrastiveLossParameter)
		}

		static
		{
			defaultInstance = new ContrastiveLossParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)
	}

	public interface ConvolutionParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ConvolutionParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		boolean hasNumOutput();

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		int getNumOutput();

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		boolean hasBiasTerm();

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		boolean getBiasTerm();

		/**
		 * <code>optional uint32 pad = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		boolean hasPad();

		/**
		 * <code>optional uint32 pad = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		int getPad();

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		boolean hasPadH();

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		int getPadH();

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		boolean hasPadW();

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		int getPadW();

		/**
		 * <code>optional uint32 kernel_size = 4;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		boolean hasKernelSize();

		/**
		 * <code>optional uint32 kernel_size = 4;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		int getKernelSize();

		/**
		 * <code>optional uint32 kernel_h = 11;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		boolean hasKernelH();

		/**
		 * <code>optional uint32 kernel_h = 11;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		int getKernelH();

		/**
		 * <code>optional uint32 kernel_w = 12;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		boolean hasKernelW();

		/**
		 * <code>optional uint32 kernel_w = 12;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		int getKernelW();

		/**
		 * <code>optional uint32 group = 5 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		boolean hasGroup();

		/**
		 * <code>optional uint32 group = 5 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		int getGroup();

		/**
		 * <code>optional uint32 stride = 6 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		boolean hasStride();

		/**
		 * <code>optional uint32 stride = 6 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		int getStride();

		/**
		 * <code>optional uint32 stride_h = 13;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		boolean hasStrideH();

		/**
		 * <code>optional uint32 stride_h = 13;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		int getStrideH();

		/**
		 * <code>optional uint32 stride_w = 14;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		boolean hasStrideW();

		/**
		 * <code>optional uint32 stride_w = 14;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		int getStrideW();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		boolean hasWeightFiller();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		boolean hasBiasFiller();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder();

		/**
		 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
		 */
		boolean hasEngine();

		/**
		 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine getEngine();
	}

	/**
	 * Protobuf type {@code caffe.ConvolutionParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ConvolutionLayer
	 * </pre>
	 */
	public static final class ConvolutionParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ConvolutionParameter)
			ConvolutionParameterOrBuilder
	{
		// Use ConvolutionParameter.newBuilder() to construct.
		private ConvolutionParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ConvolutionParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ConvolutionParameter defaultInstance;

		public static ConvolutionParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ConvolutionParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ConvolutionParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						numOutput_ = input.readUInt32();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						biasTerm_ = input.readBool();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						pad_ = input.readUInt32();
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000020;
						kernelSize_ = input.readUInt32();
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000100;
						group_ = input.readUInt32();
						break;
					}
					case 48:
					{
						bitField0_ |= 0x00000200;
						stride_ = input.readUInt32();
						break;
					}
					case 58:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00001000) == 0x00001000))
						{
							subBuilder = weightFiller_.toBuilder();
						}
						weightFiller_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(weightFiller_);
							weightFiller_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00001000;
						break;
					}
					case 66:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00002000) == 0x00002000))
						{
							subBuilder = biasFiller_.toBuilder();
						}
						biasFiller_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(biasFiller_);
							biasFiller_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00002000;
						break;
					}
					case 72:
					{
						bitField0_ |= 0x00000008;
						padH_ = input.readUInt32();
						break;
					}
					case 80:
					{
						bitField0_ |= 0x00000010;
						padW_ = input.readUInt32();
						break;
					}
					case 88:
					{
						bitField0_ |= 0x00000040;
						kernelH_ = input.readUInt32();
						break;
					}
					case 96:
					{
						bitField0_ |= 0x00000080;
						kernelW_ = input.readUInt32();
						break;
					}
					case 104:
					{
						bitField0_ |= 0x00000400;
						strideH_ = input.readUInt32();
						break;
					}
					case 112:
					{
						bitField0_ |= 0x00000800;
						strideW_ = input.readUInt32();
						break;
					}
					case 120:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(15, rawValue);
						} else
						{
							bitField0_ |= 0x00004000;
							engine_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConvolutionParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConvolutionParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ConvolutionParameter> PARSER =
				new com.google.protobuf.AbstractParser<ConvolutionParameter>()
				{
					@Override
					public ConvolutionParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ConvolutionParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ConvolutionParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.ConvolutionParameter.Engine}
		 */
		public enum Engine
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>DEFAULT = 0;</code>
			 */
			DEFAULT(0, 0),
			/**
			 * <code>CAFFE = 1;</code>
			 */
			CAFFE(1, 1),
			/**
			 * <code>CUDNN = 2;</code>
			 */
			CUDNN(2, 2), ;

			/**
			 * <code>DEFAULT = 0;</code>
			 */
			public static final int DEFAULT_VALUE = 0;
			/**
			 * <code>CAFFE = 1;</code>
			 */
			public static final int CAFFE_VALUE = 1;
			/**
			 * <code>CUDNN = 2;</code>
			 */
			public static final int CUDNN_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Engine valueOf(int value)
			{
				switch (value) {
				case 0:
					return DEFAULT;
				case 1:
					return CAFFE;
				case 2:
					return CUDNN;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Engine>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Engine> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Engine>()
					{
						@Override
						public Engine findValueByNumber(int number)
						{
							return Engine.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final Engine[] VALUES = values();

			public static Engine valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Engine(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.ConvolutionParameter.Engine)
		}

		private int bitField0_;
		public static final int NUM_OUTPUT_FIELD_NUMBER = 1;
		private int numOutput_;

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		@Override
		public boolean hasNumOutput()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		@Override
		public int getNumOutput()
		{
			return numOutput_;
		}

		public static final int BIAS_TERM_FIELD_NUMBER = 2;
		private boolean biasTerm_;

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		@Override
		public boolean hasBiasTerm()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		@Override
		public boolean getBiasTerm()
		{
			return biasTerm_;
		}

		public static final int PAD_FIELD_NUMBER = 3;
		private int pad_;

		/**
		 * <code>optional uint32 pad = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		@Override
		public boolean hasPad()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 pad = 3 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		@Override
		public int getPad()
		{
			return pad_;
		}

		public static final int PAD_H_FIELD_NUMBER = 9;
		private int padH_;

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		@Override
		public boolean hasPadH()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		@Override
		public int getPadH()
		{
			return padH_;
		}

		public static final int PAD_W_FIELD_NUMBER = 10;
		private int padW_;

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		@Override
		public boolean hasPadW()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		@Override
		public int getPadW()
		{
			return padW_;
		}

		public static final int KERNEL_SIZE_FIELD_NUMBER = 4;
		private int kernelSize_;

		/**
		 * <code>optional uint32 kernel_size = 4;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		@Override
		public boolean hasKernelSize()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional uint32 kernel_size = 4;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		@Override
		public int getKernelSize()
		{
			return kernelSize_;
		}

		public static final int KERNEL_H_FIELD_NUMBER = 11;
		private int kernelH_;

		/**
		 * <code>optional uint32 kernel_h = 11;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		@Override
		public boolean hasKernelH()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional uint32 kernel_h = 11;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		@Override
		public int getKernelH()
		{
			return kernelH_;
		}

		public static final int KERNEL_W_FIELD_NUMBER = 12;
		private int kernelW_;

		/**
		 * <code>optional uint32 kernel_w = 12;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		@Override
		public boolean hasKernelW()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional uint32 kernel_w = 12;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		@Override
		public int getKernelW()
		{
			return kernelW_;
		}

		public static final int GROUP_FIELD_NUMBER = 5;
		private int group_;

		/**
		 * <code>optional uint32 group = 5 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		@Override
		public boolean hasGroup()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional uint32 group = 5 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		@Override
		public int getGroup()
		{
			return group_;
		}

		public static final int STRIDE_FIELD_NUMBER = 6;
		private int stride_;

		/**
		 * <code>optional uint32 stride = 6 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		@Override
		public boolean hasStride()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional uint32 stride = 6 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		@Override
		public int getStride()
		{
			return stride_;
		}

		public static final int STRIDE_H_FIELD_NUMBER = 13;
		private int strideH_;

		/**
		 * <code>optional uint32 stride_h = 13;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		@Override
		public boolean hasStrideH()
		{
			return ((bitField0_ & 0x00000400) == 0x00000400);
		}

		/**
		 * <code>optional uint32 stride_h = 13;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		@Override
		public int getStrideH()
		{
			return strideH_;
		}

		public static final int STRIDE_W_FIELD_NUMBER = 14;
		private int strideW_;

		/**
		 * <code>optional uint32 stride_w = 14;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		@Override
		public boolean hasStrideW()
		{
			return ((bitField0_ & 0x00000800) == 0x00000800);
		}

		/**
		 * <code>optional uint32 stride_w = 14;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		@Override
		public int getStrideW()
		{
			return strideW_;
		}

		public static final int WEIGHT_FILLER_FIELD_NUMBER = 7;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter weightFiller_;

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public boolean hasWeightFiller()
		{
			return ((bitField0_ & 0x00001000) == 0x00001000);
		}

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller()
		{
			return weightFiller_;
		}

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder()
		{
			return weightFiller_;
		}

		public static final int BIAS_FILLER_FIELD_NUMBER = 8;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter biasFiller_;

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public boolean hasBiasFiller()
		{
			return ((bitField0_ & 0x00002000) == 0x00002000);
		}

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller()
		{
			return biasFiller_;
		}

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder()
		{
			return biasFiller_;
		}

		public static final int ENGINE_FIELD_NUMBER = 15;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine engine_;

		/**
		 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
		 */
		@Override
		public boolean hasEngine()
		{
			return ((bitField0_ & 0x00004000) == 0x00004000);
		}

		/**
		 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine getEngine()
		{
			return engine_;
		}

		private void initFields()
		{
			numOutput_ = 0;
			biasTerm_ = true;
			pad_ = 0;
			padH_ = 0;
			padW_ = 0;
			kernelSize_ = 0;
			kernelH_ = 0;
			kernelW_ = 0;
			group_ = 1;
			stride_ = 1;
			strideH_ = 0;
			strideW_ = 0;
			weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
			biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
			engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine.DEFAULT;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, numOutput_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBool(2, biasTerm_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(3, pad_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeUInt32(4, kernelSize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeUInt32(5, group_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeUInt32(6, stride_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				output.writeMessage(7, weightFiller_);
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				output.writeMessage(8, biasFiller_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeUInt32(9, padH_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeUInt32(10, padW_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeUInt32(11, kernelH_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeUInt32(12, kernelW_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				output.writeUInt32(13, strideH_);
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				output.writeUInt32(14, strideW_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				output.writeEnum(15, engine_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, numOutput_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(2, biasTerm_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(3, pad_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(4, kernelSize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(5, group_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(6, stride_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(7, weightFiller_);
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(8, biasFiller_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(9, padH_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(10, padW_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(11, kernelH_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(12, kernelW_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(13, strideH_);
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(14, strideW_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(15, engine_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ConvolutionParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ConvolutionLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ConvolutionParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConvolutionParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConvolutionParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getWeightFillerFieldBuilder();
					getBiasFillerFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				numOutput_ = 0;
				bitField0_ = (bitField0_ & ~0x00000001);
				biasTerm_ = true;
				bitField0_ = (bitField0_ & ~0x00000002);
				pad_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				padH_ = 0;
				bitField0_ = (bitField0_ & ~0x00000008);
				padW_ = 0;
				bitField0_ = (bitField0_ & ~0x00000010);
				kernelSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000020);
				kernelH_ = 0;
				bitField0_ = (bitField0_ & ~0x00000040);
				kernelW_ = 0;
				bitField0_ = (bitField0_ & ~0x00000080);
				group_ = 1;
				bitField0_ = (bitField0_ & ~0x00000100);
				stride_ = 1;
				bitField0_ = (bitField0_ & ~0x00000200);
				strideH_ = 0;
				bitField0_ = (bitField0_ & ~0x00000400);
				strideW_ = 0;
				bitField0_ = (bitField0_ & ~0x00000800);
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
				} else
				{
					weightFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00001000);
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
				} else
				{
					biasFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00002000);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine.DEFAULT;
				bitField0_ = (bitField0_ & ~0x00004000);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ConvolutionParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.numOutput_ = numOutput_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.biasTerm_ = biasTerm_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.pad_ = pad_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.padH_ = padH_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.padW_ = padW_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.kernelSize_ = kernelSize_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.kernelH_ = kernelH_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.kernelW_ = kernelW_;
				if (((from_bitField0_ & 0x00000100) == 0x00000100))
				{
					to_bitField0_ |= 0x00000100;
				}
				result.group_ = group_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200))
				{
					to_bitField0_ |= 0x00000200;
				}
				result.stride_ = stride_;
				if (((from_bitField0_ & 0x00000400) == 0x00000400))
				{
					to_bitField0_ |= 0x00000400;
				}
				result.strideH_ = strideH_;
				if (((from_bitField0_ & 0x00000800) == 0x00000800))
				{
					to_bitField0_ |= 0x00000800;
				}
				result.strideW_ = strideW_;
				if (((from_bitField0_ & 0x00001000) == 0x00001000))
				{
					to_bitField0_ |= 0x00001000;
				}
				if (weightFillerBuilder_ == null)
				{
					result.weightFiller_ = weightFiller_;
				} else
				{
					result.weightFiller_ = weightFillerBuilder_.build();
				}
				if (((from_bitField0_ & 0x00002000) == 0x00002000))
				{
					to_bitField0_ |= 0x00002000;
				}
				if (biasFillerBuilder_ == null)
				{
					result.biasFiller_ = biasFiller_;
				} else
				{
					result.biasFiller_ = biasFillerBuilder_.build();
				}
				if (((from_bitField0_ & 0x00004000) == 0x00004000))
				{
					to_bitField0_ |= 0x00004000;
				}
				result.engine_ = engine_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.getDefaultInstance())
					return this;
				if (other.hasNumOutput())
				{
					setNumOutput(other.getNumOutput());
				}
				if (other.hasBiasTerm())
				{
					setBiasTerm(other.getBiasTerm());
				}
				if (other.hasPad())
				{
					setPad(other.getPad());
				}
				if (other.hasPadH())
				{
					setPadH(other.getPadH());
				}
				if (other.hasPadW())
				{
					setPadW(other.getPadW());
				}
				if (other.hasKernelSize())
				{
					setKernelSize(other.getKernelSize());
				}
				if (other.hasKernelH())
				{
					setKernelH(other.getKernelH());
				}
				if (other.hasKernelW())
				{
					setKernelW(other.getKernelW());
				}
				if (other.hasGroup())
				{
					setGroup(other.getGroup());
				}
				if (other.hasStride())
				{
					setStride(other.getStride());
				}
				if (other.hasStrideH())
				{
					setStrideH(other.getStrideH());
				}
				if (other.hasStrideW())
				{
					setStrideW(other.getStrideW());
				}
				if (other.hasWeightFiller())
				{
					mergeWeightFiller(other.getWeightFiller());
				}
				if (other.hasBiasFiller())
				{
					mergeBiasFiller(other.getBiasFiller());
				}
				if (other.hasEngine())
				{
					setEngine(other.getEngine());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int numOutput_;

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			@Override
			public boolean hasNumOutput()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			@Override
			public int getNumOutput()
			{
				return numOutput_;
			}

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			public Builder setNumOutput(int value)
			{
				bitField0_ |= 0x00000001;
				numOutput_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			public Builder clearNumOutput()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				numOutput_ = 0;
				onChanged();
				return this;
			}

			private boolean biasTerm_ = true;

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			@Override
			public boolean hasBiasTerm()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			@Override
			public boolean getBiasTerm()
			{
				return biasTerm_;
			}

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			public Builder setBiasTerm(boolean value)
			{
				bitField0_ |= 0x00000002;
				biasTerm_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			public Builder clearBiasTerm()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				biasTerm_ = true;
				onChanged();
				return this;
			}

			private int pad_;

			/**
			 * <code>optional uint32 pad = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			@Override
			public boolean hasPad()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 pad = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			@Override
			public int getPad()
			{
				return pad_;
			}

			/**
			 * <code>optional uint32 pad = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			public Builder setPad(int value)
			{
				bitField0_ |= 0x00000004;
				pad_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad = 3 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			public Builder clearPad()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				pad_ = 0;
				onChanged();
				return this;
			}

			private int padH_;

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			@Override
			public boolean hasPadH()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			@Override
			public int getPadH()
			{
				return padH_;
			}

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			public Builder setPadH(int value)
			{
				bitField0_ |= 0x00000008;
				padH_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			public Builder clearPadH()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				padH_ = 0;
				onChanged();
				return this;
			}

			private int padW_;

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			@Override
			public boolean hasPadW()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			@Override
			public int getPadW()
			{
				return padW_;
			}

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			public Builder setPadW(int value)
			{
				bitField0_ |= 0x00000010;
				padW_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			public Builder clearPadW()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				padW_ = 0;
				onChanged();
				return this;
			}

			private int kernelSize_;

			/**
			 * <code>optional uint32 kernel_size = 4;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			@Override
			public boolean hasKernelSize()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional uint32 kernel_size = 4;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			@Override
			public int getKernelSize()
			{
				return kernelSize_;
			}

			/**
			 * <code>optional uint32 kernel_size = 4;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			public Builder setKernelSize(int value)
			{
				bitField0_ |= 0x00000020;
				kernelSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernel_size = 4;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			public Builder clearKernelSize()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				kernelSize_ = 0;
				onChanged();
				return this;
			}

			private int kernelH_;

			/**
			 * <code>optional uint32 kernel_h = 11;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			@Override
			public boolean hasKernelH()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional uint32 kernel_h = 11;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			@Override
			public int getKernelH()
			{
				return kernelH_;
			}

			/**
			 * <code>optional uint32 kernel_h = 11;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			public Builder setKernelH(int value)
			{
				bitField0_ |= 0x00000040;
				kernelH_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernel_h = 11;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			public Builder clearKernelH()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				kernelH_ = 0;
				onChanged();
				return this;
			}

			private int kernelW_;

			/**
			 * <code>optional uint32 kernel_w = 12;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			@Override
			public boolean hasKernelW()
			{
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional uint32 kernel_w = 12;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			@Override
			public int getKernelW()
			{
				return kernelW_;
			}

			/**
			 * <code>optional uint32 kernel_w = 12;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			public Builder setKernelW(int value)
			{
				bitField0_ |= 0x00000080;
				kernelW_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernel_w = 12;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			public Builder clearKernelW()
			{
				bitField0_ = (bitField0_ & ~0x00000080);
				kernelW_ = 0;
				onChanged();
				return this;
			}

			private int group_ = 1;

			/**
			 * <code>optional uint32 group = 5 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			@Override
			public boolean hasGroup()
			{
				return ((bitField0_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>optional uint32 group = 5 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			@Override
			public int getGroup()
			{
				return group_;
			}

			/**
			 * <code>optional uint32 group = 5 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			public Builder setGroup(int value)
			{
				bitField0_ |= 0x00000100;
				group_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 group = 5 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			public Builder clearGroup()
			{
				bitField0_ = (bitField0_ & ~0x00000100);
				group_ = 1;
				onChanged();
				return this;
			}

			private int stride_ = 1;

			/**
			 * <code>optional uint32 stride = 6 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			@Override
			public boolean hasStride()
			{
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional uint32 stride = 6 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			@Override
			public int getStride()
			{
				return stride_;
			}

			/**
			 * <code>optional uint32 stride = 6 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			public Builder setStride(int value)
			{
				bitField0_ |= 0x00000200;
				stride_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride = 6 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			public Builder clearStride()
			{
				bitField0_ = (bitField0_ & ~0x00000200);
				stride_ = 1;
				onChanged();
				return this;
			}

			private int strideH_;

			/**
			 * <code>optional uint32 stride_h = 13;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			@Override
			public boolean hasStrideH()
			{
				return ((bitField0_ & 0x00000400) == 0x00000400);
			}

			/**
			 * <code>optional uint32 stride_h = 13;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			@Override
			public int getStrideH()
			{
				return strideH_;
			}

			/**
			 * <code>optional uint32 stride_h = 13;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			public Builder setStrideH(int value)
			{
				bitField0_ |= 0x00000400;
				strideH_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride_h = 13;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			public Builder clearStrideH()
			{
				bitField0_ = (bitField0_ & ~0x00000400);
				strideH_ = 0;
				onChanged();
				return this;
			}

			private int strideW_;

			/**
			 * <code>optional uint32 stride_w = 14;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			@Override
			public boolean hasStrideW()
			{
				return ((bitField0_ & 0x00000800) == 0x00000800);
			}

			/**
			 * <code>optional uint32 stride_w = 14;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			@Override
			public int getStrideW()
			{
				return strideW_;
			}

			/**
			 * <code>optional uint32 stride_w = 14;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			public Builder setStrideW(int value)
			{
				bitField0_ |= 0x00000800;
				strideW_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride_w = 14;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			public Builder clearStrideW()
			{
				bitField0_ = (bitField0_ & ~0x00000800);
				strideW_ = 0;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> weightFillerBuilder_;

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public boolean hasWeightFiller()
			{
				return ((bitField0_ & 0x00001000) == 0x00001000);
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller()
			{
				if (weightFillerBuilder_ == null)
				{
					return weightFiller_;
				} else
				{
					return weightFillerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder setWeightFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (weightFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					weightFiller_ = value;
					onChanged();
				} else
				{
					weightFillerBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00001000;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder setWeightFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = builderForValue.build();
					onChanged();
				} else
				{
					weightFillerBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00001000;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder mergeWeightFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (weightFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00001000) == 0x00001000) &&
							weightFiller_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					{
						weightFiller_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder(weightFiller_).mergeFrom(value).buildPartial();
					} else
					{
						weightFiller_ = value;
					}
					onChanged();
				} else
				{
					weightFillerBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00001000;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder clearWeightFiller()
			{
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					weightFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00001000);
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getWeightFillerBuilder()
			{
				bitField0_ |= 0x00001000;
				onChanged();
				return getWeightFillerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder()
			{
				if (weightFillerBuilder_ != null)
				{
					return weightFillerBuilder_.getMessageOrBuilder();
				} else
				{
					return weightFiller_;
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 7;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getWeightFillerFieldBuilder()
			{
				if (weightFillerBuilder_ == null)
				{
					weightFillerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									getWeightFiller(),
									getParentForChildren(),
									isClean());
					weightFiller_ = null;
				}
				return weightFillerBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> biasFillerBuilder_;

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public boolean hasBiasFiller()
			{
				return ((bitField0_ & 0x00002000) == 0x00002000);
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller()
			{
				if (biasFillerBuilder_ == null)
				{
					return biasFiller_;
				} else
				{
					return biasFillerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder setBiasFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (biasFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					biasFiller_ = value;
					onChanged();
				} else
				{
					biasFillerBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00002000;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder setBiasFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = builderForValue.build();
					onChanged();
				} else
				{
					biasFillerBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00002000;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder mergeBiasFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (biasFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00002000) == 0x00002000) &&
							biasFiller_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					{
						biasFiller_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder(biasFiller_).mergeFrom(value).buildPartial();
					} else
					{
						biasFiller_ = value;
					}
					onChanged();
				} else
				{
					biasFillerBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00002000;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder clearBiasFiller()
			{
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					biasFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00002000);
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getBiasFillerBuilder()
			{
				bitField0_ |= 0x00002000;
				onChanged();
				return getBiasFillerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder()
			{
				if (biasFillerBuilder_ != null)
				{
					return biasFillerBuilder_.getMessageOrBuilder();
				} else
				{
					return biasFiller_;
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 8;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getBiasFillerFieldBuilder()
			{
				if (biasFillerBuilder_ == null)
				{
					biasFillerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									getBiasFiller(),
									getParentForChildren(),
									isClean());
					biasFiller_ = null;
				}
				return biasFillerBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine.DEFAULT;

			/**
			 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
			 */
			@Override
			public boolean hasEngine()
			{
				return ((bitField0_ & 0x00004000) == 0x00004000);
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine getEngine()
			{
				return engine_;
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
			 */
			public Builder setEngine(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00004000;
				engine_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.ConvolutionParameter.Engine engine = 15 [default = DEFAULT];</code>
			 */
			public Builder clearEngine()
			{
				bitField0_ = (bitField0_ & ~0x00004000);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ConvolutionParameter.Engine.DEFAULT;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ConvolutionParameter)
		}

		static
		{
			defaultInstance = new ConvolutionParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)
	}

	public interface DataParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.DataParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		boolean hasSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		java.lang.String getSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSourceBytes();

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		boolean hasBatchSize();

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		int getBatchSize();

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		boolean hasRandSkip();

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		int getRandSkip();

		/**
		 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
		 */
		boolean hasBackend();

		/**
		 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB getBackend();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		boolean hasScale();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		float getScale();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		boolean hasMeanFile();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		java.lang.String getMeanFile();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		com.google.protobuf.ByteString
				getMeanFileBytes();

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		boolean hasCropSize();

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		int getCropSize();

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		boolean hasMirror();

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		boolean getMirror();
	}

	/**
	 * Protobuf type {@code caffe.DataParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by DataLayer
	 * </pre>
	 */
	public static final class DataParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.DataParameter)
			DataParameterOrBuilder
	{
		// Use DataParameter.newBuilder() to construct.
		private DataParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private DataParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final DataParameter defaultInstance;

		public static DataParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public DataParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private DataParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						source_ = bs;
						break;
					}
					case 21:
					{
						bitField0_ |= 0x00000010;
						scale_ = input.readFloat();
						break;
					}
					case 26:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000020;
						meanFile_ = bs;
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000002;
						batchSize_ = input.readUInt32();
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000040;
						cropSize_ = input.readUInt32();
						break;
					}
					case 48:
					{
						bitField0_ |= 0x00000080;
						mirror_ = input.readBool();
						break;
					}
					case 56:
					{
						bitField0_ |= 0x00000004;
						randSkip_ = input.readUInt32();
						break;
					}
					case 64:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(8, rawValue);
						} else
						{
							bitField0_ |= 0x00000008;
							backend_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DataParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DataParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<DataParameter> PARSER =
				new com.google.protobuf.AbstractParser<DataParameter>()
				{
					@Override
					public DataParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new DataParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<DataParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.DataParameter.DB}
		 */
		public enum DB
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>LEVELDB = 0;</code>
			 */
			LEVELDB(0, 0),
			/**
			 * <code>LMDB = 1;</code>
			 */
			LMDB(1, 1), ;

			/**
			 * <code>LEVELDB = 0;</code>
			 */
			public static final int LEVELDB_VALUE = 0;
			/**
			 * <code>LMDB = 1;</code>
			 */
			public static final int LMDB_VALUE = 1;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static DB valueOf(int value)
			{
				switch (value) {
				case 0:
					return LEVELDB;
				case 1:
					return LMDB;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<DB>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<DB> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<DB>()
					{
						@Override
						public DB findValueByNumber(int number)
						{
							return DB.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final DB[] VALUES = values();

			public static DB valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private DB(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.DataParameter.DB)
		}

		private int bitField0_;
		public static final int SOURCE_FIELD_NUMBER = 1;
		private java.lang.Object source_;

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public boolean hasSource()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public java.lang.String getSource()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					source_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSourceBytes()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				source_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int BATCH_SIZE_FIELD_NUMBER = 4;
		private int batchSize_;

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public boolean hasBatchSize()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public int getBatchSize()
		{
			return batchSize_;
		}

		public static final int RAND_SKIP_FIELD_NUMBER = 7;
		private int randSkip_;

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		@Override
		public boolean hasRandSkip()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		@Override
		public int getRandSkip()
		{
			return randSkip_;
		}

		public static final int BACKEND_FIELD_NUMBER = 8;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB backend_;

		/**
		 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
		 */
		@Override
		public boolean hasBackend()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB getBackend()
		{
			return backend_;
		}

		public static final int SCALE_FIELD_NUMBER = 2;
		private float scale_;

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		@Override
		public boolean hasScale()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		@Override
		public float getScale()
		{
			return scale_;
		}

		public static final int MEAN_FILE_FIELD_NUMBER = 3;
		private java.lang.Object meanFile_;

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public boolean hasMeanFile()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public java.lang.String getMeanFile()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					meanFile_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getMeanFileBytes()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				meanFile_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int CROP_SIZE_FIELD_NUMBER = 5;
		private int cropSize_;

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		@Override
		public boolean hasCropSize()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		@Override
		public int getCropSize()
		{
			return cropSize_;
		}

		public static final int MIRROR_FIELD_NUMBER = 6;
		private boolean mirror_;

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		@Override
		public boolean hasMirror()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		@Override
		public boolean getMirror()
		{
			return mirror_;
		}

		private void initFields()
		{
			source_ = "";
			batchSize_ = 0;
			randSkip_ = 0;
			backend_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB.LEVELDB;
			scale_ = 1F;
			meanFile_ = "";
			cropSize_ = 0;
			mirror_ = false;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeFloat(2, scale_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeBytes(3, getMeanFileBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeUInt32(4, batchSize_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeUInt32(5, cropSize_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeBool(6, mirror_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(7, randSkip_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeEnum(8, backend_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(2, scale_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(3, getMeanFileBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(4, batchSize_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(5, cropSize_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(6, mirror_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(7, randSkip_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(8, backend_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.DataParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by DataLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.DataParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DataParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DataParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				source_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				batchSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				randSkip_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				backend_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB.LEVELDB;
				bitField0_ = (bitField0_ & ~0x00000008);
				scale_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000010);
				meanFile_ = "";
				bitField0_ = (bitField0_ & ~0x00000020);
				cropSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000040);
				mirror_ = false;
				bitField0_ = (bitField0_ & ~0x00000080);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DataParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.source_ = source_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.batchSize_ = batchSize_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.randSkip_ = randSkip_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.backend_ = backend_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.scale_ = scale_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.meanFile_ = meanFile_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.cropSize_ = cropSize_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.mirror_ = mirror_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.getDefaultInstance())
					return this;
				if (other.hasSource())
				{
					bitField0_ |= 0x00000001;
					source_ = other.source_;
					onChanged();
				}
				if (other.hasBatchSize())
				{
					setBatchSize(other.getBatchSize());
				}
				if (other.hasRandSkip())
				{
					setRandSkip(other.getRandSkip());
				}
				if (other.hasBackend())
				{
					setBackend(other.getBackend());
				}
				if (other.hasScale())
				{
					setScale(other.getScale());
				}
				if (other.hasMeanFile())
				{
					bitField0_ |= 0x00000020;
					meanFile_ = other.meanFile_;
					onChanged();
				}
				if (other.hasCropSize())
				{
					setCropSize(other.getCropSize());
				}
				if (other.hasMirror())
				{
					setMirror(other.getMirror());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object source_ = "";

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public boolean hasSource()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public java.lang.String getSource()
			{
				java.lang.Object ref = source_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						source_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSourceBytes()
			{
				java.lang.Object ref = source_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					source_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSource(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder clearSource()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				source_ = getDefaultInstance().getSource();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSourceBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			private int batchSize_;

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public boolean hasBatchSize()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public int getBatchSize()
			{
				return batchSize_;
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder setBatchSize(int value)
			{
				bitField0_ |= 0x00000002;
				batchSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder clearBatchSize()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				batchSize_ = 0;
				onChanged();
				return this;
			}

			private int randSkip_;

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			@Override
			public boolean hasRandSkip()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			@Override
			public int getRandSkip()
			{
				return randSkip_;
			}

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			public Builder setRandSkip(int value)
			{
				bitField0_ |= 0x00000004;
				randSkip_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			public Builder clearRandSkip()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				randSkip_ = 0;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB backend_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB.LEVELDB;

			/**
			 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
			 */
			@Override
			public boolean hasBackend()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB getBackend()
			{
				return backend_;
			}

			/**
			 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
			 */
			public Builder setBackend(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000008;
				backend_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.DataParameter.DB backend = 8 [default = LEVELDB];</code>
			 */
			public Builder clearBackend()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				backend_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DataParameter.DB.LEVELDB;
				onChanged();
				return this;
			}

			private float scale_ = 1F;

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			@Override
			public boolean hasScale()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			@Override
			public float getScale()
			{
				return scale_;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			public Builder setScale(float value)
			{
				bitField0_ |= 0x00000010;
				scale_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			public Builder clearScale()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				scale_ = 1F;
				onChanged();
				return this;
			}

			private java.lang.Object meanFile_ = "";

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public boolean hasMeanFile()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public java.lang.String getMeanFile()
			{
				java.lang.Object ref = meanFile_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						meanFile_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getMeanFileBytes()
			{
				java.lang.Object ref = meanFile_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					meanFile_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder setMeanFile(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000020;
				meanFile_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder clearMeanFile()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				meanFile_ = getDefaultInstance().getMeanFile();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder setMeanFileBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000020;
				meanFile_ = value;
				onChanged();
				return this;
			}

			private int cropSize_;

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			@Override
			public boolean hasCropSize()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			@Override
			public int getCropSize()
			{
				return cropSize_;
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			public Builder setCropSize(int value)
			{
				bitField0_ |= 0x00000040;
				cropSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			public Builder clearCropSize()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				cropSize_ = 0;
				onChanged();
				return this;
			}

			private boolean mirror_;

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			@Override
			public boolean hasMirror()
			{
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			@Override
			public boolean getMirror()
			{
				return mirror_;
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			public Builder setMirror(boolean value)
			{
				bitField0_ |= 0x00000080;
				mirror_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			public Builder clearMirror()
			{
				bitField0_ = (bitField0_ & ~0x00000080);
				mirror_ = false;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.DataParameter)
		}

		static
		{
			defaultInstance = new DataParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.DataParameter)
	}

	public interface DropoutParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.DropoutParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		boolean hasDropoutRatio();

		/**
		 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		float getDropoutRatio();
	}

	/**
	 * Protobuf type {@code caffe.DropoutParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by DropoutLayer
	 * </pre>
	 */
	public static final class DropoutParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.DropoutParameter)
			DropoutParameterOrBuilder
	{
		// Use DropoutParameter.newBuilder() to construct.
		private DropoutParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private DropoutParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final DropoutParameter defaultInstance;

		public static DropoutParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public DropoutParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private DropoutParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 13:
					{
						bitField0_ |= 0x00000001;
						dropoutRatio_ = input.readFloat();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DropoutParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DropoutParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<DropoutParameter> PARSER =
				new com.google.protobuf.AbstractParser<DropoutParameter>()
				{
					@Override
					public DropoutParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new DropoutParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<DropoutParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int DROPOUT_RATIO_FIELD_NUMBER = 1;
		private float dropoutRatio_;

		/**
		 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		@Override
		public boolean hasDropoutRatio()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		@Override
		public float getDropoutRatio()
		{
			return dropoutRatio_;
		}

		private void initFields()
		{
			dropoutRatio_ = 0.5F;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeFloat(1, dropoutRatio_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(1, dropoutRatio_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.DropoutParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by DropoutLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.DropoutParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DropoutParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DropoutParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				dropoutRatio_ = 0.5F;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DropoutParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.dropoutRatio_ = dropoutRatio_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter.getDefaultInstance())
					return this;
				if (other.hasDropoutRatio())
				{
					setDropoutRatio(other.getDropoutRatio());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DropoutParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private float dropoutRatio_ = 0.5F;

			/**
			 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			@Override
			public boolean hasDropoutRatio()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			@Override
			public float getDropoutRatio()
			{
				return dropoutRatio_;
			}

			/**
			 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			public Builder setDropoutRatio(float value)
			{
				bitField0_ |= 0x00000001;
				dropoutRatio_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float dropout_ratio = 1 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			public Builder clearDropoutRatio()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				dropoutRatio_ = 0.5F;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.DropoutParameter)
		}

		static
		{
			defaultInstance = new DropoutParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.DropoutParameter)
	}

	public interface DummyDataParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.DummyDataParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter>
				getDataFillerList();

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getDataFiller(int index);

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		int getDataFillerCount();

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
				getDataFillerOrBuilderList();

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getDataFillerOrBuilder(
				int index);

		/**
		 * <code>repeated uint32 num = 2;</code>
		 */
		java.util.List<java.lang.Integer> getNumList();

		/**
		 * <code>repeated uint32 num = 2;</code>
		 */
		int getNumCount();

		/**
		 * <code>repeated uint32 num = 2;</code>
		 */
		int getNum(int index);

		/**
		 * <code>repeated uint32 channels = 3;</code>
		 */
		java.util.List<java.lang.Integer> getChannelsList();

		/**
		 * <code>repeated uint32 channels = 3;</code>
		 */
		int getChannelsCount();

		/**
		 * <code>repeated uint32 channels = 3;</code>
		 */
		int getChannels(int index);

		/**
		 * <code>repeated uint32 height = 4;</code>
		 */
		java.util.List<java.lang.Integer> getHeightList();

		/**
		 * <code>repeated uint32 height = 4;</code>
		 */
		int getHeightCount();

		/**
		 * <code>repeated uint32 height = 4;</code>
		 */
		int getHeight(int index);

		/**
		 * <code>repeated uint32 width = 5;</code>
		 */
		java.util.List<java.lang.Integer> getWidthList();

		/**
		 * <code>repeated uint32 width = 5;</code>
		 */
		int getWidthCount();

		/**
		 * <code>repeated uint32 width = 5;</code>
		 */
		int getWidth(int index);
	}

	/**
	 * Protobuf type {@code caffe.DummyDataParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by DummyDataLayer.
	 * DummyDataLayer fills any number of arbitrarily shaped blobs with random
	 * (or constant) data generated by "Fillers" (see "message FillerParameter").
	 * </pre>
	 */
	public static final class DummyDataParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.DummyDataParameter)
			DummyDataParameterOrBuilder
	{
		// Use DummyDataParameter.newBuilder() to construct.
		private DummyDataParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private DummyDataParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final DummyDataParameter defaultInstance;

		public static DummyDataParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public DummyDataParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private DummyDataParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						if (!((mutable_bitField0_ & 0x00000001) == 0x00000001))
						{
							dataFiller_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter>();
							mutable_bitField0_ |= 0x00000001;
						}
						dataFiller_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry));
						break;
					}
					case 16:
					{
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002))
						{
							num_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000002;
						}
						num_.add(input.readUInt32());
						break;
					}
					case 18:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0)
						{
							num_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000002;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							num_.add(input.readUInt32());
						}
						input.popLimit(limit);
						break;
					}
					case 24:
					{
						if (!((mutable_bitField0_ & 0x00000004) == 0x00000004))
						{
							channels_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000004;
						}
						channels_.add(input.readUInt32());
						break;
					}
					case 26:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000004) == 0x00000004) && input.getBytesUntilLimit() > 0)
						{
							channels_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000004;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							channels_.add(input.readUInt32());
						}
						input.popLimit(limit);
						break;
					}
					case 32:
					{
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008))
						{
							height_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000008;
						}
						height_.add(input.readUInt32());
						break;
					}
					case 34:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000008) == 0x00000008) && input.getBytesUntilLimit() > 0)
						{
							height_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000008;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							height_.add(input.readUInt32());
						}
						input.popLimit(limit);
						break;
					}
					case 40:
					{
						if (!((mutable_bitField0_ & 0x00000010) == 0x00000010))
						{
							width_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000010;
						}
						width_.add(input.readUInt32());
						break;
					}
					case 42:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000010) == 0x00000010) && input.getBytesUntilLimit() > 0)
						{
							width_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000010;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							width_.add(input.readUInt32());
						}
						input.popLimit(limit);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000001) == 0x00000001))
				{
					dataFiller_ = java.util.Collections.unmodifiableList(dataFiller_);
				}
				if (((mutable_bitField0_ & 0x00000002) == 0x00000002))
				{
					num_ = java.util.Collections.unmodifiableList(num_);
				}
				if (((mutable_bitField0_ & 0x00000004) == 0x00000004))
				{
					channels_ = java.util.Collections.unmodifiableList(channels_);
				}
				if (((mutable_bitField0_ & 0x00000008) == 0x00000008))
				{
					height_ = java.util.Collections.unmodifiableList(height_);
				}
				if (((mutable_bitField0_ & 0x00000010) == 0x00000010))
				{
					width_ = java.util.Collections.unmodifiableList(width_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DummyDataParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DummyDataParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<DummyDataParameter> PARSER =
				new com.google.protobuf.AbstractParser<DummyDataParameter>()
				{
					@Override
					public DummyDataParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new DummyDataParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<DummyDataParameter> getParserForType()
		{
			return PARSER;
		}

		public static final int DATA_FILLER_FIELD_NUMBER = 1;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter> dataFiller_;

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter> getDataFillerList()
		{
			return dataFiller_;
		}

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
				getDataFillerOrBuilderList()
		{
			return dataFiller_;
		}

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		@Override
		public int getDataFillerCount()
		{
			return dataFiller_.size();
		}

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getDataFiller(int index)
		{
			return dataFiller_.get(index);
		}

		/**
		 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
		 *
		 * <pre>
		 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
		 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
		 * data_fillers.
		 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
		 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
		 * specified, the ith is applied to the ith top blob.
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getDataFillerOrBuilder(
				int index)
		{
			return dataFiller_.get(index);
		}

		public static final int NUM_FIELD_NUMBER = 2;
		private java.util.List<java.lang.Integer> num_;

		/**
		 * <code>repeated uint32 num = 2;</code>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getNumList()
		{
			return num_;
		}

		/**
		 * <code>repeated uint32 num = 2;</code>
		 */
		@Override
		public int getNumCount()
		{
			return num_.size();
		}

		/**
		 * <code>repeated uint32 num = 2;</code>
		 */
		@Override
		public int getNum(int index)
		{
			return num_.get(index);
		}

		public static final int CHANNELS_FIELD_NUMBER = 3;
		private java.util.List<java.lang.Integer> channels_;

		/**
		 * <code>repeated uint32 channels = 3;</code>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getChannelsList()
		{
			return channels_;
		}

		/**
		 * <code>repeated uint32 channels = 3;</code>
		 */
		@Override
		public int getChannelsCount()
		{
			return channels_.size();
		}

		/**
		 * <code>repeated uint32 channels = 3;</code>
		 */
		@Override
		public int getChannels(int index)
		{
			return channels_.get(index);
		}

		public static final int HEIGHT_FIELD_NUMBER = 4;
		private java.util.List<java.lang.Integer> height_;

		/**
		 * <code>repeated uint32 height = 4;</code>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getHeightList()
		{
			return height_;
		}

		/**
		 * <code>repeated uint32 height = 4;</code>
		 */
		@Override
		public int getHeightCount()
		{
			return height_.size();
		}

		/**
		 * <code>repeated uint32 height = 4;</code>
		 */
		@Override
		public int getHeight(int index)
		{
			return height_.get(index);
		}

		public static final int WIDTH_FIELD_NUMBER = 5;
		private java.util.List<java.lang.Integer> width_;

		/**
		 * <code>repeated uint32 width = 5;</code>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getWidthList()
		{
			return width_;
		}

		/**
		 * <code>repeated uint32 width = 5;</code>
		 */
		@Override
		public int getWidthCount()
		{
			return width_.size();
		}

		/**
		 * <code>repeated uint32 width = 5;</code>
		 */
		@Override
		public int getWidth(int index)
		{
			return width_.get(index);
		}

		private void initFields()
		{
			dataFiller_ = java.util.Collections.emptyList();
			num_ = java.util.Collections.emptyList();
			channels_ = java.util.Collections.emptyList();
			height_ = java.util.Collections.emptyList();
			width_ = java.util.Collections.emptyList();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			for (int i = 0; i < dataFiller_.size(); i++)
			{
				output.writeMessage(1, dataFiller_.get(i));
			}
			for (int i = 0; i < num_.size(); i++)
			{
				output.writeUInt32(2, num_.get(i));
			}
			for (int i = 0; i < channels_.size(); i++)
			{
				output.writeUInt32(3, channels_.get(i));
			}
			for (int i = 0; i < height_.size(); i++)
			{
				output.writeUInt32(4, height_.get(i));
			}
			for (int i = 0; i < width_.size(); i++)
			{
				output.writeUInt32(5, width_.get(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			for (int i = 0; i < dataFiller_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(1, dataFiller_.get(i));
			}
			{
				int dataSize = 0;
				for (int i = 0; i < num_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeUInt32SizeNoTag(num_.get(i));
				}
				size += dataSize;
				size += 1 * getNumList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < channels_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeUInt32SizeNoTag(channels_.get(i));
				}
				size += dataSize;
				size += 1 * getChannelsList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < height_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeUInt32SizeNoTag(height_.get(i));
				}
				size += dataSize;
				size += 1 * getHeightList().size();
			}
			{
				int dataSize = 0;
				for (int i = 0; i < width_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeUInt32SizeNoTag(width_.get(i));
				}
				size += dataSize;
				size += 1 * getWidthList().size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.DummyDataParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by DummyDataLayer.
		 * DummyDataLayer fills any number of arbitrarily shaped blobs with random
		 * (or constant) data generated by "Fillers" (see "message FillerParameter").
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.DummyDataParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DummyDataParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DummyDataParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getDataFillerFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				if (dataFillerBuilder_ == null)
				{
					dataFiller_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000001);
				} else
				{
					dataFillerBuilder_.clear();
				}
				num_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000002);
				channels_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000004);
				height_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000008);
				width_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000010);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_DummyDataParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter(this);
				int from_bitField0_ = bitField0_;
				if (dataFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00000001) == 0x00000001))
					{
						dataFiller_ = java.util.Collections.unmodifiableList(dataFiller_);
						bitField0_ = (bitField0_ & ~0x00000001);
					}
					result.dataFiller_ = dataFiller_;
				} else
				{
					result.dataFiller_ = dataFillerBuilder_.build();
				}
				if (((bitField0_ & 0x00000002) == 0x00000002))
				{
					num_ = java.util.Collections.unmodifiableList(num_);
					bitField0_ = (bitField0_ & ~0x00000002);
				}
				result.num_ = num_;
				if (((bitField0_ & 0x00000004) == 0x00000004))
				{
					channels_ = java.util.Collections.unmodifiableList(channels_);
					bitField0_ = (bitField0_ & ~0x00000004);
				}
				result.channels_ = channels_;
				if (((bitField0_ & 0x00000008) == 0x00000008))
				{
					height_ = java.util.Collections.unmodifiableList(height_);
					bitField0_ = (bitField0_ & ~0x00000008);
				}
				result.height_ = height_;
				if (((bitField0_ & 0x00000010) == 0x00000010))
				{
					width_ = java.util.Collections.unmodifiableList(width_);
					bitField0_ = (bitField0_ & ~0x00000010);
				}
				result.width_ = width_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter.getDefaultInstance())
					return this;
				if (dataFillerBuilder_ == null)
				{
					if (!other.dataFiller_.isEmpty())
					{
						if (dataFiller_.isEmpty())
						{
							dataFiller_ = other.dataFiller_;
							bitField0_ = (bitField0_ & ~0x00000001);
						} else
						{
							ensureDataFillerIsMutable();
							dataFiller_.addAll(other.dataFiller_);
						}
						onChanged();
					}
				} else
				{
					if (!other.dataFiller_.isEmpty())
					{
						if (dataFillerBuilder_.isEmpty())
						{
							dataFillerBuilder_.dispose();
							dataFillerBuilder_ = null;
							dataFiller_ = other.dataFiller_;
							bitField0_ = (bitField0_ & ~0x00000001);
							dataFillerBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getDataFillerFieldBuilder() : null;
						} else
						{
							dataFillerBuilder_.addAllMessages(other.dataFiller_);
						}
					}
				}
				if (!other.num_.isEmpty())
				{
					if (num_.isEmpty())
					{
						num_ = other.num_;
						bitField0_ = (bitField0_ & ~0x00000002);
					} else
					{
						ensureNumIsMutable();
						num_.addAll(other.num_);
					}
					onChanged();
				}
				if (!other.channels_.isEmpty())
				{
					if (channels_.isEmpty())
					{
						channels_ = other.channels_;
						bitField0_ = (bitField0_ & ~0x00000004);
					} else
					{
						ensureChannelsIsMutable();
						channels_.addAll(other.channels_);
					}
					onChanged();
				}
				if (!other.height_.isEmpty())
				{
					if (height_.isEmpty())
					{
						height_ = other.height_;
						bitField0_ = (bitField0_ & ~0x00000008);
					} else
					{
						ensureHeightIsMutable();
						height_.addAll(other.height_);
					}
					onChanged();
				}
				if (!other.width_.isEmpty())
				{
					if (width_.isEmpty())
					{
						width_ = other.width_;
						bitField0_ = (bitField0_ & ~0x00000010);
					} else
					{
						ensureWidthIsMutable();
						width_.addAll(other.width_);
					}
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.DummyDataParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter> dataFiller_ =
					java.util.Collections.emptyList();

			private void ensureDataFillerIsMutable()
			{
				if (!((bitField0_ & 0x00000001) == 0x00000001))
				{
					dataFiller_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter>(dataFiller_);
					bitField0_ |= 0x00000001;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> dataFillerBuilder_;

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter> getDataFillerList()
			{
				if (dataFillerBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(dataFiller_);
				} else
				{
					return dataFillerBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			@Override
			public int getDataFillerCount()
			{
				if (dataFillerBuilder_ == null)
				{
					return dataFiller_.size();
				} else
				{
					return dataFillerBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getDataFiller(int index)
			{
				if (dataFillerBuilder_ == null)
				{
					return dataFiller_.get(index);
				} else
				{
					return dataFillerBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder setDataFiller(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (dataFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureDataFillerIsMutable();
					dataFiller_.set(index, value);
					onChanged();
				} else
				{
					dataFillerBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder setDataFiller(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (dataFillerBuilder_ == null)
				{
					ensureDataFillerIsMutable();
					dataFiller_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					dataFillerBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder addDataFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (dataFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureDataFillerIsMutable();
					dataFiller_.add(value);
					onChanged();
				} else
				{
					dataFillerBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder addDataFiller(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (dataFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureDataFillerIsMutable();
					dataFiller_.add(index, value);
					onChanged();
				} else
				{
					dataFillerBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder addDataFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (dataFillerBuilder_ == null)
				{
					ensureDataFillerIsMutable();
					dataFiller_.add(builderForValue.build());
					onChanged();
				} else
				{
					dataFillerBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder addDataFiller(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (dataFillerBuilder_ == null)
				{
					ensureDataFillerIsMutable();
					dataFiller_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					dataFillerBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder addAllDataFiller(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter> values)
			{
				if (dataFillerBuilder_ == null)
				{
					ensureDataFillerIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, dataFiller_);
					onChanged();
				} else
				{
					dataFillerBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder clearDataFiller()
			{
				if (dataFillerBuilder_ == null)
				{
					dataFiller_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00000001);
					onChanged();
				} else
				{
					dataFillerBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public Builder removeDataFiller(int index)
			{
				if (dataFillerBuilder_ == null)
				{
					ensureDataFillerIsMutable();
					dataFiller_.remove(index);
					onChanged();
				} else
				{
					dataFillerBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getDataFillerBuilder(
					int index)
			{
				return getDataFillerFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getDataFillerOrBuilder(
					int index)
			{
				if (dataFillerBuilder_ == null)
				{
					return dataFiller_.get(index);
				} else
				{
					return dataFillerBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getDataFillerOrBuilderList()
			{
				if (dataFillerBuilder_ != null)
				{
					return dataFillerBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(dataFiller_);
				}
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder addDataFillerBuilder()
			{
				return getDataFillerFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder addDataFillerBuilder(
					int index)
			{
				return getDataFillerFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.FillerParameter data_filler = 1;</code>
			 *
			 * <pre>
			 * This layer produces N &gt;= 1 top blobs.  DummyDataParameter must specify 1 or N
			 * num, N channels, N height, and N width fields, and must specify 0, 1 or N
			 * data_fillers.
			 * If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
			 * If 1 data_filler is specified, it is applied to all top blobs.  If N are
			 * specified, the ith is applied to the ith top blob.
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder>
					getDataFillerBuilderList()
			{
				return getDataFillerFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getDataFillerFieldBuilder()
			{
				if (dataFillerBuilder_ == null)
				{
					dataFillerBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									dataFiller_,
									((bitField0_ & 0x00000001) == 0x00000001),
									getParentForChildren(),
									isClean());
					dataFiller_ = null;
				}
				return dataFillerBuilder_;
			}

			private java.util.List<java.lang.Integer> num_ = java.util.Collections.emptyList();

			private void ensureNumIsMutable()
			{
				if (!((bitField0_ & 0x00000002) == 0x00000002))
				{
					num_ = new java.util.ArrayList<java.lang.Integer>(num_);
					bitField0_ |= 0x00000002;
				}
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getNumList()
			{
				return java.util.Collections.unmodifiableList(num_);
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			@Override
			public int getNumCount()
			{
				return num_.size();
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			@Override
			public int getNum(int index)
			{
				return num_.get(index);
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			public Builder setNum(
					int index, int value)
			{
				ensureNumIsMutable();
				num_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			public Builder addNum(int value)
			{
				ensureNumIsMutable();
				num_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			public Builder addAllNum(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureNumIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, num_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 num = 2;</code>
			 */
			public Builder clearNum()
			{
				num_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000002);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Integer> channels_ = java.util.Collections.emptyList();

			private void ensureChannelsIsMutable()
			{
				if (!((bitField0_ & 0x00000004) == 0x00000004))
				{
					channels_ = new java.util.ArrayList<java.lang.Integer>(channels_);
					bitField0_ |= 0x00000004;
				}
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getChannelsList()
			{
				return java.util.Collections.unmodifiableList(channels_);
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			@Override
			public int getChannelsCount()
			{
				return channels_.size();
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			@Override
			public int getChannels(int index)
			{
				return channels_.get(index);
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			public Builder setChannels(
					int index, int value)
			{
				ensureChannelsIsMutable();
				channels_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			public Builder addChannels(int value)
			{
				ensureChannelsIsMutable();
				channels_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			public Builder addAllChannels(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureChannelsIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, channels_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 channels = 3;</code>
			 */
			public Builder clearChannels()
			{
				channels_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000004);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Integer> height_ = java.util.Collections.emptyList();

			private void ensureHeightIsMutable()
			{
				if (!((bitField0_ & 0x00000008) == 0x00000008))
				{
					height_ = new java.util.ArrayList<java.lang.Integer>(height_);
					bitField0_ |= 0x00000008;
				}
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getHeightList()
			{
				return java.util.Collections.unmodifiableList(height_);
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			@Override
			public int getHeightCount()
			{
				return height_.size();
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			@Override
			public int getHeight(int index)
			{
				return height_.get(index);
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			public Builder setHeight(
					int index, int value)
			{
				ensureHeightIsMutable();
				height_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			public Builder addHeight(int value)
			{
				ensureHeightIsMutable();
				height_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			public Builder addAllHeight(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureHeightIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, height_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 height = 4;</code>
			 */
			public Builder clearHeight()
			{
				height_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000008);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Integer> width_ = java.util.Collections.emptyList();

			private void ensureWidthIsMutable()
			{
				if (!((bitField0_ & 0x00000010) == 0x00000010))
				{
					width_ = new java.util.ArrayList<java.lang.Integer>(width_);
					bitField0_ |= 0x00000010;
				}
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getWidthList()
			{
				return java.util.Collections.unmodifiableList(width_);
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			@Override
			public int getWidthCount()
			{
				return width_.size();
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			@Override
			public int getWidth(int index)
			{
				return width_.get(index);
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			public Builder setWidth(
					int index, int value)
			{
				ensureWidthIsMutable();
				width_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			public Builder addWidth(int value)
			{
				ensureWidthIsMutable();
				width_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			public Builder addAllWidth(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureWidthIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, width_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 width = 5;</code>
			 */
			public Builder clearWidth()
			{
				width_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000010);
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.DummyDataParameter)
		}

		static
		{
			defaultInstance = new DummyDataParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)
	}

	public interface EltwiseParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.EltwiseParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
		 *
		 * <pre>
		 * element-wise operation
		 * </pre>
		 */
		boolean hasOperation();

		/**
		 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
		 *
		 * <pre>
		 * element-wise operation
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp getOperation();

		/**
		 * <code>repeated float coeff = 2;</code>
		 *
		 * <pre>
		 * blob-wise coefficient for SUM operation
		 * </pre>
		 */
		java.util.List<java.lang.Float> getCoeffList();

		/**
		 * <code>repeated float coeff = 2;</code>
		 *
		 * <pre>
		 * blob-wise coefficient for SUM operation
		 * </pre>
		 */
		int getCoeffCount();

		/**
		 * <code>repeated float coeff = 2;</code>
		 *
		 * <pre>
		 * blob-wise coefficient for SUM operation
		 * </pre>
		 */
		float getCoeff(int index);

		/**
		 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
		 *
		 * <pre>
		 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
		 * of computing the gradient for the PROD operation. (No effect for SUM op.)
		 * </pre>
		 */
		boolean hasStableProdGrad();

		/**
		 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
		 *
		 * <pre>
		 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
		 * of computing the gradient for the PROD operation. (No effect for SUM op.)
		 * </pre>
		 */
		boolean getStableProdGrad();
	}

	/**
	 * Protobuf type {@code caffe.EltwiseParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by EltwiseLayer
	 * </pre>
	 */
	public static final class EltwiseParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.EltwiseParameter)
			EltwiseParameterOrBuilder
	{
		// Use EltwiseParameter.newBuilder() to construct.
		private EltwiseParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private EltwiseParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final EltwiseParameter defaultInstance;

		public static EltwiseParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public EltwiseParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private EltwiseParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							operation_ = value;
						}
						break;
					}
					case 21:
					{
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002))
						{
							coeff_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000002;
						}
						coeff_.add(input.readFloat());
						break;
					}
					case 18:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0)
						{
							coeff_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00000002;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							coeff_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000002;
						stableProdGrad_ = input.readBool();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000002) == 0x00000002))
				{
					coeff_ = java.util.Collections.unmodifiableList(coeff_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_EltwiseParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_EltwiseParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<EltwiseParameter> PARSER =
				new com.google.protobuf.AbstractParser<EltwiseParameter>()
				{
					@Override
					public EltwiseParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new EltwiseParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<EltwiseParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.EltwiseParameter.EltwiseOp}
		 */
		public enum EltwiseOp
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>PROD = 0;</code>
			 */
			PROD(0, 0),
			/**
			 * <code>SUM = 1;</code>
			 */
			SUM(1, 1),
			/**
			 * <code>MAX = 2;</code>
			 */
			MAX(2, 2), ;

			/**
			 * <code>PROD = 0;</code>
			 */
			public static final int PROD_VALUE = 0;
			/**
			 * <code>SUM = 1;</code>
			 */
			public static final int SUM_VALUE = 1;
			/**
			 * <code>MAX = 2;</code>
			 */
			public static final int MAX_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static EltwiseOp valueOf(int value)
			{
				switch (value) {
				case 0:
					return PROD;
				case 1:
					return SUM;
				case 2:
					return MAX;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<EltwiseOp>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<EltwiseOp> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<EltwiseOp>()
					{
						@Override
						public EltwiseOp findValueByNumber(int number)
						{
							return EltwiseOp.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final EltwiseOp[] VALUES = values();

			public static EltwiseOp valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private EltwiseOp(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.EltwiseParameter.EltwiseOp)
		}

		private int bitField0_;
		public static final int OPERATION_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp operation_;

		/**
		 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
		 *
		 * <pre>
		 * element-wise operation
		 * </pre>
		 */
		@Override
		public boolean hasOperation()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
		 *
		 * <pre>
		 * element-wise operation
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp getOperation()
		{
			return operation_;
		}

		public static final int COEFF_FIELD_NUMBER = 2;
		private java.util.List<java.lang.Float> coeff_;

		/**
		 * <code>repeated float coeff = 2;</code>
		 *
		 * <pre>
		 * blob-wise coefficient for SUM operation
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getCoeffList()
		{
			return coeff_;
		}

		/**
		 * <code>repeated float coeff = 2;</code>
		 *
		 * <pre>
		 * blob-wise coefficient for SUM operation
		 * </pre>
		 */
		@Override
		public int getCoeffCount()
		{
			return coeff_.size();
		}

		/**
		 * <code>repeated float coeff = 2;</code>
		 *
		 * <pre>
		 * blob-wise coefficient for SUM operation
		 * </pre>
		 */
		@Override
		public float getCoeff(int index)
		{
			return coeff_.get(index);
		}

		public static final int STABLE_PROD_GRAD_FIELD_NUMBER = 3;
		private boolean stableProdGrad_;

		/**
		 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
		 *
		 * <pre>
		 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
		 * of computing the gradient for the PROD operation. (No effect for SUM op.)
		 * </pre>
		 */
		@Override
		public boolean hasStableProdGrad()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
		 *
		 * <pre>
		 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
		 * of computing the gradient for the PROD operation. (No effect for SUM op.)
		 * </pre>
		 */
		@Override
		public boolean getStableProdGrad()
		{
			return stableProdGrad_;
		}

		private void initFields()
		{
			operation_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp.SUM;
			coeff_ = java.util.Collections.emptyList();
			stableProdGrad_ = true;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, operation_.getNumber());
			}
			for (int i = 0; i < coeff_.size(); i++)
			{
				output.writeFloat(2, coeff_.get(i));
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBool(3, stableProdGrad_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, operation_.getNumber());
			}
			{
				int dataSize = 0;
				dataSize = 4 * getCoeffList().size();
				size += dataSize;
				size += 1 * getCoeffList().size();
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(3, stableProdGrad_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.EltwiseParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by EltwiseLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.EltwiseParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_EltwiseParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_EltwiseParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				operation_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp.SUM;
				bitField0_ = (bitField0_ & ~0x00000001);
				coeff_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000002);
				stableProdGrad_ = true;
				bitField0_ = (bitField0_ & ~0x00000004);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_EltwiseParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.operation_ = operation_;
				if (((bitField0_ & 0x00000002) == 0x00000002))
				{
					coeff_ = java.util.Collections.unmodifiableList(coeff_);
					bitField0_ = (bitField0_ & ~0x00000002);
				}
				result.coeff_ = coeff_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.stableProdGrad_ = stableProdGrad_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.getDefaultInstance())
					return this;
				if (other.hasOperation())
				{
					setOperation(other.getOperation());
				}
				if (!other.coeff_.isEmpty())
				{
					if (coeff_.isEmpty())
					{
						coeff_ = other.coeff_;
						bitField0_ = (bitField0_ & ~0x00000002);
					} else
					{
						ensureCoeffIsMutable();
						coeff_.addAll(other.coeff_);
					}
					onChanged();
				}
				if (other.hasStableProdGrad())
				{
					setStableProdGrad(other.getStableProdGrad());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp operation_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp.SUM;

			/**
			 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
			 *
			 * <pre>
			 * element-wise operation
			 * </pre>
			 */
			@Override
			public boolean hasOperation()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
			 *
			 * <pre>
			 * element-wise operation
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp getOperation()
			{
				return operation_;
			}

			/**
			 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
			 *
			 * <pre>
			 * element-wise operation
			 * </pre>
			 */
			public Builder setOperation(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				operation_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.EltwiseParameter.EltwiseOp operation = 1 [default = SUM];</code>
			 *
			 * <pre>
			 * element-wise operation
			 * </pre>
			 */
			public Builder clearOperation()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				operation_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.EltwiseParameter.EltwiseOp.SUM;
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> coeff_ = java.util.Collections.emptyList();

			private void ensureCoeffIsMutable()
			{
				if (!((bitField0_ & 0x00000002) == 0x00000002))
				{
					coeff_ = new java.util.ArrayList<java.lang.Float>(coeff_);
					bitField0_ |= 0x00000002;
				}
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getCoeffList()
			{
				return java.util.Collections.unmodifiableList(coeff_);
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			@Override
			public int getCoeffCount()
			{
				return coeff_.size();
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			@Override
			public float getCoeff(int index)
			{
				return coeff_.get(index);
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			public Builder setCoeff(
					int index, float value)
			{
				ensureCoeffIsMutable();
				coeff_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			public Builder addCoeff(float value)
			{
				ensureCoeffIsMutable();
				coeff_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			public Builder addAllCoeff(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureCoeffIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, coeff_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float coeff = 2;</code>
			 *
			 * <pre>
			 * blob-wise coefficient for SUM operation
			 * </pre>
			 */
			public Builder clearCoeff()
			{
				coeff_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000002);
				onChanged();
				return this;
			}

			private boolean stableProdGrad_ = true;

			/**
			 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
			 *
			 * <pre>
			 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
			 * of computing the gradient for the PROD operation. (No effect for SUM op.)
			 * </pre>
			 */
			@Override
			public boolean hasStableProdGrad()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
			 *
			 * <pre>
			 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
			 * of computing the gradient for the PROD operation. (No effect for SUM op.)
			 * </pre>
			 */
			@Override
			public boolean getStableProdGrad()
			{
				return stableProdGrad_;
			}

			/**
			 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
			 *
			 * <pre>
			 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
			 * of computing the gradient for the PROD operation. (No effect for SUM op.)
			 * </pre>
			 */
			public Builder setStableProdGrad(boolean value)
			{
				bitField0_ |= 0x00000004;
				stableProdGrad_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool stable_prod_grad = 3 [default = true];</code>
			 *
			 * <pre>
			 * Whether to use an asymptotically slower (for &gt;2 inputs) but stabler method
			 * of computing the gradient for the PROD operation. (No effect for SUM op.)
			 * </pre>
			 */
			public Builder clearStableProdGrad()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				stableProdGrad_ = true;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.EltwiseParameter)
		}

		static
		{
			defaultInstance = new EltwiseParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)
	}

	public interface ThresholdParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ThresholdParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional float threshold = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Strictly Positive values
		 * </pre>
		 */
		boolean hasThreshold();

		/**
		 * <code>optional float threshold = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Strictly Positive values
		 * </pre>
		 */
		float getThreshold();
	}

	/**
	 * Protobuf type {@code caffe.ThresholdParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ThresholdLayer
	 * </pre>
	 */
	public static final class ThresholdParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ThresholdParameter)
			ThresholdParameterOrBuilder
	{
		// Use ThresholdParameter.newBuilder() to construct.
		private ThresholdParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ThresholdParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ThresholdParameter defaultInstance;

		public static ThresholdParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ThresholdParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ThresholdParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 13:
					{
						bitField0_ |= 0x00000001;
						threshold_ = input.readFloat();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ThresholdParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ThresholdParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ThresholdParameter> PARSER =
				new com.google.protobuf.AbstractParser<ThresholdParameter>()
				{
					@Override
					public ThresholdParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ThresholdParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ThresholdParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int THRESHOLD_FIELD_NUMBER = 1;
		private float threshold_;

		/**
		 * <code>optional float threshold = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Strictly Positive values
		 * </pre>
		 */
		@Override
		public boolean hasThreshold()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional float threshold = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Strictly Positive values
		 * </pre>
		 */
		@Override
		public float getThreshold()
		{
			return threshold_;
		}

		private void initFields()
		{
			threshold_ = 0F;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeFloat(1, threshold_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(1, threshold_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ThresholdParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ThresholdLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ThresholdParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ThresholdParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ThresholdParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				threshold_ = 0F;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ThresholdParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.threshold_ = threshold_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter.getDefaultInstance())
					return this;
				if (other.hasThreshold())
				{
					setThreshold(other.getThreshold());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ThresholdParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private float threshold_;

			/**
			 * <code>optional float threshold = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Strictly Positive values
			 * </pre>
			 */
			@Override
			public boolean hasThreshold()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional float threshold = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Strictly Positive values
			 * </pre>
			 */
			@Override
			public float getThreshold()
			{
				return threshold_;
			}

			/**
			 * <code>optional float threshold = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Strictly Positive values
			 * </pre>
			 */
			public Builder setThreshold(float value)
			{
				bitField0_ |= 0x00000001;
				threshold_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float threshold = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Strictly Positive values
			 * </pre>
			 */
			public Builder clearThreshold()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				threshold_ = 0F;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ThresholdParameter)
		}

		static
		{
			defaultInstance = new ThresholdParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)
	}

	public interface HDF5DataParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.HDF5DataParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		boolean hasSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		java.lang.String getSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSourceBytes();

		/**
		 * <code>optional uint32 batch_size = 2;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		boolean hasBatchSize();

		/**
		 * <code>optional uint32 batch_size = 2;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		int getBatchSize();
	}

	/**
	 * Protobuf type {@code caffe.HDF5DataParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by HDF5DataLayer
	 * </pre>
	 */
	public static final class HDF5DataParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.HDF5DataParameter)
			HDF5DataParameterOrBuilder
	{
		// Use HDF5DataParameter.newBuilder() to construct.
		private HDF5DataParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private HDF5DataParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final HDF5DataParameter defaultInstance;

		public static HDF5DataParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public HDF5DataParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private HDF5DataParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						source_ = bs;
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						batchSize_ = input.readUInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5DataParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5DataParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<HDF5DataParameter> PARSER =
				new com.google.protobuf.AbstractParser<HDF5DataParameter>()
				{
					@Override
					public HDF5DataParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new HDF5DataParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<HDF5DataParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int SOURCE_FIELD_NUMBER = 1;
		private java.lang.Object source_;

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public boolean hasSource()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public java.lang.String getSource()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					source_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSourceBytes()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				source_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int BATCH_SIZE_FIELD_NUMBER = 2;
		private int batchSize_;

		/**
		 * <code>optional uint32 batch_size = 2;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public boolean hasBatchSize()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint32 batch_size = 2;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public int getBatchSize()
		{
			return batchSize_;
		}

		private void initFields()
		{
			source_ = "";
			batchSize_ = 0;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeUInt32(2, batchSize_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(2, batchSize_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.HDF5DataParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by HDF5DataLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.HDF5DataParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5DataParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5DataParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				source_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				batchSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5DataParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.source_ = source_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.batchSize_ = batchSize_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter.getDefaultInstance())
					return this;
				if (other.hasSource())
				{
					bitField0_ |= 0x00000001;
					source_ = other.source_;
					onChanged();
				}
				if (other.hasBatchSize())
				{
					setBatchSize(other.getBatchSize());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5DataParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object source_ = "";

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public boolean hasSource()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public java.lang.String getSource()
			{
				java.lang.Object ref = source_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						source_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSourceBytes()
			{
				java.lang.Object ref = source_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					source_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSource(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder clearSource()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				source_ = getDefaultInstance().getSource();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSourceBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			private int batchSize_;

			/**
			 * <code>optional uint32 batch_size = 2;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public boolean hasBatchSize()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint32 batch_size = 2;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public int getBatchSize()
			{
				return batchSize_;
			}

			/**
			 * <code>optional uint32 batch_size = 2;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder setBatchSize(int value)
			{
				bitField0_ |= 0x00000002;
				batchSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 batch_size = 2;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder clearBatchSize()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				batchSize_ = 0;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.HDF5DataParameter)
		}

		static
		{
			defaultInstance = new HDF5DataParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)
	}

	public interface HDF5OutputParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.HDF5OutputParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string file_name = 1;</code>
		 */
		boolean hasFileName();

		/**
		 * <code>optional string file_name = 1;</code>
		 */
		java.lang.String getFileName();

		/**
		 * <code>optional string file_name = 1;</code>
		 */
		com.google.protobuf.ByteString
				getFileNameBytes();
	}

	/**
	 * Protobuf type {@code caffe.HDF5OutputParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by HDF5OutputLayer
	 * </pre>
	 */
	public static final class HDF5OutputParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.HDF5OutputParameter)
			HDF5OutputParameterOrBuilder
	{
		// Use HDF5OutputParameter.newBuilder() to construct.
		private HDF5OutputParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private HDF5OutputParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final HDF5OutputParameter defaultInstance;

		public static HDF5OutputParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public HDF5OutputParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private HDF5OutputParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						fileName_ = bs;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5OutputParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5OutputParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<HDF5OutputParameter> PARSER =
				new com.google.protobuf.AbstractParser<HDF5OutputParameter>()
				{
					@Override
					public HDF5OutputParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new HDF5OutputParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<HDF5OutputParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int FILE_NAME_FIELD_NUMBER = 1;
		private java.lang.Object fileName_;

		/**
		 * <code>optional string file_name = 1;</code>
		 */
		@Override
		public boolean hasFileName()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string file_name = 1;</code>
		 */
		@Override
		public java.lang.String getFileName()
		{
			java.lang.Object ref = fileName_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					fileName_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string file_name = 1;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getFileNameBytes()
		{
			java.lang.Object ref = fileName_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				fileName_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		private void initFields()
		{
			fileName_ = "";
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getFileNameBytes());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getFileNameBytes());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.HDF5OutputParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by HDF5OutputLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.HDF5OutputParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5OutputParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5OutputParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				fileName_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HDF5OutputParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.fileName_ = fileName_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance())
					return this;
				if (other.hasFileName())
				{
					bitField0_ |= 0x00000001;
					fileName_ = other.fileName_;
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object fileName_ = "";

			/**
			 * <code>optional string file_name = 1;</code>
			 */
			@Override
			public boolean hasFileName()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string file_name = 1;</code>
			 */
			@Override
			public java.lang.String getFileName()
			{
				java.lang.Object ref = fileName_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						fileName_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string file_name = 1;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getFileNameBytes()
			{
				java.lang.Object ref = fileName_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					fileName_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string file_name = 1;</code>
			 */
			public Builder setFileName(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				fileName_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string file_name = 1;</code>
			 */
			public Builder clearFileName()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				fileName_ = getDefaultInstance().getFileName();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string file_name = 1;</code>
			 */
			public Builder setFileNameBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				fileName_ = value;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.HDF5OutputParameter)
		}

		static
		{
			defaultInstance = new HDF5OutputParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)
	}

	public interface HingeLossParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.HingeLossParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
		 *
		 * <pre>
		 * Specify the Norm to use L1 or L2
		 * </pre>
		 */
		boolean hasNorm();

		/**
		 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
		 *
		 * <pre>
		 * Specify the Norm to use L1 or L2
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm getNorm();
	}

	/**
	 * Protobuf type {@code caffe.HingeLossParameter}
	 */
	public static final class HingeLossParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.HingeLossParameter)
			HingeLossParameterOrBuilder
	{
		// Use HingeLossParameter.newBuilder() to construct.
		private HingeLossParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private HingeLossParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final HingeLossParameter defaultInstance;

		public static HingeLossParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public HingeLossParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private HingeLossParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							norm_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HingeLossParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HingeLossParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<HingeLossParameter> PARSER =
				new com.google.protobuf.AbstractParser<HingeLossParameter>()
				{
					@Override
					public HingeLossParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new HingeLossParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<HingeLossParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.HingeLossParameter.Norm}
		 */
		public enum Norm
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>L1 = 1;</code>
			 */
			L1(0, 1),
			/**
			 * <code>L2 = 2;</code>
			 */
			L2(1, 2), ;

			/**
			 * <code>L1 = 1;</code>
			 */
			public static final int L1_VALUE = 1;
			/**
			 * <code>L2 = 2;</code>
			 */
			public static final int L2_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Norm valueOf(int value)
			{
				switch (value) {
				case 1:
					return L1;
				case 2:
					return L2;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Norm>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Norm> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Norm>()
					{
						@Override
						public Norm findValueByNumber(int number)
						{
							return Norm.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final Norm[] VALUES = values();

			public static Norm valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Norm(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.HingeLossParameter.Norm)
		}

		private int bitField0_;
		public static final int NORM_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm norm_;

		/**
		 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
		 *
		 * <pre>
		 * Specify the Norm to use L1 or L2
		 * </pre>
		 */
		@Override
		public boolean hasNorm()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
		 *
		 * <pre>
		 * Specify the Norm to use L1 or L2
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm getNorm()
		{
			return norm_;
		}

		private void initFields()
		{
			norm_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm.L1;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, norm_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, norm_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.HingeLossParameter}
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.HingeLossParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HingeLossParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HingeLossParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				norm_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm.L1;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_HingeLossParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.norm_ = norm_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.getDefaultInstance())
					return this;
				if (other.hasNorm())
				{
					setNorm(other.getNorm());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm norm_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm.L1;

			/**
			 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
			 *
			 * <pre>
			 * Specify the Norm to use L1 or L2
			 * </pre>
			 */
			@Override
			public boolean hasNorm()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
			 *
			 * <pre>
			 * Specify the Norm to use L1 or L2
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm getNorm()
			{
				return norm_;
			}

			/**
			 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
			 *
			 * <pre>
			 * Specify the Norm to use L1 or L2
			 * </pre>
			 */
			public Builder setNorm(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				norm_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.HingeLossParameter.Norm norm = 1 [default = L1];</code>
			 *
			 * <pre>
			 * Specify the Norm to use L1 or L2
			 * </pre>
			 */
			public Builder clearNorm()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				norm_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HingeLossParameter.Norm.L1;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.HingeLossParameter)
		}

		static
		{
			defaultInstance = new HingeLossParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)
	}

	public interface ImageDataParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ImageDataParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		boolean hasSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		java.lang.String getSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSourceBytes();

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		boolean hasBatchSize();

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		int getBatchSize();

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		boolean hasRandSkip();

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		int getRandSkip();

		/**
		 * <code>optional bool shuffle = 8 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * </pre>
		 */
		boolean hasShuffle();

		/**
		 * <code>optional bool shuffle = 8 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * </pre>
		 */
		boolean getShuffle();

		/**
		 * <code>optional uint32 new_height = 9 [default = 0];</code>
		 *
		 * <pre>
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		boolean hasNewHeight();

		/**
		 * <code>optional uint32 new_height = 9 [default = 0];</code>
		 *
		 * <pre>
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		int getNewHeight();

		/**
		 * <code>optional uint32 new_width = 10 [default = 0];</code>
		 */
		boolean hasNewWidth();

		/**
		 * <code>optional uint32 new_width = 10 [default = 0];</code>
		 */
		int getNewWidth();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		boolean hasScale();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		float getScale();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		boolean hasMeanFile();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		java.lang.String getMeanFile();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		com.google.protobuf.ByteString
				getMeanFileBytes();

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		boolean hasCropSize();

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		int getCropSize();

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		boolean hasMirror();

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		boolean getMirror();
	}

	/**
	 * Protobuf type {@code caffe.ImageDataParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ImageDataLayer
	 * </pre>
	 */
	public static final class ImageDataParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ImageDataParameter)
			ImageDataParameterOrBuilder
	{
		// Use ImageDataParameter.newBuilder() to construct.
		private ImageDataParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ImageDataParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ImageDataParameter defaultInstance;

		public static ImageDataParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ImageDataParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ImageDataParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						source_ = bs;
						break;
					}
					case 21:
					{
						bitField0_ |= 0x00000040;
						scale_ = input.readFloat();
						break;
					}
					case 26:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000080;
						meanFile_ = bs;
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000002;
						batchSize_ = input.readUInt32();
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000100;
						cropSize_ = input.readUInt32();
						break;
					}
					case 48:
					{
						bitField0_ |= 0x00000200;
						mirror_ = input.readBool();
						break;
					}
					case 56:
					{
						bitField0_ |= 0x00000004;
						randSkip_ = input.readUInt32();
						break;
					}
					case 64:
					{
						bitField0_ |= 0x00000008;
						shuffle_ = input.readBool();
						break;
					}
					case 72:
					{
						bitField0_ |= 0x00000010;
						newHeight_ = input.readUInt32();
						break;
					}
					case 80:
					{
						bitField0_ |= 0x00000020;
						newWidth_ = input.readUInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ImageDataParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ImageDataParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ImageDataParameter> PARSER =
				new com.google.protobuf.AbstractParser<ImageDataParameter>()
				{
					@Override
					public ImageDataParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ImageDataParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ImageDataParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int SOURCE_FIELD_NUMBER = 1;
		private java.lang.Object source_;

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public boolean hasSource()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public java.lang.String getSource()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					source_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSourceBytes()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				source_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int BATCH_SIZE_FIELD_NUMBER = 4;
		private int batchSize_;

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public boolean hasBatchSize()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public int getBatchSize()
		{
			return batchSize_;
		}

		public static final int RAND_SKIP_FIELD_NUMBER = 7;
		private int randSkip_;

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		@Override
		public boolean hasRandSkip()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		@Override
		public int getRandSkip()
		{
			return randSkip_;
		}

		public static final int SHUFFLE_FIELD_NUMBER = 8;
		private boolean shuffle_;

		/**
		 * <code>optional bool shuffle = 8 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * </pre>
		 */
		@Override
		public boolean hasShuffle()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional bool shuffle = 8 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * </pre>
		 */
		@Override
		public boolean getShuffle()
		{
			return shuffle_;
		}

		public static final int NEW_HEIGHT_FIELD_NUMBER = 9;
		private int newHeight_;

		/**
		 * <code>optional uint32 new_height = 9 [default = 0];</code>
		 *
		 * <pre>
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		@Override
		public boolean hasNewHeight()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional uint32 new_height = 9 [default = 0];</code>
		 *
		 * <pre>
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		@Override
		public int getNewHeight()
		{
			return newHeight_;
		}

		public static final int NEW_WIDTH_FIELD_NUMBER = 10;
		private int newWidth_;

		/**
		 * <code>optional uint32 new_width = 10 [default = 0];</code>
		 */
		@Override
		public boolean hasNewWidth()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional uint32 new_width = 10 [default = 0];</code>
		 */
		@Override
		public int getNewWidth()
		{
			return newWidth_;
		}

		public static final int SCALE_FIELD_NUMBER = 2;
		private float scale_;

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		@Override
		public boolean hasScale()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
		 * simple scaling and subtracting the data mean, if provided. Note that the
		 * mean subtraction is always carried out before scaling.
		 * </pre>
		 */
		@Override
		public float getScale()
		{
			return scale_;
		}

		public static final int MEAN_FILE_FIELD_NUMBER = 3;
		private java.lang.Object meanFile_;

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public boolean hasMeanFile()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public java.lang.String getMeanFile()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					meanFile_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getMeanFileBytes()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				meanFile_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int CROP_SIZE_FIELD_NUMBER = 5;
		private int cropSize_;

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		@Override
		public boolean hasCropSize()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
		 * crop an image.
		 * </pre>
		 */
		@Override
		public int getCropSize()
		{
			return cropSize_;
		}

		public static final int MIRROR_FIELD_NUMBER = 6;
		private boolean mirror_;

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		@Override
		public boolean hasMirror()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
		 * data.
		 * </pre>
		 */
		@Override
		public boolean getMirror()
		{
			return mirror_;
		}

		private void initFields()
		{
			source_ = "";
			batchSize_ = 0;
			randSkip_ = 0;
			shuffle_ = false;
			newHeight_ = 0;
			newWidth_ = 0;
			scale_ = 1F;
			meanFile_ = "";
			cropSize_ = 0;
			mirror_ = false;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeFloat(2, scale_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeBytes(3, getMeanFileBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeUInt32(4, batchSize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeUInt32(5, cropSize_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeBool(6, mirror_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(7, randSkip_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeBool(8, shuffle_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeUInt32(9, newHeight_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeUInt32(10, newWidth_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(2, scale_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(3, getMeanFileBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(4, batchSize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(5, cropSize_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(6, mirror_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(7, randSkip_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(8, shuffle_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(9, newHeight_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(10, newWidth_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ImageDataParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ImageDataLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ImageDataParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ImageDataParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ImageDataParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				source_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				batchSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				randSkip_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				shuffle_ = false;
				bitField0_ = (bitField0_ & ~0x00000008);
				newHeight_ = 0;
				bitField0_ = (bitField0_ & ~0x00000010);
				newWidth_ = 0;
				bitField0_ = (bitField0_ & ~0x00000020);
				scale_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000040);
				meanFile_ = "";
				bitField0_ = (bitField0_ & ~0x00000080);
				cropSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000100);
				mirror_ = false;
				bitField0_ = (bitField0_ & ~0x00000200);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ImageDataParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.source_ = source_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.batchSize_ = batchSize_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.randSkip_ = randSkip_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.shuffle_ = shuffle_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.newHeight_ = newHeight_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.newWidth_ = newWidth_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.scale_ = scale_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.meanFile_ = meanFile_;
				if (((from_bitField0_ & 0x00000100) == 0x00000100))
				{
					to_bitField0_ |= 0x00000100;
				}
				result.cropSize_ = cropSize_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200))
				{
					to_bitField0_ |= 0x00000200;
				}
				result.mirror_ = mirror_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter.getDefaultInstance())
					return this;
				if (other.hasSource())
				{
					bitField0_ |= 0x00000001;
					source_ = other.source_;
					onChanged();
				}
				if (other.hasBatchSize())
				{
					setBatchSize(other.getBatchSize());
				}
				if (other.hasRandSkip())
				{
					setRandSkip(other.getRandSkip());
				}
				if (other.hasShuffle())
				{
					setShuffle(other.getShuffle());
				}
				if (other.hasNewHeight())
				{
					setNewHeight(other.getNewHeight());
				}
				if (other.hasNewWidth())
				{
					setNewWidth(other.getNewWidth());
				}
				if (other.hasScale())
				{
					setScale(other.getScale());
				}
				if (other.hasMeanFile())
				{
					bitField0_ |= 0x00000080;
					meanFile_ = other.meanFile_;
					onChanged();
				}
				if (other.hasCropSize())
				{
					setCropSize(other.getCropSize());
				}
				if (other.hasMirror())
				{
					setMirror(other.getMirror());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ImageDataParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object source_ = "";

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public boolean hasSource()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public java.lang.String getSource()
			{
				java.lang.Object ref = source_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						source_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSourceBytes()
			{
				java.lang.Object ref = source_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					source_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSource(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder clearSource()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				source_ = getDefaultInstance().getSource();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSourceBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			private int batchSize_;

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public boolean hasBatchSize()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public int getBatchSize()
			{
				return batchSize_;
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder setBatchSize(int value)
			{
				bitField0_ |= 0x00000002;
				batchSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder clearBatchSize()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				batchSize_ = 0;
				onChanged();
				return this;
			}

			private int randSkip_;

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			@Override
			public boolean hasRandSkip()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			@Override
			public int getRandSkip()
			{
				return randSkip_;
			}

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			public Builder setRandSkip(int value)
			{
				bitField0_ |= 0x00000004;
				randSkip_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 rand_skip = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			public Builder clearRandSkip()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				randSkip_ = 0;
				onChanged();
				return this;
			}

			private boolean shuffle_;

			/**
			 * <code>optional bool shuffle = 8 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * </pre>
			 */
			@Override
			public boolean hasShuffle()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional bool shuffle = 8 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * </pre>
			 */
			@Override
			public boolean getShuffle()
			{
				return shuffle_;
			}

			/**
			 * <code>optional bool shuffle = 8 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * </pre>
			 */
			public Builder setShuffle(boolean value)
			{
				bitField0_ |= 0x00000008;
				shuffle_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool shuffle = 8 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * </pre>
			 */
			public Builder clearShuffle()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				shuffle_ = false;
				onChanged();
				return this;
			}

			private int newHeight_;

			/**
			 * <code>optional uint32 new_height = 9 [default = 0];</code>
			 *
			 * <pre>
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			@Override
			public boolean hasNewHeight()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional uint32 new_height = 9 [default = 0];</code>
			 *
			 * <pre>
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			@Override
			public int getNewHeight()
			{
				return newHeight_;
			}

			/**
			 * <code>optional uint32 new_height = 9 [default = 0];</code>
			 *
			 * <pre>
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			public Builder setNewHeight(int value)
			{
				bitField0_ |= 0x00000010;
				newHeight_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 new_height = 9 [default = 0];</code>
			 *
			 * <pre>
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			public Builder clearNewHeight()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				newHeight_ = 0;
				onChanged();
				return this;
			}

			private int newWidth_;

			/**
			 * <code>optional uint32 new_width = 10 [default = 0];</code>
			 */
			@Override
			public boolean hasNewWidth()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional uint32 new_width = 10 [default = 0];</code>
			 */
			@Override
			public int getNewWidth()
			{
				return newWidth_;
			}

			/**
			 * <code>optional uint32 new_width = 10 [default = 0];</code>
			 */
			public Builder setNewWidth(int value)
			{
				bitField0_ |= 0x00000020;
				newWidth_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 new_width = 10 [default = 0];</code>
			 */
			public Builder clearNewWidth()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				newWidth_ = 0;
				onChanged();
				return this;
			}

			private float scale_ = 1F;

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			@Override
			public boolean hasScale()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			@Override
			public float getScale()
			{
				return scale_;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			public Builder setScale(float value)
			{
				bitField0_ |= 0x00000040;
				scale_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. For data pre-processing, we can do
			 * simple scaling and subtracting the data mean, if provided. Note that the
			 * mean subtraction is always carried out before scaling.
			 * </pre>
			 */
			public Builder clearScale()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				scale_ = 1F;
				onChanged();
				return this;
			}

			private java.lang.Object meanFile_ = "";

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public boolean hasMeanFile()
			{
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public java.lang.String getMeanFile()
			{
				java.lang.Object ref = meanFile_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						meanFile_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getMeanFileBytes()
			{
				java.lang.Object ref = meanFile_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					meanFile_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder setMeanFile(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000080;
				meanFile_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder clearMeanFile()
			{
				bitField0_ = (bitField0_ & ~0x00000080);
				meanFile_ = getDefaultInstance().getMeanFile();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder setMeanFileBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000080;
				meanFile_ = value;
				onChanged();
				return this;
			}

			private int cropSize_;

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			@Override
			public boolean hasCropSize()
			{
				return ((bitField0_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			@Override
			public int getCropSize()
			{
				return cropSize_;
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			public Builder setCropSize(int value)
			{
				bitField0_ |= 0x00000100;
				cropSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we would like to randomly
			 * crop an image.
			 * </pre>
			 */
			public Builder clearCropSize()
			{
				bitField0_ = (bitField0_ & ~0x00000100);
				cropSize_ = 0;
				onChanged();
				return this;
			}

			private boolean mirror_;

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			@Override
			public boolean hasMirror()
			{
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			@Override
			public boolean getMirror()
			{
				return mirror_;
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			public Builder setMirror(boolean value)
			{
				bitField0_ |= 0x00000200;
				mirror_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
			 * data.
			 * </pre>
			 */
			public Builder clearMirror()
			{
				bitField0_ = (bitField0_ & ~0x00000200);
				mirror_ = false;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ImageDataParameter)
		}

		static
		{
			defaultInstance = new ImageDataParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)
	}

	public interface InfogainLossParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.InfogainLossParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the infogain matrix source.
		 * </pre>
		 */
		boolean hasSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the infogain matrix source.
		 * </pre>
		 */
		java.lang.String getSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the infogain matrix source.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSourceBytes();
	}

	/**
	 * Protobuf type {@code caffe.InfogainLossParameter}
	 *
	 * <pre>
	 * Message that stores parameters InfogainLossLayer
	 * </pre>
	 */
	public static final class InfogainLossParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.InfogainLossParameter)
			InfogainLossParameterOrBuilder
	{
		// Use InfogainLossParameter.newBuilder() to construct.
		private InfogainLossParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private InfogainLossParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final InfogainLossParameter defaultInstance;

		public static InfogainLossParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public InfogainLossParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private InfogainLossParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						source_ = bs;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InfogainLossParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InfogainLossParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<InfogainLossParameter> PARSER =
				new com.google.protobuf.AbstractParser<InfogainLossParameter>()
				{
					@Override
					public InfogainLossParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new InfogainLossParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<InfogainLossParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int SOURCE_FIELD_NUMBER = 1;
		private java.lang.Object source_;

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the infogain matrix source.
		 * </pre>
		 */
		@Override
		public boolean hasSource()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the infogain matrix source.
		 * </pre>
		 */
		@Override
		public java.lang.String getSource()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					source_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the infogain matrix source.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSourceBytes()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				source_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		private void initFields()
		{
			source_ = "";
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getSourceBytes());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getSourceBytes());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.InfogainLossParameter}
		 *
		 * <pre>
		 * Message that stores parameters InfogainLossLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.InfogainLossParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InfogainLossParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InfogainLossParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				source_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InfogainLossParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.source_ = source_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter.getDefaultInstance())
					return this;
				if (other.hasSource())
				{
					bitField0_ |= 0x00000001;
					source_ = other.source_;
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InfogainLossParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object source_ = "";

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the infogain matrix source.
			 * </pre>
			 */
			@Override
			public boolean hasSource()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the infogain matrix source.
			 * </pre>
			 */
			@Override
			public java.lang.String getSource()
			{
				java.lang.Object ref = source_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						source_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the infogain matrix source.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSourceBytes()
			{
				java.lang.Object ref = source_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					source_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the infogain matrix source.
			 * </pre>
			 */
			public Builder setSource(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the infogain matrix source.
			 * </pre>
			 */
			public Builder clearSource()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				source_ = getDefaultInstance().getSource();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the infogain matrix source.
			 * </pre>
			 */
			public Builder setSourceBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.InfogainLossParameter)
		}

		static
		{
			defaultInstance = new InfogainLossParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)
	}

	public interface InnerProductParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.InnerProductParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		boolean hasNumOutput();

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		int getNumOutput();

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		boolean hasBiasTerm();

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		boolean getBiasTerm();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		boolean hasWeightFiller();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		boolean hasBiasFiller();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder();
	}

	/**
	 * Protobuf type {@code caffe.InnerProductParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by InnerProductLayer
	 * </pre>
	 */
	public static final class InnerProductParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.InnerProductParameter)
			InnerProductParameterOrBuilder
	{
		// Use InnerProductParameter.newBuilder() to construct.
		private InnerProductParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private InnerProductParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final InnerProductParameter defaultInstance;

		public static InnerProductParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public InnerProductParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private InnerProductParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						numOutput_ = input.readUInt32();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						biasTerm_ = input.readBool();
						break;
					}
					case 26:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000004) == 0x00000004))
						{
							subBuilder = weightFiller_.toBuilder();
						}
						weightFiller_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(weightFiller_);
							weightFiller_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000004;
						break;
					}
					case 34:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000008) == 0x00000008))
						{
							subBuilder = biasFiller_.toBuilder();
						}
						biasFiller_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(biasFiller_);
							biasFiller_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000008;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InnerProductParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InnerProductParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<InnerProductParameter> PARSER =
				new com.google.protobuf.AbstractParser<InnerProductParameter>()
				{
					@Override
					public InnerProductParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new InnerProductParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<InnerProductParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int NUM_OUTPUT_FIELD_NUMBER = 1;
		private int numOutput_;

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		@Override
		public boolean hasNumOutput()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 num_output = 1;</code>
		 *
		 * <pre>
		 * The number of outputs for the layer
		 * </pre>
		 */
		@Override
		public int getNumOutput()
		{
			return numOutput_;
		}

		public static final int BIAS_TERM_FIELD_NUMBER = 2;
		private boolean biasTerm_;

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		@Override
		public boolean hasBiasTerm()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bool bias_term = 2 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		@Override
		public boolean getBiasTerm()
		{
			return biasTerm_;
		}

		public static final int WEIGHT_FILLER_FIELD_NUMBER = 3;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter weightFiller_;

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public boolean hasWeightFiller()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller()
		{
			return weightFiller_;
		}

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder()
		{
			return weightFiller_;
		}

		public static final int BIAS_FILLER_FIELD_NUMBER = 4;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter biasFiller_;

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public boolean hasBiasFiller()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller()
		{
			return biasFiller_;
		}

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder()
		{
			return biasFiller_;
		}

		private void initFields()
		{
			numOutput_ = 0;
			biasTerm_ = true;
			weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
			biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, numOutput_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBool(2, biasTerm_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeMessage(3, weightFiller_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeMessage(4, biasFiller_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, numOutput_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(2, biasTerm_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(3, weightFiller_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(4, biasFiller_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.InnerProductParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by InnerProductLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.InnerProductParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InnerProductParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InnerProductParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getWeightFillerFieldBuilder();
					getBiasFillerFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				numOutput_ = 0;
				bitField0_ = (bitField0_ & ~0x00000001);
				biasTerm_ = true;
				bitField0_ = (bitField0_ & ~0x00000002);
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
				} else
				{
					weightFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000004);
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
				} else
				{
					biasFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000008);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_InnerProductParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.numOutput_ = numOutput_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.biasTerm_ = biasTerm_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				if (weightFillerBuilder_ == null)
				{
					result.weightFiller_ = weightFiller_;
				} else
				{
					result.weightFiller_ = weightFillerBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				if (biasFillerBuilder_ == null)
				{
					result.biasFiller_ = biasFiller_;
				} else
				{
					result.biasFiller_ = biasFillerBuilder_.build();
				}
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter.getDefaultInstance())
					return this;
				if (other.hasNumOutput())
				{
					setNumOutput(other.getNumOutput());
				}
				if (other.hasBiasTerm())
				{
					setBiasTerm(other.getBiasTerm());
				}
				if (other.hasWeightFiller())
				{
					mergeWeightFiller(other.getWeightFiller());
				}
				if (other.hasBiasFiller())
				{
					mergeBiasFiller(other.getBiasFiller());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.InnerProductParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int numOutput_;

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			@Override
			public boolean hasNumOutput()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			@Override
			public int getNumOutput()
			{
				return numOutput_;
			}

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			public Builder setNumOutput(int value)
			{
				bitField0_ |= 0x00000001;
				numOutput_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 num_output = 1;</code>
			 *
			 * <pre>
			 * The number of outputs for the layer
			 * </pre>
			 */
			public Builder clearNumOutput()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				numOutput_ = 0;
				onChanged();
				return this;
			}

			private boolean biasTerm_ = true;

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			@Override
			public boolean hasBiasTerm()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			@Override
			public boolean getBiasTerm()
			{
				return biasTerm_;
			}

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			public Builder setBiasTerm(boolean value)
			{
				bitField0_ |= 0x00000002;
				biasTerm_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool bias_term = 2 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			public Builder clearBiasTerm()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				biasTerm_ = true;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> weightFillerBuilder_;

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public boolean hasWeightFiller()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller()
			{
				if (weightFillerBuilder_ == null)
				{
					return weightFiller_;
				} else
				{
					return weightFillerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder setWeightFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (weightFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					weightFiller_ = value;
					onChanged();
				} else
				{
					weightFillerBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000004;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder setWeightFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = builderForValue.build();
					onChanged();
				} else
				{
					weightFillerBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000004;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder mergeWeightFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (weightFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00000004) == 0x00000004) &&
							weightFiller_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					{
						weightFiller_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder(weightFiller_).mergeFrom(value).buildPartial();
					} else
					{
						weightFiller_ = value;
					}
					onChanged();
				} else
				{
					weightFillerBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000004;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder clearWeightFiller()
			{
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					weightFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000004);
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getWeightFillerBuilder()
			{
				bitField0_ |= 0x00000004;
				onChanged();
				return getWeightFillerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder()
			{
				if (weightFillerBuilder_ != null)
				{
					return weightFillerBuilder_.getMessageOrBuilder();
				} else
				{
					return weightFiller_;
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 3;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getWeightFillerFieldBuilder()
			{
				if (weightFillerBuilder_ == null)
				{
					weightFillerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									getWeightFiller(),
									getParentForChildren(),
									isClean());
					weightFiller_ = null;
				}
				return weightFillerBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> biasFillerBuilder_;

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public boolean hasBiasFiller()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller()
			{
				if (biasFillerBuilder_ == null)
				{
					return biasFiller_;
				} else
				{
					return biasFillerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder setBiasFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (biasFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					biasFiller_ = value;
					onChanged();
				} else
				{
					biasFillerBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000008;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder setBiasFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = builderForValue.build();
					onChanged();
				} else
				{
					biasFillerBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000008;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder mergeBiasFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (biasFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00000008) == 0x00000008) &&
							biasFiller_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					{
						biasFiller_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder(biasFiller_).mergeFrom(value).buildPartial();
					} else
					{
						biasFiller_ = value;
					}
					onChanged();
				} else
				{
					biasFillerBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000008;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder clearBiasFiller()
			{
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					biasFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000008);
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getBiasFillerBuilder()
			{
				bitField0_ |= 0x00000008;
				onChanged();
				return getBiasFillerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder()
			{
				if (biasFillerBuilder_ != null)
				{
					return biasFillerBuilder_.getMessageOrBuilder();
				} else
				{
					return biasFiller_;
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 4;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getBiasFillerFieldBuilder()
			{
				if (biasFillerBuilder_ == null)
				{
					biasFillerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									getBiasFiller(),
									getParentForChildren(),
									isClean());
					biasFiller_ = null;
				}
				return biasFillerBuilder_;
			}

			// @@protoc_insertion_point(builder_scope:caffe.InnerProductParameter)
		}

		static
		{
			defaultInstance = new InnerProductParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)
	}

	public interface LRNParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.LRNParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 local_size = 1 [default = 5];</code>
		 */
		boolean hasLocalSize();

		/**
		 * <code>optional uint32 local_size = 1 [default = 5];</code>
		 */
		int getLocalSize();

		/**
		 * <code>optional float alpha = 2 [default = 1];</code>
		 */
		boolean hasAlpha();

		/**
		 * <code>optional float alpha = 2 [default = 1];</code>
		 */
		float getAlpha();

		/**
		 * <code>optional float beta = 3 [default = 0.75];</code>
		 */
		boolean hasBeta();

		/**
		 * <code>optional float beta = 3 [default = 0.75];</code>
		 */
		float getBeta();

		/**
		 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
		 */
		boolean hasNormRegion();

		/**
		 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion getNormRegion();
	}

	/**
	 * Protobuf type {@code caffe.LRNParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by LRNLayer
	 * </pre>
	 */
	public static final class LRNParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.LRNParameter)
			LRNParameterOrBuilder
	{
		// Use LRNParameter.newBuilder() to construct.
		private LRNParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private LRNParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final LRNParameter defaultInstance;

		public static LRNParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public LRNParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private LRNParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						localSize_ = input.readUInt32();
						break;
					}
					case 21:
					{
						bitField0_ |= 0x00000002;
						alpha_ = input.readFloat();
						break;
					}
					case 29:
					{
						bitField0_ |= 0x00000004;
						beta_ = input.readFloat();
						break;
					}
					case 32:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(4, rawValue);
						} else
						{
							bitField0_ |= 0x00000008;
							normRegion_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LRNParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LRNParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<LRNParameter> PARSER =
				new com.google.protobuf.AbstractParser<LRNParameter>()
				{
					@Override
					public LRNParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new LRNParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<LRNParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.LRNParameter.NormRegion}
		 */
		public enum NormRegion
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>ACROSS_CHANNELS = 0;</code>
			 */
			ACROSS_CHANNELS(0, 0),
			/**
			 * <code>WITHIN_CHANNEL = 1;</code>
			 */
			WITHIN_CHANNEL(1, 1), ;

			/**
			 * <code>ACROSS_CHANNELS = 0;</code>
			 */
			public static final int ACROSS_CHANNELS_VALUE = 0;
			/**
			 * <code>WITHIN_CHANNEL = 1;</code>
			 */
			public static final int WITHIN_CHANNEL_VALUE = 1;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static NormRegion valueOf(int value)
			{
				switch (value) {
				case 0:
					return ACROSS_CHANNELS;
				case 1:
					return WITHIN_CHANNEL;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<NormRegion>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<NormRegion> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<NormRegion>()
					{
						@Override
						public NormRegion findValueByNumber(int number)
						{
							return NormRegion.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final NormRegion[] VALUES = values();

			public static NormRegion valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private NormRegion(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.LRNParameter.NormRegion)
		}

		private int bitField0_;
		public static final int LOCAL_SIZE_FIELD_NUMBER = 1;
		private int localSize_;

		/**
		 * <code>optional uint32 local_size = 1 [default = 5];</code>
		 */
		@Override
		public boolean hasLocalSize()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 local_size = 1 [default = 5];</code>
		 */
		@Override
		public int getLocalSize()
		{
			return localSize_;
		}

		public static final int ALPHA_FIELD_NUMBER = 2;
		private float alpha_;

		/**
		 * <code>optional float alpha = 2 [default = 1];</code>
		 */
		@Override
		public boolean hasAlpha()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional float alpha = 2 [default = 1];</code>
		 */
		@Override
		public float getAlpha()
		{
			return alpha_;
		}

		public static final int BETA_FIELD_NUMBER = 3;
		private float beta_;

		/**
		 * <code>optional float beta = 3 [default = 0.75];</code>
		 */
		@Override
		public boolean hasBeta()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional float beta = 3 [default = 0.75];</code>
		 */
		@Override
		public float getBeta()
		{
			return beta_;
		}

		public static final int NORM_REGION_FIELD_NUMBER = 4;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion normRegion_;

		/**
		 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
		 */
		@Override
		public boolean hasNormRegion()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion getNormRegion()
		{
			return normRegion_;
		}

		private void initFields()
		{
			localSize_ = 5;
			alpha_ = 1F;
			beta_ = 0.75F;
			normRegion_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion.ACROSS_CHANNELS;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, localSize_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeFloat(2, alpha_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeFloat(3, beta_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeEnum(4, normRegion_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, localSize_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(2, alpha_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(3, beta_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(4, normRegion_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.LRNParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by LRNLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.LRNParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LRNParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LRNParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				localSize_ = 5;
				bitField0_ = (bitField0_ & ~0x00000001);
				alpha_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000002);
				beta_ = 0.75F;
				bitField0_ = (bitField0_ & ~0x00000004);
				normRegion_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion.ACROSS_CHANNELS;
				bitField0_ = (bitField0_ & ~0x00000008);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_LRNParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.localSize_ = localSize_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.alpha_ = alpha_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.beta_ = beta_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.normRegion_ = normRegion_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.getDefaultInstance())
					return this;
				if (other.hasLocalSize())
				{
					setLocalSize(other.getLocalSize());
				}
				if (other.hasAlpha())
				{
					setAlpha(other.getAlpha());
				}
				if (other.hasBeta())
				{
					setBeta(other.getBeta());
				}
				if (other.hasNormRegion())
				{
					setNormRegion(other.getNormRegion());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int localSize_ = 5;

			/**
			 * <code>optional uint32 local_size = 1 [default = 5];</code>
			 */
			@Override
			public boolean hasLocalSize()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 local_size = 1 [default = 5];</code>
			 */
			@Override
			public int getLocalSize()
			{
				return localSize_;
			}

			/**
			 * <code>optional uint32 local_size = 1 [default = 5];</code>
			 */
			public Builder setLocalSize(int value)
			{
				bitField0_ |= 0x00000001;
				localSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 local_size = 1 [default = 5];</code>
			 */
			public Builder clearLocalSize()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				localSize_ = 5;
				onChanged();
				return this;
			}

			private float alpha_ = 1F;

			/**
			 * <code>optional float alpha = 2 [default = 1];</code>
			 */
			@Override
			public boolean hasAlpha()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional float alpha = 2 [default = 1];</code>
			 */
			@Override
			public float getAlpha()
			{
				return alpha_;
			}

			/**
			 * <code>optional float alpha = 2 [default = 1];</code>
			 */
			public Builder setAlpha(float value)
			{
				bitField0_ |= 0x00000002;
				alpha_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float alpha = 2 [default = 1];</code>
			 */
			public Builder clearAlpha()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				alpha_ = 1F;
				onChanged();
				return this;
			}

			private float beta_ = 0.75F;

			/**
			 * <code>optional float beta = 3 [default = 0.75];</code>
			 */
			@Override
			public boolean hasBeta()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional float beta = 3 [default = 0.75];</code>
			 */
			@Override
			public float getBeta()
			{
				return beta_;
			}

			/**
			 * <code>optional float beta = 3 [default = 0.75];</code>
			 */
			public Builder setBeta(float value)
			{
				bitField0_ |= 0x00000004;
				beta_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float beta = 3 [default = 0.75];</code>
			 */
			public Builder clearBeta()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				beta_ = 0.75F;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion normRegion_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion.ACROSS_CHANNELS;

			/**
			 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
			 */
			@Override
			public boolean hasNormRegion()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion getNormRegion()
			{
				return normRegion_;
			}

			/**
			 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
			 */
			public Builder setNormRegion(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000008;
				normRegion_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.LRNParameter.NormRegion norm_region = 4 [default = ACROSS_CHANNELS];</code>
			 */
			public Builder clearNormRegion()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				normRegion_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.LRNParameter.NormRegion.ACROSS_CHANNELS;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.LRNParameter)
		}

		static
		{
			defaultInstance = new LRNParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.LRNParameter)
	}

	public interface MemoryDataParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.MemoryDataParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 batch_size = 1;</code>
		 */
		boolean hasBatchSize();

		/**
		 * <code>optional uint32 batch_size = 1;</code>
		 */
		int getBatchSize();

		/**
		 * <code>optional uint32 channels = 2;</code>
		 */
		boolean hasChannels();

		/**
		 * <code>optional uint32 channels = 2;</code>
		 */
		int getChannels();

		/**
		 * <code>optional uint32 height = 3;</code>
		 */
		boolean hasHeight();

		/**
		 * <code>optional uint32 height = 3;</code>
		 */
		int getHeight();

		/**
		 * <code>optional uint32 width = 4;</code>
		 */
		boolean hasWidth();

		/**
		 * <code>optional uint32 width = 4;</code>
		 */
		int getWidth();
	}

	/**
	 * Protobuf type {@code caffe.MemoryDataParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by MemoryDataLayer
	 * </pre>
	 */
	public static final class MemoryDataParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.MemoryDataParameter)
			MemoryDataParameterOrBuilder
	{
		// Use MemoryDataParameter.newBuilder() to construct.
		private MemoryDataParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private MemoryDataParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final MemoryDataParameter defaultInstance;

		public static MemoryDataParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public MemoryDataParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private MemoryDataParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						batchSize_ = input.readUInt32();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						channels_ = input.readUInt32();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						height_ = input.readUInt32();
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000008;
						width_ = input.readUInt32();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MemoryDataParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MemoryDataParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<MemoryDataParameter> PARSER =
				new com.google.protobuf.AbstractParser<MemoryDataParameter>()
				{
					@Override
					public MemoryDataParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new MemoryDataParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<MemoryDataParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int BATCH_SIZE_FIELD_NUMBER = 1;
		private int batchSize_;

		/**
		 * <code>optional uint32 batch_size = 1;</code>
		 */
		@Override
		public boolean hasBatchSize()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 batch_size = 1;</code>
		 */
		@Override
		public int getBatchSize()
		{
			return batchSize_;
		}

		public static final int CHANNELS_FIELD_NUMBER = 2;
		private int channels_;

		/**
		 * <code>optional uint32 channels = 2;</code>
		 */
		@Override
		public boolean hasChannels()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint32 channels = 2;</code>
		 */
		@Override
		public int getChannels()
		{
			return channels_;
		}

		public static final int HEIGHT_FIELD_NUMBER = 3;
		private int height_;

		/**
		 * <code>optional uint32 height = 3;</code>
		 */
		@Override
		public boolean hasHeight()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 height = 3;</code>
		 */
		@Override
		public int getHeight()
		{
			return height_;
		}

		public static final int WIDTH_FIELD_NUMBER = 4;
		private int width_;

		/**
		 * <code>optional uint32 width = 4;</code>
		 */
		@Override
		public boolean hasWidth()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional uint32 width = 4;</code>
		 */
		@Override
		public int getWidth()
		{
			return width_;
		}

		private void initFields()
		{
			batchSize_ = 0;
			channels_ = 0;
			height_ = 0;
			width_ = 0;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, batchSize_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeUInt32(2, channels_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(3, height_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeUInt32(4, width_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, batchSize_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(2, channels_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(3, height_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(4, width_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.MemoryDataParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by MemoryDataLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.MemoryDataParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MemoryDataParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MemoryDataParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				batchSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000001);
				channels_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				height_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				width_ = 0;
				bitField0_ = (bitField0_ & ~0x00000008);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MemoryDataParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.batchSize_ = batchSize_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.channels_ = channels_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.height_ = height_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.width_ = width_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter.getDefaultInstance())
					return this;
				if (other.hasBatchSize())
				{
					setBatchSize(other.getBatchSize());
				}
				if (other.hasChannels())
				{
					setChannels(other.getChannels());
				}
				if (other.hasHeight())
				{
					setHeight(other.getHeight());
				}
				if (other.hasWidth())
				{
					setWidth(other.getWidth());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MemoryDataParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int batchSize_;

			/**
			 * <code>optional uint32 batch_size = 1;</code>
			 */
			@Override
			public boolean hasBatchSize()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 batch_size = 1;</code>
			 */
			@Override
			public int getBatchSize()
			{
				return batchSize_;
			}

			/**
			 * <code>optional uint32 batch_size = 1;</code>
			 */
			public Builder setBatchSize(int value)
			{
				bitField0_ |= 0x00000001;
				batchSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 batch_size = 1;</code>
			 */
			public Builder clearBatchSize()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				batchSize_ = 0;
				onChanged();
				return this;
			}

			private int channels_;

			/**
			 * <code>optional uint32 channels = 2;</code>
			 */
			@Override
			public boolean hasChannels()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint32 channels = 2;</code>
			 */
			@Override
			public int getChannels()
			{
				return channels_;
			}

			/**
			 * <code>optional uint32 channels = 2;</code>
			 */
			public Builder setChannels(int value)
			{
				bitField0_ |= 0x00000002;
				channels_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 channels = 2;</code>
			 */
			public Builder clearChannels()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				channels_ = 0;
				onChanged();
				return this;
			}

			private int height_;

			/**
			 * <code>optional uint32 height = 3;</code>
			 */
			@Override
			public boolean hasHeight()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 height = 3;</code>
			 */
			@Override
			public int getHeight()
			{
				return height_;
			}

			/**
			 * <code>optional uint32 height = 3;</code>
			 */
			public Builder setHeight(int value)
			{
				bitField0_ |= 0x00000004;
				height_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 height = 3;</code>
			 */
			public Builder clearHeight()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				height_ = 0;
				onChanged();
				return this;
			}

			private int width_;

			/**
			 * <code>optional uint32 width = 4;</code>
			 */
			@Override
			public boolean hasWidth()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional uint32 width = 4;</code>
			 */
			@Override
			public int getWidth()
			{
				return width_;
			}

			/**
			 * <code>optional uint32 width = 4;</code>
			 */
			public Builder setWidth(int value)
			{
				bitField0_ |= 0x00000008;
				width_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 width = 4;</code>
			 */
			public Builder clearWidth()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				width_ = 0;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.MemoryDataParameter)
		}

		static
		{
			defaultInstance = new MemoryDataParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)
	}

	public interface MVNParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.MVNParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional bool normalize_variance = 1 [default = true];</code>
		 *
		 * <pre>
		 * This parameter can be set to false to normalize mean only
		 * </pre>
		 */
		boolean hasNormalizeVariance();

		/**
		 * <code>optional bool normalize_variance = 1 [default = true];</code>
		 *
		 * <pre>
		 * This parameter can be set to false to normalize mean only
		 * </pre>
		 */
		boolean getNormalizeVariance();

		/**
		 * <code>optional bool across_channels = 2 [default = false];</code>
		 *
		 * <pre>
		 * This parameter can be set to true to perform DNN-like MVN
		 * </pre>
		 */
		boolean hasAcrossChannels();

		/**
		 * <code>optional bool across_channels = 2 [default = false];</code>
		 *
		 * <pre>
		 * This parameter can be set to true to perform DNN-like MVN
		 * </pre>
		 */
		boolean getAcrossChannels();
	}

	/**
	 * Protobuf type {@code caffe.MVNParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by MVNLayer
	 * </pre>
	 */
	public static final class MVNParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.MVNParameter)
			MVNParameterOrBuilder
	{
		// Use MVNParameter.newBuilder() to construct.
		private MVNParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private MVNParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final MVNParameter defaultInstance;

		public static MVNParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public MVNParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private MVNParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						normalizeVariance_ = input.readBool();
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000002;
						acrossChannels_ = input.readBool();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MVNParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MVNParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<MVNParameter> PARSER =
				new com.google.protobuf.AbstractParser<MVNParameter>()
				{
					@Override
					public MVNParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new MVNParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<MVNParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int NORMALIZE_VARIANCE_FIELD_NUMBER = 1;
		private boolean normalizeVariance_;

		/**
		 * <code>optional bool normalize_variance = 1 [default = true];</code>
		 *
		 * <pre>
		 * This parameter can be set to false to normalize mean only
		 * </pre>
		 */
		@Override
		public boolean hasNormalizeVariance()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional bool normalize_variance = 1 [default = true];</code>
		 *
		 * <pre>
		 * This parameter can be set to false to normalize mean only
		 * </pre>
		 */
		@Override
		public boolean getNormalizeVariance()
		{
			return normalizeVariance_;
		}

		public static final int ACROSS_CHANNELS_FIELD_NUMBER = 2;
		private boolean acrossChannels_;

		/**
		 * <code>optional bool across_channels = 2 [default = false];</code>
		 *
		 * <pre>
		 * This parameter can be set to true to perform DNN-like MVN
		 * </pre>
		 */
		@Override
		public boolean hasAcrossChannels()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bool across_channels = 2 [default = false];</code>
		 *
		 * <pre>
		 * This parameter can be set to true to perform DNN-like MVN
		 * </pre>
		 */
		@Override
		public boolean getAcrossChannels()
		{
			return acrossChannels_;
		}

		private void initFields()
		{
			normalizeVariance_ = true;
			acrossChannels_ = false;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBool(1, normalizeVariance_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBool(2, acrossChannels_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(1, normalizeVariance_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(2, acrossChannels_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.MVNParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by MVNLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.MVNParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MVNParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MVNParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				normalizeVariance_ = true;
				bitField0_ = (bitField0_ & ~0x00000001);
				acrossChannels_ = false;
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_MVNParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.normalizeVariance_ = normalizeVariance_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.acrossChannels_ = acrossChannels_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter.getDefaultInstance())
					return this;
				if (other.hasNormalizeVariance())
				{
					setNormalizeVariance(other.getNormalizeVariance());
				}
				if (other.hasAcrossChannels())
				{
					setAcrossChannels(other.getAcrossChannels());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.MVNParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private boolean normalizeVariance_ = true;

			/**
			 * <code>optional bool normalize_variance = 1 [default = true];</code>
			 *
			 * <pre>
			 * This parameter can be set to false to normalize mean only
			 * </pre>
			 */
			@Override
			public boolean hasNormalizeVariance()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional bool normalize_variance = 1 [default = true];</code>
			 *
			 * <pre>
			 * This parameter can be set to false to normalize mean only
			 * </pre>
			 */
			@Override
			public boolean getNormalizeVariance()
			{
				return normalizeVariance_;
			}

			/**
			 * <code>optional bool normalize_variance = 1 [default = true];</code>
			 *
			 * <pre>
			 * This parameter can be set to false to normalize mean only
			 * </pre>
			 */
			public Builder setNormalizeVariance(boolean value)
			{
				bitField0_ |= 0x00000001;
				normalizeVariance_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool normalize_variance = 1 [default = true];</code>
			 *
			 * <pre>
			 * This parameter can be set to false to normalize mean only
			 * </pre>
			 */
			public Builder clearNormalizeVariance()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				normalizeVariance_ = true;
				onChanged();
				return this;
			}

			private boolean acrossChannels_;

			/**
			 * <code>optional bool across_channels = 2 [default = false];</code>
			 *
			 * <pre>
			 * This parameter can be set to true to perform DNN-like MVN
			 * </pre>
			 */
			@Override
			public boolean hasAcrossChannels()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional bool across_channels = 2 [default = false];</code>
			 *
			 * <pre>
			 * This parameter can be set to true to perform DNN-like MVN
			 * </pre>
			 */
			@Override
			public boolean getAcrossChannels()
			{
				return acrossChannels_;
			}

			/**
			 * <code>optional bool across_channels = 2 [default = false];</code>
			 *
			 * <pre>
			 * This parameter can be set to true to perform DNN-like MVN
			 * </pre>
			 */
			public Builder setAcrossChannels(boolean value)
			{
				bitField0_ |= 0x00000002;
				acrossChannels_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool across_channels = 2 [default = false];</code>
			 *
			 * <pre>
			 * This parameter can be set to true to perform DNN-like MVN
			 * </pre>
			 */
			public Builder clearAcrossChannels()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				acrossChannels_ = false;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.MVNParameter)
		}

		static
		{
			defaultInstance = new MVNParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.MVNParameter)
	}

	public interface PoolingParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.PoolingParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		boolean hasPool();

		/**
		 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod getPool();

		/**
		 * <code>optional uint32 pad = 4 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		boolean hasPad();

		/**
		 * <code>optional uint32 pad = 4 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		int getPad();

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		boolean hasPadH();

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		int getPadH();

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		boolean hasPadW();

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		int getPadW();

		/**
		 * <code>optional uint32 kernel_size = 2;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		boolean hasKernelSize();

		/**
		 * <code>optional uint32 kernel_size = 2;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		int getKernelSize();

		/**
		 * <code>optional uint32 kernel_h = 5;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		boolean hasKernelH();

		/**
		 * <code>optional uint32 kernel_h = 5;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		int getKernelH();

		/**
		 * <code>optional uint32 kernel_w = 6;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		boolean hasKernelW();

		/**
		 * <code>optional uint32 kernel_w = 6;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		int getKernelW();

		/**
		 * <code>optional uint32 stride = 3 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		boolean hasStride();

		/**
		 * <code>optional uint32 stride = 3 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		int getStride();

		/**
		 * <code>optional uint32 stride_h = 7;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		boolean hasStrideH();

		/**
		 * <code>optional uint32 stride_h = 7;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		int getStrideH();

		/**
		 * <code>optional uint32 stride_w = 8;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		boolean hasStrideW();

		/**
		 * <code>optional uint32 stride_w = 8;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		int getStrideW();

		/**
		 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
		 */
		boolean hasEngine();

		/**
		 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine getEngine();
	}

	/**
	 * Protobuf type {@code caffe.PoolingParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by PoolingLayer
	 * </pre>
	 */
	public static final class PoolingParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.PoolingParameter)
			PoolingParameterOrBuilder
	{
		// Use PoolingParameter.newBuilder() to construct.
		private PoolingParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private PoolingParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final PoolingParameter defaultInstance;

		public static PoolingParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public PoolingParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private PoolingParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							pool_ = value;
						}
						break;
					}
					case 16:
					{
						bitField0_ |= 0x00000010;
						kernelSize_ = input.readUInt32();
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000080;
						stride_ = input.readUInt32();
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000002;
						pad_ = input.readUInt32();
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000020;
						kernelH_ = input.readUInt32();
						break;
					}
					case 48:
					{
						bitField0_ |= 0x00000040;
						kernelW_ = input.readUInt32();
						break;
					}
					case 56:
					{
						bitField0_ |= 0x00000100;
						strideH_ = input.readUInt32();
						break;
					}
					case 64:
					{
						bitField0_ |= 0x00000200;
						strideW_ = input.readUInt32();
						break;
					}
					case 72:
					{
						bitField0_ |= 0x00000004;
						padH_ = input.readUInt32();
						break;
					}
					case 80:
					{
						bitField0_ |= 0x00000008;
						padW_ = input.readUInt32();
						break;
					}
					case 88:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(11, rawValue);
						} else
						{
							bitField0_ |= 0x00000400;
							engine_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PoolingParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PoolingParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<PoolingParameter> PARSER =
				new com.google.protobuf.AbstractParser<PoolingParameter>()
				{
					@Override
					public PoolingParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new PoolingParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<PoolingParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.PoolingParameter.PoolMethod}
		 */
		public enum PoolMethod
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>MAX = 0;</code>
			 */
			MAX(0, 0),
			/**
			 * <code>AVE = 1;</code>
			 */
			AVE(1, 1),
			/**
			 * <code>STOCHASTIC = 2;</code>
			 */
			STOCHASTIC(2, 2), ;

			/**
			 * <code>MAX = 0;</code>
			 */
			public static final int MAX_VALUE = 0;
			/**
			 * <code>AVE = 1;</code>
			 */
			public static final int AVE_VALUE = 1;
			/**
			 * <code>STOCHASTIC = 2;</code>
			 */
			public static final int STOCHASTIC_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static PoolMethod valueOf(int value)
			{
				switch (value) {
				case 0:
					return MAX;
				case 1:
					return AVE;
				case 2:
					return STOCHASTIC;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<PoolMethod>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<PoolMethod> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<PoolMethod>()
					{
						@Override
						public PoolMethod findValueByNumber(int number)
						{
							return PoolMethod.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final PoolMethod[] VALUES = values();

			public static PoolMethod valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private PoolMethod(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.PoolingParameter.PoolMethod)
		}

		/**
		 * Protobuf enum {@code caffe.PoolingParameter.Engine}
		 */
		public enum Engine
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>DEFAULT = 0;</code>
			 */
			DEFAULT(0, 0),
			/**
			 * <code>CAFFE = 1;</code>
			 */
			CAFFE(1, 1),
			/**
			 * <code>CUDNN = 2;</code>
			 */
			CUDNN(2, 2), ;

			/**
			 * <code>DEFAULT = 0;</code>
			 */
			public static final int DEFAULT_VALUE = 0;
			/**
			 * <code>CAFFE = 1;</code>
			 */
			public static final int CAFFE_VALUE = 1;
			/**
			 * <code>CUDNN = 2;</code>
			 */
			public static final int CUDNN_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Engine valueOf(int value)
			{
				switch (value) {
				case 0:
					return DEFAULT;
				case 1:
					return CAFFE;
				case 2:
					return CUDNN;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Engine>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Engine> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Engine>()
					{
						@Override
						public Engine findValueByNumber(int number)
						{
							return Engine.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDescriptor().getEnumTypes().get(1);
			}

			private static final Engine[] VALUES = values();

			public static Engine valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Engine(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.PoolingParameter.Engine)
		}

		private int bitField0_;
		public static final int POOL_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod pool_;

		/**
		 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		@Override
		public boolean hasPool()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod getPool()
		{
			return pool_;
		}

		public static final int PAD_FIELD_NUMBER = 4;
		private int pad_;

		/**
		 * <code>optional uint32 pad = 4 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		@Override
		public boolean hasPad()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint32 pad = 4 [default = 0];</code>
		 *
		 * <pre>
		 * Pad, kernel size, and stride are all given as a single value for equal
		 * dimensions in height and width or as Y, X pairs.
		 * </pre>
		 */
		@Override
		public int getPad()
		{
			return pad_;
		}

		public static final int PAD_H_FIELD_NUMBER = 9;
		private int padH_;

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		@Override
		public boolean hasPadH()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 pad_h = 9 [default = 0];</code>
		 *
		 * <pre>
		 * The padding height
		 * </pre>
		 */
		@Override
		public int getPadH()
		{
			return padH_;
		}

		public static final int PAD_W_FIELD_NUMBER = 10;
		private int padW_;

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		@Override
		public boolean hasPadW()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional uint32 pad_w = 10 [default = 0];</code>
		 *
		 * <pre>
		 * The padding width
		 * </pre>
		 */
		@Override
		public int getPadW()
		{
			return padW_;
		}

		public static final int KERNEL_SIZE_FIELD_NUMBER = 2;
		private int kernelSize_;

		/**
		 * <code>optional uint32 kernel_size = 2;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		@Override
		public boolean hasKernelSize()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional uint32 kernel_size = 2;</code>
		 *
		 * <pre>
		 * The kernel size (square)
		 * </pre>
		 */
		@Override
		public int getKernelSize()
		{
			return kernelSize_;
		}

		public static final int KERNEL_H_FIELD_NUMBER = 5;
		private int kernelH_;

		/**
		 * <code>optional uint32 kernel_h = 5;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		@Override
		public boolean hasKernelH()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional uint32 kernel_h = 5;</code>
		 *
		 * <pre>
		 * The kernel height
		 * </pre>
		 */
		@Override
		public int getKernelH()
		{
			return kernelH_;
		}

		public static final int KERNEL_W_FIELD_NUMBER = 6;
		private int kernelW_;

		/**
		 * <code>optional uint32 kernel_w = 6;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		@Override
		public boolean hasKernelW()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional uint32 kernel_w = 6;</code>
		 *
		 * <pre>
		 * The kernel width
		 * </pre>
		 */
		@Override
		public int getKernelW()
		{
			return kernelW_;
		}

		public static final int STRIDE_FIELD_NUMBER = 3;
		private int stride_;

		/**
		 * <code>optional uint32 stride = 3 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		@Override
		public boolean hasStride()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional uint32 stride = 3 [default = 1];</code>
		 *
		 * <pre>
		 * The stride (equal in Y, X)
		 * </pre>
		 */
		@Override
		public int getStride()
		{
			return stride_;
		}

		public static final int STRIDE_H_FIELD_NUMBER = 7;
		private int strideH_;

		/**
		 * <code>optional uint32 stride_h = 7;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		@Override
		public boolean hasStrideH()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional uint32 stride_h = 7;</code>
		 *
		 * <pre>
		 * The stride height
		 * </pre>
		 */
		@Override
		public int getStrideH()
		{
			return strideH_;
		}

		public static final int STRIDE_W_FIELD_NUMBER = 8;
		private int strideW_;

		/**
		 * <code>optional uint32 stride_w = 8;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		@Override
		public boolean hasStrideW()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional uint32 stride_w = 8;</code>
		 *
		 * <pre>
		 * The stride width
		 * </pre>
		 */
		@Override
		public int getStrideW()
		{
			return strideW_;
		}

		public static final int ENGINE_FIELD_NUMBER = 11;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine engine_;

		/**
		 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
		 */
		@Override
		public boolean hasEngine()
		{
			return ((bitField0_ & 0x00000400) == 0x00000400);
		}

		/**
		 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine getEngine()
		{
			return engine_;
		}

		private void initFields()
		{
			pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod.MAX;
			pad_ = 0;
			padH_ = 0;
			padW_ = 0;
			kernelSize_ = 0;
			kernelH_ = 0;
			kernelW_ = 0;
			stride_ = 1;
			strideH_ = 0;
			strideW_ = 0;
			engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine.DEFAULT;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, pool_.getNumber());
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeUInt32(2, kernelSize_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeUInt32(3, stride_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeUInt32(4, pad_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeUInt32(5, kernelH_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeUInt32(6, kernelW_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeUInt32(7, strideH_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeUInt32(8, strideW_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(9, padH_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeUInt32(10, padW_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				output.writeEnum(11, engine_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, pool_.getNumber());
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(2, kernelSize_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(3, stride_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(4, pad_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(5, kernelH_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(6, kernelW_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(7, strideH_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(8, strideW_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(9, padH_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(10, padW_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(11, engine_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.PoolingParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by PoolingLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.PoolingParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PoolingParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PoolingParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod.MAX;
				bitField0_ = (bitField0_ & ~0x00000001);
				pad_ = 0;
				bitField0_ = (bitField0_ & ~0x00000002);
				padH_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				padW_ = 0;
				bitField0_ = (bitField0_ & ~0x00000008);
				kernelSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000010);
				kernelH_ = 0;
				bitField0_ = (bitField0_ & ~0x00000020);
				kernelW_ = 0;
				bitField0_ = (bitField0_ & ~0x00000040);
				stride_ = 1;
				bitField0_ = (bitField0_ & ~0x00000080);
				strideH_ = 0;
				bitField0_ = (bitField0_ & ~0x00000100);
				strideW_ = 0;
				bitField0_ = (bitField0_ & ~0x00000200);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine.DEFAULT;
				bitField0_ = (bitField0_ & ~0x00000400);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PoolingParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.pool_ = pool_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.pad_ = pad_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.padH_ = padH_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.padW_ = padW_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.kernelSize_ = kernelSize_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.kernelH_ = kernelH_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.kernelW_ = kernelW_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.stride_ = stride_;
				if (((from_bitField0_ & 0x00000100) == 0x00000100))
				{
					to_bitField0_ |= 0x00000100;
				}
				result.strideH_ = strideH_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200))
				{
					to_bitField0_ |= 0x00000200;
				}
				result.strideW_ = strideW_;
				if (((from_bitField0_ & 0x00000400) == 0x00000400))
				{
					to_bitField0_ |= 0x00000400;
				}
				result.engine_ = engine_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.getDefaultInstance())
					return this;
				if (other.hasPool())
				{
					setPool(other.getPool());
				}
				if (other.hasPad())
				{
					setPad(other.getPad());
				}
				if (other.hasPadH())
				{
					setPadH(other.getPadH());
				}
				if (other.hasPadW())
				{
					setPadW(other.getPadW());
				}
				if (other.hasKernelSize())
				{
					setKernelSize(other.getKernelSize());
				}
				if (other.hasKernelH())
				{
					setKernelH(other.getKernelH());
				}
				if (other.hasKernelW())
				{
					setKernelW(other.getKernelW());
				}
				if (other.hasStride())
				{
					setStride(other.getStride());
				}
				if (other.hasStrideH())
				{
					setStrideH(other.getStrideH());
				}
				if (other.hasStrideW())
				{
					setStrideW(other.getStrideW());
				}
				if (other.hasEngine())
				{
					setEngine(other.getEngine());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod.MAX;

			/**
			 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			@Override
			public boolean hasPool()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod getPool()
			{
				return pool_;
			}

			/**
			 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			public Builder setPool(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				pool_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.PoolingParameter.PoolMethod pool = 1 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			public Builder clearPool()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.PoolMethod.MAX;
				onChanged();
				return this;
			}

			private int pad_;

			/**
			 * <code>optional uint32 pad = 4 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			@Override
			public boolean hasPad()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint32 pad = 4 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			@Override
			public int getPad()
			{
				return pad_;
			}

			/**
			 * <code>optional uint32 pad = 4 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			public Builder setPad(int value)
			{
				bitField0_ |= 0x00000002;
				pad_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad = 4 [default = 0];</code>
			 *
			 * <pre>
			 * Pad, kernel size, and stride are all given as a single value for equal
			 * dimensions in height and width or as Y, X pairs.
			 * </pre>
			 */
			public Builder clearPad()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				pad_ = 0;
				onChanged();
				return this;
			}

			private int padH_;

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			@Override
			public boolean hasPadH()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			@Override
			public int getPadH()
			{
				return padH_;
			}

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			public Builder setPadH(int value)
			{
				bitField0_ |= 0x00000004;
				padH_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad_h = 9 [default = 0];</code>
			 *
			 * <pre>
			 * The padding height
			 * </pre>
			 */
			public Builder clearPadH()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				padH_ = 0;
				onChanged();
				return this;
			}

			private int padW_;

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			@Override
			public boolean hasPadW()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			@Override
			public int getPadW()
			{
				return padW_;
			}

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			public Builder setPadW(int value)
			{
				bitField0_ |= 0x00000008;
				padW_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad_w = 10 [default = 0];</code>
			 *
			 * <pre>
			 * The padding width
			 * </pre>
			 */
			public Builder clearPadW()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				padW_ = 0;
				onChanged();
				return this;
			}

			private int kernelSize_;

			/**
			 * <code>optional uint32 kernel_size = 2;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			@Override
			public boolean hasKernelSize()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional uint32 kernel_size = 2;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			@Override
			public int getKernelSize()
			{
				return kernelSize_;
			}

			/**
			 * <code>optional uint32 kernel_size = 2;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			public Builder setKernelSize(int value)
			{
				bitField0_ |= 0x00000010;
				kernelSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernel_size = 2;</code>
			 *
			 * <pre>
			 * The kernel size (square)
			 * </pre>
			 */
			public Builder clearKernelSize()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				kernelSize_ = 0;
				onChanged();
				return this;
			}

			private int kernelH_;

			/**
			 * <code>optional uint32 kernel_h = 5;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			@Override
			public boolean hasKernelH()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional uint32 kernel_h = 5;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			@Override
			public int getKernelH()
			{
				return kernelH_;
			}

			/**
			 * <code>optional uint32 kernel_h = 5;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			public Builder setKernelH(int value)
			{
				bitField0_ |= 0x00000020;
				kernelH_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernel_h = 5;</code>
			 *
			 * <pre>
			 * The kernel height
			 * </pre>
			 */
			public Builder clearKernelH()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				kernelH_ = 0;
				onChanged();
				return this;
			}

			private int kernelW_;

			/**
			 * <code>optional uint32 kernel_w = 6;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			@Override
			public boolean hasKernelW()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional uint32 kernel_w = 6;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			@Override
			public int getKernelW()
			{
				return kernelW_;
			}

			/**
			 * <code>optional uint32 kernel_w = 6;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			public Builder setKernelW(int value)
			{
				bitField0_ |= 0x00000040;
				kernelW_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernel_w = 6;</code>
			 *
			 * <pre>
			 * The kernel width
			 * </pre>
			 */
			public Builder clearKernelW()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				kernelW_ = 0;
				onChanged();
				return this;
			}

			private int stride_ = 1;

			/**
			 * <code>optional uint32 stride = 3 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			@Override
			public boolean hasStride()
			{
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional uint32 stride = 3 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			@Override
			public int getStride()
			{
				return stride_;
			}

			/**
			 * <code>optional uint32 stride = 3 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			public Builder setStride(int value)
			{
				bitField0_ |= 0x00000080;
				stride_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride = 3 [default = 1];</code>
			 *
			 * <pre>
			 * The stride (equal in Y, X)
			 * </pre>
			 */
			public Builder clearStride()
			{
				bitField0_ = (bitField0_ & ~0x00000080);
				stride_ = 1;
				onChanged();
				return this;
			}

			private int strideH_;

			/**
			 * <code>optional uint32 stride_h = 7;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			@Override
			public boolean hasStrideH()
			{
				return ((bitField0_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>optional uint32 stride_h = 7;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			@Override
			public int getStrideH()
			{
				return strideH_;
			}

			/**
			 * <code>optional uint32 stride_h = 7;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			public Builder setStrideH(int value)
			{
				bitField0_ |= 0x00000100;
				strideH_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride_h = 7;</code>
			 *
			 * <pre>
			 * The stride height
			 * </pre>
			 */
			public Builder clearStrideH()
			{
				bitField0_ = (bitField0_ & ~0x00000100);
				strideH_ = 0;
				onChanged();
				return this;
			}

			private int strideW_;

			/**
			 * <code>optional uint32 stride_w = 8;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			@Override
			public boolean hasStrideW()
			{
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional uint32 stride_w = 8;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			@Override
			public int getStrideW()
			{
				return strideW_;
			}

			/**
			 * <code>optional uint32 stride_w = 8;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			public Builder setStrideW(int value)
			{
				bitField0_ |= 0x00000200;
				strideW_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride_w = 8;</code>
			 *
			 * <pre>
			 * The stride width
			 * </pre>
			 */
			public Builder clearStrideW()
			{
				bitField0_ = (bitField0_ & ~0x00000200);
				strideW_ = 0;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine.DEFAULT;

			/**
			 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
			 */
			@Override
			public boolean hasEngine()
			{
				return ((bitField0_ & 0x00000400) == 0x00000400);
			}

			/**
			 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine getEngine()
			{
				return engine_;
			}

			/**
			 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
			 */
			public Builder setEngine(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000400;
				engine_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.PoolingParameter.Engine engine = 11 [default = DEFAULT];</code>
			 */
			public Builder clearEngine()
			{
				bitField0_ = (bitField0_ & ~0x00000400);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PoolingParameter.Engine.DEFAULT;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.PoolingParameter)
		}

		static
		{
			defaultInstance = new PoolingParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.PoolingParameter)
	}

	public interface PowerParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.PowerParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional float power = 1 [default = 1];</code>
		 *
		 * <pre>
		 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
		 * </pre>
		 */
		boolean hasPower();

		/**
		 * <code>optional float power = 1 [default = 1];</code>
		 *
		 * <pre>
		 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
		 * </pre>
		 */
		float getPower();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 */
		boolean hasScale();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 */
		float getScale();

		/**
		 * <code>optional float shift = 3 [default = 0];</code>
		 */
		boolean hasShift();

		/**
		 * <code>optional float shift = 3 [default = 0];</code>
		 */
		float getShift();
	}

	/**
	 * Protobuf type {@code caffe.PowerParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by PowerLayer
	 * </pre>
	 */
	public static final class PowerParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.PowerParameter)
			PowerParameterOrBuilder
	{
		// Use PowerParameter.newBuilder() to construct.
		private PowerParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private PowerParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final PowerParameter defaultInstance;

		public static PowerParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public PowerParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private PowerParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 13:
					{
						bitField0_ |= 0x00000001;
						power_ = input.readFloat();
						break;
					}
					case 21:
					{
						bitField0_ |= 0x00000002;
						scale_ = input.readFloat();
						break;
					}
					case 29:
					{
						bitField0_ |= 0x00000004;
						shift_ = input.readFloat();
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PowerParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PowerParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<PowerParameter> PARSER =
				new com.google.protobuf.AbstractParser<PowerParameter>()
				{
					@Override
					public PowerParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new PowerParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<PowerParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int POWER_FIELD_NUMBER = 1;
		private float power_;

		/**
		 * <code>optional float power = 1 [default = 1];</code>
		 *
		 * <pre>
		 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
		 * </pre>
		 */
		@Override
		public boolean hasPower()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional float power = 1 [default = 1];</code>
		 *
		 * <pre>
		 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
		 * </pre>
		 */
		@Override
		public float getPower()
		{
			return power_;
		}

		public static final int SCALE_FIELD_NUMBER = 2;
		private float scale_;

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 */
		@Override
		public boolean hasScale()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 */
		@Override
		public float getScale()
		{
			return scale_;
		}

		public static final int SHIFT_FIELD_NUMBER = 3;
		private float shift_;

		/**
		 * <code>optional float shift = 3 [default = 0];</code>
		 */
		@Override
		public boolean hasShift()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional float shift = 3 [default = 0];</code>
		 */
		@Override
		public float getShift()
		{
			return shift_;
		}

		private void initFields()
		{
			power_ = 1F;
			scale_ = 1F;
			shift_ = 0F;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeFloat(1, power_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeFloat(2, scale_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeFloat(3, shift_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(1, power_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(2, scale_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(3, shift_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.PowerParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by PowerLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.PowerParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PowerParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PowerParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				power_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000001);
				scale_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000002);
				shift_ = 0F;
				bitField0_ = (bitField0_ & ~0x00000004);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_PowerParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.power_ = power_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.scale_ = scale_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.shift_ = shift_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter.getDefaultInstance())
					return this;
				if (other.hasPower())
				{
					setPower(other.getPower());
				}
				if (other.hasScale())
				{
					setScale(other.getScale());
				}
				if (other.hasShift())
				{
					setShift(other.getShift());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.PowerParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private float power_ = 1F;

			/**
			 * <code>optional float power = 1 [default = 1];</code>
			 *
			 * <pre>
			 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
			 * </pre>
			 */
			@Override
			public boolean hasPower()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional float power = 1 [default = 1];</code>
			 *
			 * <pre>
			 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
			 * </pre>
			 */
			@Override
			public float getPower()
			{
				return power_;
			}

			/**
			 * <code>optional float power = 1 [default = 1];</code>
			 *
			 * <pre>
			 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
			 * </pre>
			 */
			public Builder setPower(float value)
			{
				bitField0_ |= 0x00000001;
				power_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float power = 1 [default = 1];</code>
			 *
			 * <pre>
			 * PowerLayer computes outputs y = (shift + scale * x) ^ power.
			 * </pre>
			 */
			public Builder clearPower()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				power_ = 1F;
				onChanged();
				return this;
			}

			private float scale_ = 1F;

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 */
			@Override
			public boolean hasScale()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 */
			@Override
			public float getScale()
			{
				return scale_;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 */
			public Builder setScale(float value)
			{
				bitField0_ |= 0x00000002;
				scale_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 */
			public Builder clearScale()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				scale_ = 1F;
				onChanged();
				return this;
			}

			private float shift_;

			/**
			 * <code>optional float shift = 3 [default = 0];</code>
			 */
			@Override
			public boolean hasShift()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional float shift = 3 [default = 0];</code>
			 */
			@Override
			public float getShift()
			{
				return shift_;
			}

			/**
			 * <code>optional float shift = 3 [default = 0];</code>
			 */
			public Builder setShift(float value)
			{
				bitField0_ |= 0x00000004;
				shift_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float shift = 3 [default = 0];</code>
			 */
			public Builder clearShift()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				shift_ = 0F;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.PowerParameter)
		}

		static
		{
			defaultInstance = new PowerParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.PowerParameter)
	}

	public interface ReLUParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.ReLUParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional float negative_slope = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Allow non-zero slope for negative inputs to speed up optimization
		 * Described in:
		 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
		 * improve neural network acoustic models. In ICML Workshop on Deep Learning
		 * for Audio, Speech, and Language Processing.
		 * </pre>
		 */
		boolean hasNegativeSlope();

		/**
		 * <code>optional float negative_slope = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Allow non-zero slope for negative inputs to speed up optimization
		 * Described in:
		 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
		 * improve neural network acoustic models. In ICML Workshop on Deep Learning
		 * for Audio, Speech, and Language Processing.
		 * </pre>
		 */
		float getNegativeSlope();

		/**
		 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
		 */
		boolean hasEngine();

		/**
		 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine getEngine();
	}

	/**
	 * Protobuf type {@code caffe.ReLUParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by ReLULayer
	 * </pre>
	 */
	public static final class ReLUParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.ReLUParameter)
			ReLUParameterOrBuilder
	{
		// Use ReLUParameter.newBuilder() to construct.
		private ReLUParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private ReLUParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final ReLUParameter defaultInstance;

		public static ReLUParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public ReLUParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private ReLUParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 13:
					{
						bitField0_ |= 0x00000001;
						negativeSlope_ = input.readFloat();
						break;
					}
					case 16:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(2, rawValue);
						} else
						{
							bitField0_ |= 0x00000002;
							engine_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ReLUParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ReLUParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<ReLUParameter> PARSER =
				new com.google.protobuf.AbstractParser<ReLUParameter>()
				{
					@Override
					public ReLUParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new ReLUParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<ReLUParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.ReLUParameter.Engine}
		 */
		public enum Engine
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>DEFAULT = 0;</code>
			 */
			DEFAULT(0, 0),
			/**
			 * <code>CAFFE = 1;</code>
			 */
			CAFFE(1, 1),
			/**
			 * <code>CUDNN = 2;</code>
			 */
			CUDNN(2, 2), ;

			/**
			 * <code>DEFAULT = 0;</code>
			 */
			public static final int DEFAULT_VALUE = 0;
			/**
			 * <code>CAFFE = 1;</code>
			 */
			public static final int CAFFE_VALUE = 1;
			/**
			 * <code>CUDNN = 2;</code>
			 */
			public static final int CUDNN_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Engine valueOf(int value)
			{
				switch (value) {
				case 0:
					return DEFAULT;
				case 1:
					return CAFFE;
				case 2:
					return CUDNN;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Engine>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Engine> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Engine>()
					{
						@Override
						public Engine findValueByNumber(int number)
						{
							return Engine.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final Engine[] VALUES = values();

			public static Engine valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Engine(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.ReLUParameter.Engine)
		}

		private int bitField0_;
		public static final int NEGATIVE_SLOPE_FIELD_NUMBER = 1;
		private float negativeSlope_;

		/**
		 * <code>optional float negative_slope = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Allow non-zero slope for negative inputs to speed up optimization
		 * Described in:
		 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
		 * improve neural network acoustic models. In ICML Workshop on Deep Learning
		 * for Audio, Speech, and Language Processing.
		 * </pre>
		 */
		@Override
		public boolean hasNegativeSlope()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional float negative_slope = 1 [default = 0];</code>
		 *
		 * <pre>
		 * Allow non-zero slope for negative inputs to speed up optimization
		 * Described in:
		 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
		 * improve neural network acoustic models. In ICML Workshop on Deep Learning
		 * for Audio, Speech, and Language Processing.
		 * </pre>
		 */
		@Override
		public float getNegativeSlope()
		{
			return negativeSlope_;
		}

		public static final int ENGINE_FIELD_NUMBER = 2;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine engine_;

		/**
		 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
		 */
		@Override
		public boolean hasEngine()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine getEngine()
		{
			return engine_;
		}

		private void initFields()
		{
			negativeSlope_ = 0F;
			engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine.DEFAULT;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeFloat(1, negativeSlope_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeEnum(2, engine_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(1, negativeSlope_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(2, engine_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.ReLUParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by ReLULayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.ReLUParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ReLUParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ReLUParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				negativeSlope_ = 0F;
				bitField0_ = (bitField0_ & ~0x00000001);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine.DEFAULT;
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_ReLUParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.negativeSlope_ = negativeSlope_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.engine_ = engine_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.getDefaultInstance())
					return this;
				if (other.hasNegativeSlope())
				{
					setNegativeSlope(other.getNegativeSlope());
				}
				if (other.hasEngine())
				{
					setEngine(other.getEngine());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private float negativeSlope_;

			/**
			 * <code>optional float negative_slope = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Allow non-zero slope for negative inputs to speed up optimization
			 * Described in:
			 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
			 * improve neural network acoustic models. In ICML Workshop on Deep Learning
			 * for Audio, Speech, and Language Processing.
			 * </pre>
			 */
			@Override
			public boolean hasNegativeSlope()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional float negative_slope = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Allow non-zero slope for negative inputs to speed up optimization
			 * Described in:
			 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
			 * improve neural network acoustic models. In ICML Workshop on Deep Learning
			 * for Audio, Speech, and Language Processing.
			 * </pre>
			 */
			@Override
			public float getNegativeSlope()
			{
				return negativeSlope_;
			}

			/**
			 * <code>optional float negative_slope = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Allow non-zero slope for negative inputs to speed up optimization
			 * Described in:
			 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
			 * improve neural network acoustic models. In ICML Workshop on Deep Learning
			 * for Audio, Speech, and Language Processing.
			 * </pre>
			 */
			public Builder setNegativeSlope(float value)
			{
				bitField0_ |= 0x00000001;
				negativeSlope_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float negative_slope = 1 [default = 0];</code>
			 *
			 * <pre>
			 * Allow non-zero slope for negative inputs to speed up optimization
			 * Described in:
			 * Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier nonlinearities
			 * improve neural network acoustic models. In ICML Workshop on Deep Learning
			 * for Audio, Speech, and Language Processing.
			 * </pre>
			 */
			public Builder clearNegativeSlope()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				negativeSlope_ = 0F;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine.DEFAULT;

			/**
			 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
			 */
			@Override
			public boolean hasEngine()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine getEngine()
			{
				return engine_;
			}

			/**
			 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
			 */
			public Builder setEngine(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000002;
				engine_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.ReLUParameter.Engine engine = 2 [default = DEFAULT];</code>
			 */
			public Builder clearEngine()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.ReLUParameter.Engine.DEFAULT;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.ReLUParameter)
		}

		static
		{
			defaultInstance = new ReLUParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.ReLUParameter)
	}

	public interface SigmoidParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.SigmoidParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		boolean hasEngine();

		/**
		 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine getEngine();
	}

	/**
	 * Protobuf type {@code caffe.SigmoidParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by SigmoidLayer
	 * </pre>
	 */
	public static final class SigmoidParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.SigmoidParameter)
			SigmoidParameterOrBuilder
	{
		// Use SigmoidParameter.newBuilder() to construct.
		private SigmoidParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private SigmoidParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final SigmoidParameter defaultInstance;

		public static SigmoidParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public SigmoidParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private SigmoidParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							engine_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SigmoidParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SigmoidParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<SigmoidParameter> PARSER =
				new com.google.protobuf.AbstractParser<SigmoidParameter>()
				{
					@Override
					public SigmoidParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new SigmoidParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<SigmoidParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.SigmoidParameter.Engine}
		 */
		public enum Engine
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>DEFAULT = 0;</code>
			 */
			DEFAULT(0, 0),
			/**
			 * <code>CAFFE = 1;</code>
			 */
			CAFFE(1, 1),
			/**
			 * <code>CUDNN = 2;</code>
			 */
			CUDNN(2, 2), ;

			/**
			 * <code>DEFAULT = 0;</code>
			 */
			public static final int DEFAULT_VALUE = 0;
			/**
			 * <code>CAFFE = 1;</code>
			 */
			public static final int CAFFE_VALUE = 1;
			/**
			 * <code>CUDNN = 2;</code>
			 */
			public static final int CUDNN_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Engine valueOf(int value)
			{
				switch (value) {
				case 0:
					return DEFAULT;
				case 1:
					return CAFFE;
				case 2:
					return CUDNN;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Engine>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Engine> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Engine>()
					{
						@Override
						public Engine findValueByNumber(int number)
						{
							return Engine.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final Engine[] VALUES = values();

			public static Engine valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Engine(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.SigmoidParameter.Engine)
		}

		private int bitField0_;
		public static final int ENGINE_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine engine_;

		/**
		 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		@Override
		public boolean hasEngine()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine getEngine()
		{
			return engine_;
		}

		private void initFields()
		{
			engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine.DEFAULT;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, engine_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, engine_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.SigmoidParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by SigmoidLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.SigmoidParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SigmoidParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SigmoidParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine.DEFAULT;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SigmoidParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.engine_ = engine_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.getDefaultInstance())
					return this;
				if (other.hasEngine())
				{
					setEngine(other.getEngine());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine.DEFAULT;

			/**
			 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			@Override
			public boolean hasEngine()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine getEngine()
			{
				return engine_;
			}

			/**
			 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			public Builder setEngine(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				engine_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.SigmoidParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			public Builder clearEngine()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SigmoidParameter.Engine.DEFAULT;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.SigmoidParameter)
		}

		static
		{
			defaultInstance = new SigmoidParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)
	}

	public interface SliceParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.SliceParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * SliceLayer needs to know which dimension to slice across.
		 * Currently, SliceLayer only supports slicing across num (dim 0)
		 * and channels (dim 1).
		 * By default, SliceLayer slices across channels.
		 * </pre>
		 */
		boolean hasSliceDim();

		/**
		 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * SliceLayer needs to know which dimension to slice across.
		 * Currently, SliceLayer only supports slicing across num (dim 0)
		 * and channels (dim 1).
		 * By default, SliceLayer slices across channels.
		 * </pre>
		 */
		int getSliceDim();

		/**
		 * <code>repeated uint32 slice_point = 2;</code>
		 */
		java.util.List<java.lang.Integer> getSlicePointList();

		/**
		 * <code>repeated uint32 slice_point = 2;</code>
		 */
		int getSlicePointCount();

		/**
		 * <code>repeated uint32 slice_point = 2;</code>
		 */
		int getSlicePoint(int index);
	}

	/**
	 * Protobuf type {@code caffe.SliceParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by SliceLayer
	 * </pre>
	 */
	public static final class SliceParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.SliceParameter)
			SliceParameterOrBuilder
	{
		// Use SliceParameter.newBuilder() to construct.
		private SliceParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private SliceParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final SliceParameter defaultInstance;

		public static SliceParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public SliceParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private SliceParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						bitField0_ |= 0x00000001;
						sliceDim_ = input.readUInt32();
						break;
					}
					case 16:
					{
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002))
						{
							slicePoint_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000002;
						}
						slicePoint_.add(input.readUInt32());
						break;
					}
					case 18:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0)
						{
							slicePoint_ = new java.util.ArrayList<java.lang.Integer>();
							mutable_bitField0_ |= 0x00000002;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							slicePoint_.add(input.readUInt32());
						}
						input.popLimit(limit);
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00000002) == 0x00000002))
				{
					slicePoint_ = java.util.Collections.unmodifiableList(slicePoint_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SliceParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SliceParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<SliceParameter> PARSER =
				new com.google.protobuf.AbstractParser<SliceParameter>()
				{
					@Override
					public SliceParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new SliceParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<SliceParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int SLICE_DIM_FIELD_NUMBER = 1;
		private int sliceDim_;

		/**
		 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * SliceLayer needs to know which dimension to slice across.
		 * Currently, SliceLayer only supports slicing across num (dim 0)
		 * and channels (dim 1).
		 * By default, SliceLayer slices across channels.
		 * </pre>
		 */
		@Override
		public boolean hasSliceDim()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
		 *
		 * <pre>
		 * SliceLayer needs to know which dimension to slice across.
		 * Currently, SliceLayer only supports slicing across num (dim 0)
		 * and channels (dim 1).
		 * By default, SliceLayer slices across channels.
		 * </pre>
		 */
		@Override
		public int getSliceDim()
		{
			return sliceDim_;
		}

		public static final int SLICE_POINT_FIELD_NUMBER = 2;
		private java.util.List<java.lang.Integer> slicePoint_;

		/**
		 * <code>repeated uint32 slice_point = 2;</code>
		 */
		@Override
		public java.util.List<java.lang.Integer>
				getSlicePointList()
		{
			return slicePoint_;
		}

		/**
		 * <code>repeated uint32 slice_point = 2;</code>
		 */
		@Override
		public int getSlicePointCount()
		{
			return slicePoint_.size();
		}

		/**
		 * <code>repeated uint32 slice_point = 2;</code>
		 */
		@Override
		public int getSlicePoint(int index)
		{
			return slicePoint_.get(index);
		}

		private void initFields()
		{
			sliceDim_ = 1;
			slicePoint_ = java.util.Collections.emptyList();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(1, sliceDim_);
			}
			for (int i = 0; i < slicePoint_.size(); i++)
			{
				output.writeUInt32(2, slicePoint_.get(i));
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(1, sliceDim_);
			}
			{
				int dataSize = 0;
				for (int i = 0; i < slicePoint_.size(); i++)
				{
					dataSize += com.google.protobuf.CodedOutputStream
							.computeUInt32SizeNoTag(slicePoint_.get(i));
				}
				size += dataSize;
				size += 1 * getSlicePointList().size();
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.SliceParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by SliceLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.SliceParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SliceParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SliceParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				sliceDim_ = 1;
				bitField0_ = (bitField0_ & ~0x00000001);
				slicePoint_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SliceParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.sliceDim_ = sliceDim_;
				if (((bitField0_ & 0x00000002) == 0x00000002))
				{
					slicePoint_ = java.util.Collections.unmodifiableList(slicePoint_);
					bitField0_ = (bitField0_ & ~0x00000002);
				}
				result.slicePoint_ = slicePoint_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter.getDefaultInstance())
					return this;
				if (other.hasSliceDim())
				{
					setSliceDim(other.getSliceDim());
				}
				if (!other.slicePoint_.isEmpty())
				{
					if (slicePoint_.isEmpty())
					{
						slicePoint_ = other.slicePoint_;
						bitField0_ = (bitField0_ & ~0x00000002);
					} else
					{
						ensureSlicePointIsMutable();
						slicePoint_.addAll(other.slicePoint_);
					}
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SliceParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private int sliceDim_ = 1;

			/**
			 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * SliceLayer needs to know which dimension to slice across.
			 * Currently, SliceLayer only supports slicing across num (dim 0)
			 * and channels (dim 1).
			 * By default, SliceLayer slices across channels.
			 * </pre>
			 */
			@Override
			public boolean hasSliceDim()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * SliceLayer needs to know which dimension to slice across.
			 * Currently, SliceLayer only supports slicing across num (dim 0)
			 * and channels (dim 1).
			 * By default, SliceLayer slices across channels.
			 * </pre>
			 */
			@Override
			public int getSliceDim()
			{
				return sliceDim_;
			}

			/**
			 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * SliceLayer needs to know which dimension to slice across.
			 * Currently, SliceLayer only supports slicing across num (dim 0)
			 * and channels (dim 1).
			 * By default, SliceLayer slices across channels.
			 * </pre>
			 */
			public Builder setSliceDim(int value)
			{
				bitField0_ |= 0x00000001;
				sliceDim_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 slice_dim = 1 [default = 1];</code>
			 *
			 * <pre>
			 * SliceLayer needs to know which dimension to slice across.
			 * Currently, SliceLayer only supports slicing across num (dim 0)
			 * and channels (dim 1).
			 * By default, SliceLayer slices across channels.
			 * </pre>
			 */
			public Builder clearSliceDim()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				sliceDim_ = 1;
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Integer> slicePoint_ = java.util.Collections.emptyList();

			private void ensureSlicePointIsMutable()
			{
				if (!((bitField0_ & 0x00000002) == 0x00000002))
				{
					slicePoint_ = new java.util.ArrayList<java.lang.Integer>(slicePoint_);
					bitField0_ |= 0x00000002;
				}
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			@Override
			public java.util.List<java.lang.Integer>
					getSlicePointList()
			{
				return java.util.Collections.unmodifiableList(slicePoint_);
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			@Override
			public int getSlicePointCount()
			{
				return slicePoint_.size();
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			@Override
			public int getSlicePoint(int index)
			{
				return slicePoint_.get(index);
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			public Builder setSlicePoint(
					int index, int value)
			{
				ensureSlicePointIsMutable();
				slicePoint_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			public Builder addSlicePoint(int value)
			{
				ensureSlicePointIsMutable();
				slicePoint_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			public Builder addAllSlicePoint(
					java.lang.Iterable<? extends java.lang.Integer> values)
			{
				ensureSlicePointIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, slicePoint_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated uint32 slice_point = 2;</code>
			 */
			public Builder clearSlicePoint()
			{
				slicePoint_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00000002);
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.SliceParameter)
		}

		static
		{
			defaultInstance = new SliceParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.SliceParameter)
	}

	public interface SoftmaxParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.SoftmaxParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		boolean hasEngine();

		/**
		 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine getEngine();
	}

	/**
	 * Protobuf type {@code caffe.SoftmaxParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by SoftmaxLayer, SoftMaxWithLossLayer
	 * </pre>
	 */
	public static final class SoftmaxParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.SoftmaxParameter)
			SoftmaxParameterOrBuilder
	{
		// Use SoftmaxParameter.newBuilder() to construct.
		private SoftmaxParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private SoftmaxParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final SoftmaxParameter defaultInstance;

		public static SoftmaxParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public SoftmaxParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private SoftmaxParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							engine_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SoftmaxParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SoftmaxParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<SoftmaxParameter> PARSER =
				new com.google.protobuf.AbstractParser<SoftmaxParameter>()
				{
					@Override
					public SoftmaxParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new SoftmaxParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<SoftmaxParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.SoftmaxParameter.Engine}
		 */
		public enum Engine
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>DEFAULT = 0;</code>
			 */
			DEFAULT(0, 0),
			/**
			 * <code>CAFFE = 1;</code>
			 */
			CAFFE(1, 1),
			/**
			 * <code>CUDNN = 2;</code>
			 */
			CUDNN(2, 2), ;

			/**
			 * <code>DEFAULT = 0;</code>
			 */
			public static final int DEFAULT_VALUE = 0;
			/**
			 * <code>CAFFE = 1;</code>
			 */
			public static final int CAFFE_VALUE = 1;
			/**
			 * <code>CUDNN = 2;</code>
			 */
			public static final int CUDNN_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Engine valueOf(int value)
			{
				switch (value) {
				case 0:
					return DEFAULT;
				case 1:
					return CAFFE;
				case 2:
					return CUDNN;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Engine>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Engine> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Engine>()
					{
						@Override
						public Engine findValueByNumber(int number)
						{
							return Engine.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final Engine[] VALUES = values();

			public static Engine valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Engine(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.SoftmaxParameter.Engine)
		}

		private int bitField0_;
		public static final int ENGINE_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine engine_;

		/**
		 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		@Override
		public boolean hasEngine()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine getEngine()
		{
			return engine_;
		}

		private void initFields()
		{
			engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine.DEFAULT;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, engine_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, engine_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.SoftmaxParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by SoftmaxLayer, SoftMaxWithLossLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.SoftmaxParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SoftmaxParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SoftmaxParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine.DEFAULT;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_SoftmaxParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.engine_ = engine_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.getDefaultInstance())
					return this;
				if (other.hasEngine())
				{
					setEngine(other.getEngine());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine.DEFAULT;

			/**
			 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			@Override
			public boolean hasEngine()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine getEngine()
			{
				return engine_;
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			public Builder setEngine(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				engine_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.SoftmaxParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			public Builder clearEngine()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.SoftmaxParameter.Engine.DEFAULT;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.SoftmaxParameter)
		}

		static
		{
			defaultInstance = new SoftmaxParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)
	}

	public interface TanHParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.TanHParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		boolean hasEngine();

		/**
		 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine getEngine();
	}

	/**
	 * Protobuf type {@code caffe.TanHParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by SigmoidLayer
	 * </pre>
	 */
	public static final class TanHParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.TanHParameter)
			TanHParameterOrBuilder
	{
		// Use TanHParameter.newBuilder() to construct.
		private TanHParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private TanHParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final TanHParameter defaultInstance;

		public static TanHParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public TanHParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private TanHParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 8:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(1, rawValue);
						} else
						{
							bitField0_ |= 0x00000001;
							engine_ = value;
						}
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TanHParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TanHParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<TanHParameter> PARSER =
				new com.google.protobuf.AbstractParser<TanHParameter>()
				{
					@Override
					public TanHParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new TanHParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<TanHParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.TanHParameter.Engine}
		 */
		public enum Engine
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>DEFAULT = 0;</code>
			 */
			DEFAULT(0, 0),
			/**
			 * <code>CAFFE = 1;</code>
			 */
			CAFFE(1, 1),
			/**
			 * <code>CUDNN = 2;</code>
			 */
			CUDNN(2, 2), ;

			/**
			 * <code>DEFAULT = 0;</code>
			 */
			public static final int DEFAULT_VALUE = 0;
			/**
			 * <code>CAFFE = 1;</code>
			 */
			public static final int CAFFE_VALUE = 1;
			/**
			 * <code>CUDNN = 2;</code>
			 */
			public static final int CUDNN_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static Engine valueOf(int value)
			{
				switch (value) {
				case 0:
					return DEFAULT;
				case 1:
					return CAFFE;
				case 2:
					return CUDNN;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<Engine>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<Engine> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<Engine>()
					{
						@Override
						public Engine findValueByNumber(int number)
						{
							return Engine.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final Engine[] VALUES = values();

			public static Engine valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private Engine(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.TanHParameter.Engine)
		}

		private int bitField0_;
		public static final int ENGINE_FIELD_NUMBER = 1;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine engine_;

		/**
		 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		@Override
		public boolean hasEngine()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine getEngine()
		{
			return engine_;
		}

		private void initFields()
		{
			engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine.DEFAULT;
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeEnum(1, engine_.getNumber());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(1, engine_.getNumber());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.TanHParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by SigmoidLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.TanHParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TanHParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TanHParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine.DEFAULT;
				bitField0_ = (bitField0_ & ~0x00000001);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_TanHParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.engine_ = engine_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.getDefaultInstance())
					return this;
				if (other.hasEngine())
				{
					setEngine(other.getEngine());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine.DEFAULT;

			/**
			 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			@Override
			public boolean hasEngine()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine getEngine()
			{
				return engine_;
			}

			/**
			 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			public Builder setEngine(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				engine_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.TanHParameter.Engine engine = 1 [default = DEFAULT];</code>
			 */
			public Builder clearEngine()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				engine_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.TanHParameter.Engine.DEFAULT;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.TanHParameter)
		}

		static
		{
			defaultInstance = new TanHParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.TanHParameter)
	}

	public interface WindowDataParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.WindowDataParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		boolean hasSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		java.lang.String getSource();

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSourceBytes();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		boolean hasScale();

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		float getScale();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		boolean hasMeanFile();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		java.lang.String getMeanFile();

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		com.google.protobuf.ByteString
				getMeanFileBytes();

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		boolean hasBatchSize();

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		int getBatchSize();

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		boolean hasCropSize();

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		int getCropSize();

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		boolean hasMirror();

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		boolean getMirror();

		/**
		 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
		 *
		 * <pre>
		 * Foreground (object) overlap threshold
		 * </pre>
		 */
		boolean hasFgThreshold();

		/**
		 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
		 *
		 * <pre>
		 * Foreground (object) overlap threshold
		 * </pre>
		 */
		float getFgThreshold();

		/**
		 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
		 *
		 * <pre>
		 * Background (non-object) overlap threshold
		 * </pre>
		 */
		boolean hasBgThreshold();

		/**
		 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
		 *
		 * <pre>
		 * Background (non-object) overlap threshold
		 * </pre>
		 */
		float getBgThreshold();

		/**
		 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		boolean hasFgFraction();

		/**
		 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		float getFgFraction();

		/**
		 * <code>optional uint32 context_pad = 10 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		boolean hasContextPad();

		/**
		 * <code>optional uint32 context_pad = 10 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		int getContextPad();

		/**
		 * <code>optional string crop_mode = 11 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		boolean hasCropMode();

		/**
		 * <code>optional string crop_mode = 11 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		java.lang.String getCropMode();

		/**
		 * <code>optional string crop_mode = 11 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getCropModeBytes();
	}

	/**
	 * Protobuf type {@code caffe.WindowDataParameter}
	 *
	 * <pre>
	 * Message that stores parameters used by WindowDataLayer
	 * </pre>
	 */
	public static final class WindowDataParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.WindowDataParameter)
			WindowDataParameterOrBuilder
	{
		// Use WindowDataParameter.newBuilder() to construct.
		private WindowDataParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private WindowDataParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final WindowDataParameter defaultInstance;

		public static WindowDataParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public WindowDataParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private WindowDataParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						source_ = bs;
						break;
					}
					case 21:
					{
						bitField0_ |= 0x00000002;
						scale_ = input.readFloat();
						break;
					}
					case 26:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000004;
						meanFile_ = bs;
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000008;
						batchSize_ = input.readUInt32();
						break;
					}
					case 40:
					{
						bitField0_ |= 0x00000010;
						cropSize_ = input.readUInt32();
						break;
					}
					case 48:
					{
						bitField0_ |= 0x00000020;
						mirror_ = input.readBool();
						break;
					}
					case 61:
					{
						bitField0_ |= 0x00000040;
						fgThreshold_ = input.readFloat();
						break;
					}
					case 69:
					{
						bitField0_ |= 0x00000080;
						bgThreshold_ = input.readFloat();
						break;
					}
					case 77:
					{
						bitField0_ |= 0x00000100;
						fgFraction_ = input.readFloat();
						break;
					}
					case 80:
					{
						bitField0_ |= 0x00000200;
						contextPad_ = input.readUInt32();
						break;
					}
					case 90:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000400;
						cropMode_ = bs;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_WindowDataParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_WindowDataParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.class,
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<WindowDataParameter> PARSER =
				new com.google.protobuf.AbstractParser<WindowDataParameter>()
				{
					@Override
					public WindowDataParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new WindowDataParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<WindowDataParameter> getParserForType()
		{
			return PARSER;
		}

		private int bitField0_;
		public static final int SOURCE_FIELD_NUMBER = 1;
		private java.lang.Object source_;

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public boolean hasSource()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public java.lang.String getSource()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					source_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string source = 1;</code>
		 *
		 * <pre>
		 * Specify the data source.
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSourceBytes()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				source_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int SCALE_FIELD_NUMBER = 2;
		private float scale_;

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		@Override
		public boolean hasScale()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional float scale = 2 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		@Override
		public float getScale()
		{
			return scale_;
		}

		public static final int MEAN_FILE_FIELD_NUMBER = 3;
		private java.lang.Object meanFile_;

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public boolean hasMeanFile()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public java.lang.String getMeanFile()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					meanFile_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string mean_file = 3;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getMeanFileBytes()
		{
			java.lang.Object ref = meanFile_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				meanFile_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int BATCH_SIZE_FIELD_NUMBER = 4;
		private int batchSize_;

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public boolean hasBatchSize()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional uint32 batch_size = 4;</code>
		 *
		 * <pre>
		 * Specify the batch size.
		 * </pre>
		 */
		@Override
		public int getBatchSize()
		{
			return batchSize_;
		}

		public static final int CROP_SIZE_FIELD_NUMBER = 5;
		private int cropSize_;

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		@Override
		public boolean hasCropSize()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional uint32 crop_size = 5 [default = 0];</code>
		 *
		 * <pre>
		 * Specify if we would like to randomly crop an image.
		 * </pre>
		 */
		@Override
		public int getCropSize()
		{
			return cropSize_;
		}

		public static final int MIRROR_FIELD_NUMBER = 6;
		private boolean mirror_;

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		@Override
		public boolean hasMirror()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional bool mirror = 6 [default = false];</code>
		 *
		 * <pre>
		 * Specify if we want to randomly mirror data.
		 * </pre>
		 */
		@Override
		public boolean getMirror()
		{
			return mirror_;
		}

		public static final int FG_THRESHOLD_FIELD_NUMBER = 7;
		private float fgThreshold_;

		/**
		 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
		 *
		 * <pre>
		 * Foreground (object) overlap threshold
		 * </pre>
		 */
		@Override
		public boolean hasFgThreshold()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
		 *
		 * <pre>
		 * Foreground (object) overlap threshold
		 * </pre>
		 */
		@Override
		public float getFgThreshold()
		{
			return fgThreshold_;
		}

		public static final int BG_THRESHOLD_FIELD_NUMBER = 8;
		private float bgThreshold_;

		/**
		 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
		 *
		 * <pre>
		 * Background (non-object) overlap threshold
		 * </pre>
		 */
		@Override
		public boolean hasBgThreshold()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
		 *
		 * <pre>
		 * Background (non-object) overlap threshold
		 * </pre>
		 */
		@Override
		public float getBgThreshold()
		{
			return bgThreshold_;
		}

		public static final int FG_FRACTION_FIELD_NUMBER = 9;
		private float fgFraction_;

		/**
		 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		@Override
		public boolean hasFgFraction()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		@Override
		public float getFgFraction()
		{
			return fgFraction_;
		}

		public static final int CONTEXT_PAD_FIELD_NUMBER = 10;
		private int contextPad_;

		/**
		 * <code>optional uint32 context_pad = 10 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		@Override
		public boolean hasContextPad()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional uint32 context_pad = 10 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		@Override
		public int getContextPad()
		{
			return contextPad_;
		}

		public static final int CROP_MODE_FIELD_NUMBER = 11;
		private java.lang.Object cropMode_;

		/**
		 * <code>optional string crop_mode = 11 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		@Override
		public boolean hasCropMode()
		{
			return ((bitField0_ & 0x00000400) == 0x00000400);
		}

		/**
		 * <code>optional string crop_mode = 11 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		@Override
		public java.lang.String getCropMode()
		{
			java.lang.Object ref = cropMode_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					cropMode_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string crop_mode = 11 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getCropModeBytes()
		{
			java.lang.Object ref = cropMode_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				cropMode_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		private void initFields()
		{
			source_ = "";
			scale_ = 1F;
			meanFile_ = "";
			batchSize_ = 0;
			cropSize_ = 0;
			mirror_ = false;
			fgThreshold_ = 0.5F;
			bgThreshold_ = 0.5F;
			fgFraction_ = 0.25F;
			contextPad_ = 0;
			cropMode_ = "warp";
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeFloat(2, scale_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeBytes(3, getMeanFileBytes());
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeUInt32(4, batchSize_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeUInt32(5, cropSize_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeBool(6, mirror_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeFloat(7, fgThreshold_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeFloat(8, bgThreshold_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeFloat(9, fgFraction_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeUInt32(10, contextPad_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				output.writeBytes(11, getCropModeBytes());
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getSourceBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(2, scale_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(3, getMeanFileBytes());
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(4, batchSize_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(5, cropSize_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(6, mirror_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(7, fgThreshold_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(8, bgThreshold_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(9, fgFraction_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(10, contextPad_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(11, getCropModeBytes());
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.WindowDataParameter}
		 *
		 * <pre>
		 * Message that stores parameters used by WindowDataLayer
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.WindowDataParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_WindowDataParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_WindowDataParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.class,
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				source_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				scale_ = 1F;
				bitField0_ = (bitField0_ & ~0x00000002);
				meanFile_ = "";
				bitField0_ = (bitField0_ & ~0x00000004);
				batchSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000008);
				cropSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000010);
				mirror_ = false;
				bitField0_ = (bitField0_ & ~0x00000020);
				fgThreshold_ = 0.5F;
				bitField0_ = (bitField0_ & ~0x00000040);
				bgThreshold_ = 0.5F;
				bitField0_ = (bitField0_ & ~0x00000080);
				fgFraction_ = 0.25F;
				bitField0_ = (bitField0_ & ~0x00000100);
				contextPad_ = 0;
				bitField0_ = (bitField0_ & ~0x00000200);
				cropMode_ = "warp";
				bitField0_ = (bitField0_ & ~0x00000400);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_WindowDataParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter(this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.source_ = source_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.scale_ = scale_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.meanFile_ = meanFile_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.batchSize_ = batchSize_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				result.cropSize_ = cropSize_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				result.mirror_ = mirror_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.fgThreshold_ = fgThreshold_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.bgThreshold_ = bgThreshold_;
				if (((from_bitField0_ & 0x00000100) == 0x00000100))
				{
					to_bitField0_ |= 0x00000100;
				}
				result.fgFraction_ = fgFraction_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200))
				{
					to_bitField0_ |= 0x00000200;
				}
				result.contextPad_ = contextPad_;
				if (((from_bitField0_ & 0x00000400) == 0x00000400))
				{
					to_bitField0_ |= 0x00000400;
				}
				result.cropMode_ = cropMode_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter.getDefaultInstance())
					return this;
				if (other.hasSource())
				{
					bitField0_ |= 0x00000001;
					source_ = other.source_;
					onChanged();
				}
				if (other.hasScale())
				{
					setScale(other.getScale());
				}
				if (other.hasMeanFile())
				{
					bitField0_ |= 0x00000004;
					meanFile_ = other.meanFile_;
					onChanged();
				}
				if (other.hasBatchSize())
				{
					setBatchSize(other.getBatchSize());
				}
				if (other.hasCropSize())
				{
					setCropSize(other.getCropSize());
				}
				if (other.hasMirror())
				{
					setMirror(other.getMirror());
				}
				if (other.hasFgThreshold())
				{
					setFgThreshold(other.getFgThreshold());
				}
				if (other.hasBgThreshold())
				{
					setBgThreshold(other.getBgThreshold());
				}
				if (other.hasFgFraction())
				{
					setFgFraction(other.getFgFraction());
				}
				if (other.hasContextPad())
				{
					setContextPad(other.getContextPad());
				}
				if (other.hasCropMode())
				{
					bitField0_ |= 0x00000400;
					cropMode_ = other.cropMode_;
					onChanged();
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.WindowDataParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			private java.lang.Object source_ = "";

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public boolean hasSource()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public java.lang.String getSource()
			{
				java.lang.Object ref = source_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						source_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSourceBytes()
			{
				java.lang.Object ref = source_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					source_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSource(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder clearSource()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				source_ = getDefaultInstance().getSource();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 1;</code>
			 *
			 * <pre>
			 * Specify the data source.
			 * </pre>
			 */
			public Builder setSourceBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				source_ = value;
				onChanged();
				return this;
			}

			private float scale_ = 1F;

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			@Override
			public boolean hasScale()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			@Override
			public float getScale()
			{
				return scale_;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			public Builder setScale(float value)
			{
				bitField0_ |= 0x00000002;
				scale_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float scale = 2 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			public Builder clearScale()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				scale_ = 1F;
				onChanged();
				return this;
			}

			private java.lang.Object meanFile_ = "";

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public boolean hasMeanFile()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public java.lang.String getMeanFile()
			{
				java.lang.Object ref = meanFile_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						meanFile_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getMeanFileBytes()
			{
				java.lang.Object ref = meanFile_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					meanFile_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder setMeanFile(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				meanFile_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder clearMeanFile()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				meanFile_ = getDefaultInstance().getMeanFile();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string mean_file = 3;</code>
			 */
			public Builder setMeanFileBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				meanFile_ = value;
				onChanged();
				return this;
			}

			private int batchSize_;

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public boolean hasBatchSize()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			@Override
			public int getBatchSize()
			{
				return batchSize_;
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder setBatchSize(int value)
			{
				bitField0_ |= 0x00000008;
				batchSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 batch_size = 4;</code>
			 *
			 * <pre>
			 * Specify the batch size.
			 * </pre>
			 */
			public Builder clearBatchSize()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				batchSize_ = 0;
				onChanged();
				return this;
			}

			private int cropSize_;

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			@Override
			public boolean hasCropSize()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			@Override
			public int getCropSize()
			{
				return cropSize_;
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			public Builder setCropSize(int value)
			{
				bitField0_ |= 0x00000010;
				cropSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 crop_size = 5 [default = 0];</code>
			 *
			 * <pre>
			 * Specify if we would like to randomly crop an image.
			 * </pre>
			 */
			public Builder clearCropSize()
			{
				bitField0_ = (bitField0_ & ~0x00000010);
				cropSize_ = 0;
				onChanged();
				return this;
			}

			private boolean mirror_;

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			@Override
			public boolean hasMirror()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			@Override
			public boolean getMirror()
			{
				return mirror_;
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			public Builder setMirror(boolean value)
			{
				bitField0_ |= 0x00000020;
				mirror_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool mirror = 6 [default = false];</code>
			 *
			 * <pre>
			 * Specify if we want to randomly mirror data.
			 * </pre>
			 */
			public Builder clearMirror()
			{
				bitField0_ = (bitField0_ & ~0x00000020);
				mirror_ = false;
				onChanged();
				return this;
			}

			private float fgThreshold_ = 0.5F;

			/**
			 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
			 *
			 * <pre>
			 * Foreground (object) overlap threshold
			 * </pre>
			 */
			@Override
			public boolean hasFgThreshold()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
			 *
			 * <pre>
			 * Foreground (object) overlap threshold
			 * </pre>
			 */
			@Override
			public float getFgThreshold()
			{
				return fgThreshold_;
			}

			/**
			 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
			 *
			 * <pre>
			 * Foreground (object) overlap threshold
			 * </pre>
			 */
			public Builder setFgThreshold(float value)
			{
				bitField0_ |= 0x00000040;
				fgThreshold_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float fg_threshold = 7 [default = 0.5];</code>
			 *
			 * <pre>
			 * Foreground (object) overlap threshold
			 * </pre>
			 */
			public Builder clearFgThreshold()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				fgThreshold_ = 0.5F;
				onChanged();
				return this;
			}

			private float bgThreshold_ = 0.5F;

			/**
			 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
			 *
			 * <pre>
			 * Background (non-object) overlap threshold
			 * </pre>
			 */
			@Override
			public boolean hasBgThreshold()
			{
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
			 *
			 * <pre>
			 * Background (non-object) overlap threshold
			 * </pre>
			 */
			@Override
			public float getBgThreshold()
			{
				return bgThreshold_;
			}

			/**
			 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
			 *
			 * <pre>
			 * Background (non-object) overlap threshold
			 * </pre>
			 */
			public Builder setBgThreshold(float value)
			{
				bitField0_ |= 0x00000080;
				bgThreshold_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float bg_threshold = 8 [default = 0.5];</code>
			 *
			 * <pre>
			 * Background (non-object) overlap threshold
			 * </pre>
			 */
			public Builder clearBgThreshold()
			{
				bitField0_ = (bitField0_ & ~0x00000080);
				bgThreshold_ = 0.5F;
				onChanged();
				return this;
			}

			private float fgFraction_ = 0.25F;

			/**
			 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			@Override
			public boolean hasFgFraction()
			{
				return ((bitField0_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			@Override
			public float getFgFraction()
			{
				return fgFraction_;
			}

			/**
			 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			public Builder setFgFraction(float value)
			{
				bitField0_ |= 0x00000100;
				fgFraction_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float fg_fraction = 9 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			public Builder clearFgFraction()
			{
				bitField0_ = (bitField0_ & ~0x00000100);
				fgFraction_ = 0.25F;
				onChanged();
				return this;
			}

			private int contextPad_;

			/**
			 * <code>optional uint32 context_pad = 10 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			@Override
			public boolean hasContextPad()
			{
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional uint32 context_pad = 10 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			@Override
			public int getContextPad()
			{
				return contextPad_;
			}

			/**
			 * <code>optional uint32 context_pad = 10 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			public Builder setContextPad(int value)
			{
				bitField0_ |= 0x00000200;
				contextPad_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 context_pad = 10 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			public Builder clearContextPad()
			{
				bitField0_ = (bitField0_ & ~0x00000200);
				contextPad_ = 0;
				onChanged();
				return this;
			}

			private java.lang.Object cropMode_ = "warp";

			/**
			 * <code>optional string crop_mode = 11 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			@Override
			public boolean hasCropMode()
			{
				return ((bitField0_ & 0x00000400) == 0x00000400);
			}

			/**
			 * <code>optional string crop_mode = 11 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			@Override
			public java.lang.String getCropMode()
			{
				java.lang.Object ref = cropMode_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						cropMode_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string crop_mode = 11 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getCropModeBytes()
			{
				java.lang.Object ref = cropMode_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					cropMode_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string crop_mode = 11 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			public Builder setCropMode(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000400;
				cropMode_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string crop_mode = 11 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			public Builder clearCropMode()
			{
				bitField0_ = (bitField0_ & ~0x00000400);
				cropMode_ = getDefaultInstance().getCropMode();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string crop_mode = 11 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			public Builder setCropModeBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000400;
				cropMode_ = value;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:caffe.WindowDataParameter)
		}

		static
		{
			defaultInstance = new WindowDataParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)
	}

	public interface V0LayerParameterOrBuilder extends
			// @@protoc_insertion_point(interface_extends:caffe.V0LayerParameter)
			com.google.protobuf.MessageOrBuilder
	{

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		boolean hasName();

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		java.lang.String getName();

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getNameBytes();

		/**
		 * <code>optional string type = 2;</code>
		 *
		 * <pre>
		 * the string to specify the layer type
		 * </pre>
		 */
		boolean hasType();

		/**
		 * <code>optional string type = 2;</code>
		 *
		 * <pre>
		 * the string to specify the layer type
		 * </pre>
		 */
		java.lang.String getType();

		/**
		 * <code>optional string type = 2;</code>
		 *
		 * <pre>
		 * the string to specify the layer type
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getTypeBytes();

		/**
		 * <code>optional uint32 num_output = 3;</code>
		 *
		 * <pre>
		 * Parameters to specify layers with inner products.
		 * </pre>
		 */
		boolean hasNumOutput();

		/**
		 * <code>optional uint32 num_output = 3;</code>
		 *
		 * <pre>
		 * Parameters to specify layers with inner products.
		 * </pre>
		 */
		int getNumOutput();

		/**
		 * <code>optional bool biasterm = 4 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		boolean hasBiasterm();

		/**
		 * <code>optional bool biasterm = 4 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		boolean getBiasterm();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		boolean hasWeightFiller();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller();

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		boolean hasBiasFiller();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller();

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder();

		/**
		 * <code>optional uint32 pad = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The padding size
		 * </pre>
		 */
		boolean hasPad();

		/**
		 * <code>optional uint32 pad = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The padding size
		 * </pre>
		 */
		int getPad();

		/**
		 * <code>optional uint32 kernelsize = 8;</code>
		 *
		 * <pre>
		 * The kernel size
		 * </pre>
		 */
		boolean hasKernelsize();

		/**
		 * <code>optional uint32 kernelsize = 8;</code>
		 *
		 * <pre>
		 * The kernel size
		 * </pre>
		 */
		int getKernelsize();

		/**
		 * <code>optional uint32 group = 9 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		boolean hasGroup();

		/**
		 * <code>optional uint32 group = 9 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		int getGroup();

		/**
		 * <code>optional uint32 stride = 10 [default = 1];</code>
		 *
		 * <pre>
		 * The stride
		 * </pre>
		 */
		boolean hasStride();

		/**
		 * <code>optional uint32 stride = 10 [default = 1];</code>
		 *
		 * <pre>
		 * The stride
		 * </pre>
		 */
		int getStride();

		/**
		 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		boolean hasPool();

		/**
		 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod getPool();

		/**
		 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		boolean hasDropoutRatio();

		/**
		 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		float getDropoutRatio();

		/**
		 * <code>optional uint32 local_size = 13 [default = 5];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		boolean hasLocalSize();

		/**
		 * <code>optional uint32 local_size = 13 [default = 5];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		int getLocalSize();

		/**
		 * <code>optional float alpha = 14 [default = 1];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		boolean hasAlpha();

		/**
		 * <code>optional float alpha = 14 [default = 1];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		float getAlpha();

		/**
		 * <code>optional float beta = 15 [default = 0.75];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		boolean hasBeta();

		/**
		 * <code>optional float beta = 15 [default = 0.75];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		float getBeta();

		/**
		 * <code>optional string source = 16;</code>
		 *
		 * <pre>
		 * For data layers, specify the data source
		 * </pre>
		 */
		boolean hasSource();

		/**
		 * <code>optional string source = 16;</code>
		 *
		 * <pre>
		 * For data layers, specify the data source
		 * </pre>
		 */
		java.lang.String getSource();

		/**
		 * <code>optional string source = 16;</code>
		 *
		 * <pre>
		 * For data layers, specify the data source
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getSourceBytes();

		/**
		 * <code>optional float scale = 17 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		boolean hasScale();

		/**
		 * <code>optional float scale = 17 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		float getScale();

		/**
		 * <code>optional string meanfile = 18;</code>
		 */
		boolean hasMeanfile();

		/**
		 * <code>optional string meanfile = 18;</code>
		 */
		java.lang.String getMeanfile();

		/**
		 * <code>optional string meanfile = 18;</code>
		 */
		com.google.protobuf.ByteString
				getMeanfileBytes();

		/**
		 * <code>optional uint32 batchsize = 19;</code>
		 *
		 * <pre>
		 * For data layers, specify the batch size.
		 * </pre>
		 */
		boolean hasBatchsize();

		/**
		 * <code>optional uint32 batchsize = 19;</code>
		 *
		 * <pre>
		 * For data layers, specify the batch size.
		 * </pre>
		 */
		int getBatchsize();

		/**
		 * <code>optional uint32 cropsize = 20 [default = 0];</code>
		 *
		 * <pre>
		 * For data layers, specify if we would like to randomly crop an image.
		 * </pre>
		 */
		boolean hasCropsize();

		/**
		 * <code>optional uint32 cropsize = 20 [default = 0];</code>
		 *
		 * <pre>
		 * For data layers, specify if we would like to randomly crop an image.
		 * </pre>
		 */
		int getCropsize();

		/**
		 * <code>optional bool mirror = 21 [default = false];</code>
		 *
		 * <pre>
		 * For data layers, specify if we want to randomly mirror data.
		 * </pre>
		 */
		boolean hasMirror();

		/**
		 * <code>optional bool mirror = 21 [default = false];</code>
		 *
		 * <pre>
		 * For data layers, specify if we want to randomly mirror data.
		 * </pre>
		 */
		boolean getMirror();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>
				getBlobsList();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index);

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		int getBlobsCount();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getBlobsOrBuilderList();

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
				int index);

		/**
		 * <code>repeated float blobs_lr = 51;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		java.util.List<java.lang.Float> getBlobsLrList();

		/**
		 * <code>repeated float blobs_lr = 51;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		int getBlobsLrCount();

		/**
		 * <code>repeated float blobs_lr = 51;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		float getBlobsLr(int index);

		/**
		 * <code>repeated float weight_decay = 52;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		java.util.List<java.lang.Float> getWeightDecayList();

		/**
		 * <code>repeated float weight_decay = 52;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		int getWeightDecayCount();

		/**
		 * <code>repeated float weight_decay = 52;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		float getWeightDecay(int index);

		/**
		 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		boolean hasRandSkip();

		/**
		 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		int getRandSkip();

		/**
		 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
		 *
		 * <pre>
		 * Fields related to detection (det_*)
		 * foreground (object) overlap threshold
		 * </pre>
		 */
		boolean hasDetFgThreshold();

		/**
		 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
		 *
		 * <pre>
		 * Fields related to detection (det_*)
		 * foreground (object) overlap threshold
		 * </pre>
		 */
		float getDetFgThreshold();

		/**
		 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
		 *
		 * <pre>
		 * background (non-object) overlap threshold
		 * </pre>
		 */
		boolean hasDetBgThreshold();

		/**
		 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
		 *
		 * <pre>
		 * background (non-object) overlap threshold
		 * </pre>
		 */
		float getDetBgThreshold();

		/**
		 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		boolean hasDetFgFraction();

		/**
		 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		float getDetFgFraction();

		/**
		 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		boolean hasDetContextPad();

		/**
		 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		int getDetContextPad();

		/**
		 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		boolean hasDetCropMode();

		/**
		 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		java.lang.String getDetCropMode();

		/**
		 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		com.google.protobuf.ByteString
				getDetCropModeBytes();

		/**
		 * <code>optional int32 new_num = 60 [default = 0];</code>
		 *
		 * <pre>
		 * For ReshapeLayer, one needs to specify the new dimensions.
		 * </pre>
		 */
		boolean hasNewNum();

		/**
		 * <code>optional int32 new_num = 60 [default = 0];</code>
		 *
		 * <pre>
		 * For ReshapeLayer, one needs to specify the new dimensions.
		 * </pre>
		 */
		int getNewNum();

		/**
		 * <code>optional int32 new_channels = 61 [default = 0];</code>
		 */
		boolean hasNewChannels();

		/**
		 * <code>optional int32 new_channels = 61 [default = 0];</code>
		 */
		int getNewChannels();

		/**
		 * <code>optional int32 new_height = 62 [default = 0];</code>
		 */
		boolean hasNewHeight();

		/**
		 * <code>optional int32 new_height = 62 [default = 0];</code>
		 */
		int getNewHeight();

		/**
		 * <code>optional int32 new_width = 63 [default = 0];</code>
		 */
		boolean hasNewWidth();

		/**
		 * <code>optional int32 new_width = 63 [default = 0];</code>
		 */
		int getNewWidth();

		/**
		 * <code>optional bool shuffle_images = 64 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		boolean hasShuffleImages();

		/**
		 * <code>optional bool shuffle_images = 64 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		boolean getShuffleImages();

		/**
		 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
		 *
		 * <pre>
		 * For ConcatLayer, one needs to specify the dimension for concatenation, and
		 * the other dimensions must be the same for all the bottom blobs.
		 * By default it will concatenate blobs along the channels dimension.
		 * </pre>
		 */
		boolean hasConcatDim();

		/**
		 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
		 *
		 * <pre>
		 * For ConcatLayer, one needs to specify the dimension for concatenation, and
		 * the other dimensions must be the same for all the bottom blobs.
		 * By default it will concatenate blobs along the channels dimension.
		 * </pre>
		 */
		int getConcatDim();

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
		 */
		boolean hasHdf5OutputParam();

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getHdf5OutputParam();

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
		 */
		com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder getHdf5OutputParamOrBuilder();
	}

	/**
	 * Protobuf type {@code caffe.V0LayerParameter}
	 *
	 * <pre>
	 * DEPRECATED: V0LayerParameter is the old way of specifying layer parameters
	 * in Caffe.  We keep this message type around for legacy support.
	 * </pre>
	 */
	public static final class V0LayerParameter extends
			com.google.protobuf.GeneratedMessage implements
			// @@protoc_insertion_point(message_implements:caffe.V0LayerParameter)
			V0LayerParameterOrBuilder
	{
		// Use V0LayerParameter.newBuilder() to construct.
		private V0LayerParameter(com.google.protobuf.GeneratedMessage.Builder<?> builder)
		{
			super(builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private V0LayerParameter(boolean noInit)
		{
			this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
		}

		private static final V0LayerParameter defaultInstance;

		public static V0LayerParameter getDefaultInstance()
		{
			return defaultInstance;
		}

		@Override
		public V0LayerParameter getDefaultInstanceForType()
		{
			return defaultInstance;
		}

		private final com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final com.google.protobuf.UnknownFieldSet
				getUnknownFields()
		{
			return this.unknownFields;
		}

		private V0LayerParameter(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			initFields();
			int mutable_bitField0_ = 0;
			int mutable_bitField1_ = 0;
			com.google.protobuf.UnknownFieldSet.Builder unknownFields =
					com.google.protobuf.UnknownFieldSet.newBuilder();
			try
			{
				boolean done = false;
				while (!done)
				{
					int tag = input.readTag();
					switch (tag) {
					case 0:
						done = true;
						break;
					default:
					{
						if (!parseUnknownField(input, unknownFields,
								extensionRegistry, tag))
						{
							done = true;
						}
						break;
					}
					case 10:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000001;
						name_ = bs;
						break;
					}
					case 18:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00000002;
						type_ = bs;
						break;
					}
					case 24:
					{
						bitField0_ |= 0x00000004;
						numOutput_ = input.readUInt32();
						break;
					}
					case 32:
					{
						bitField0_ |= 0x00000008;
						biasterm_ = input.readBool();
						break;
					}
					case 42:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000010) == 0x00000010))
						{
							subBuilder = weightFiller_.toBuilder();
						}
						weightFiller_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(weightFiller_);
							weightFiller_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000010;
						break;
					}
					case 50:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder subBuilder = null;
						if (((bitField0_ & 0x00000020) == 0x00000020))
						{
							subBuilder = biasFiller_.toBuilder();
						}
						biasFiller_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(biasFiller_);
							biasFiller_ = subBuilder.buildPartial();
						}
						bitField0_ |= 0x00000020;
						break;
					}
					case 56:
					{
						bitField0_ |= 0x00000040;
						pad_ = input.readUInt32();
						break;
					}
					case 64:
					{
						bitField0_ |= 0x00000080;
						kernelsize_ = input.readUInt32();
						break;
					}
					case 72:
					{
						bitField0_ |= 0x00000100;
						group_ = input.readUInt32();
						break;
					}
					case 80:
					{
						bitField0_ |= 0x00000200;
						stride_ = input.readUInt32();
						break;
					}
					case 88:
					{
						int rawValue = input.readEnum();
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod value = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod
								.valueOf(rawValue);
						if (value == null)
						{
							unknownFields.mergeVarintField(11, rawValue);
						} else
						{
							bitField0_ |= 0x00000400;
							pool_ = value;
						}
						break;
					}
					case 101:
					{
						bitField0_ |= 0x00000800;
						dropoutRatio_ = input.readFloat();
						break;
					}
					case 104:
					{
						bitField0_ |= 0x00001000;
						localSize_ = input.readUInt32();
						break;
					}
					case 117:
					{
						bitField0_ |= 0x00002000;
						alpha_ = input.readFloat();
						break;
					}
					case 125:
					{
						bitField0_ |= 0x00004000;
						beta_ = input.readFloat();
						break;
					}
					case 130:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00008000;
						source_ = bs;
						break;
					}
					case 141:
					{
						bitField0_ |= 0x00010000;
						scale_ = input.readFloat();
						break;
					}
					case 146:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x00020000;
						meanfile_ = bs;
						break;
					}
					case 152:
					{
						bitField0_ |= 0x00040000;
						batchsize_ = input.readUInt32();
						break;
					}
					case 160:
					{
						bitField0_ |= 0x00080000;
						cropsize_ = input.readUInt32();
						break;
					}
					case 168:
					{
						bitField0_ |= 0x00100000;
						mirror_ = input.readBool();
						break;
					}
					case 402:
					{
						if (!((mutable_bitField0_ & 0x00200000) == 0x00200000))
						{
							blobs_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>();
							mutable_bitField0_ |= 0x00200000;
						}
						blobs_.add(input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.PARSER, extensionRegistry));
						break;
					}
					case 413:
					{
						if (!((mutable_bitField0_ & 0x00400000) == 0x00400000))
						{
							blobsLr_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00400000;
						}
						blobsLr_.add(input.readFloat());
						break;
					}
					case 410:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00400000) == 0x00400000) && input.getBytesUntilLimit() > 0)
						{
							blobsLr_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00400000;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							blobsLr_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 421:
					{
						if (!((mutable_bitField0_ & 0x00800000) == 0x00800000))
						{
							weightDecay_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00800000;
						}
						weightDecay_.add(input.readFloat());
						break;
					}
					case 418:
					{
						int length = input.readRawVarint32();
						int limit = input.pushLimit(length);
						if (!((mutable_bitField0_ & 0x00800000) == 0x00800000) && input.getBytesUntilLimit() > 0)
						{
							weightDecay_ = new java.util.ArrayList<java.lang.Float>();
							mutable_bitField0_ |= 0x00800000;
						}
						while (input.getBytesUntilLimit() > 0)
						{
							weightDecay_.add(input.readFloat());
						}
						input.popLimit(limit);
						break;
					}
					case 424:
					{
						bitField0_ |= 0x00200000;
						randSkip_ = input.readUInt32();
						break;
					}
					case 437:
					{
						bitField0_ |= 0x00400000;
						detFgThreshold_ = input.readFloat();
						break;
					}
					case 445:
					{
						bitField0_ |= 0x00800000;
						detBgThreshold_ = input.readFloat();
						break;
					}
					case 453:
					{
						bitField0_ |= 0x01000000;
						detFgFraction_ = input.readFloat();
						break;
					}
					case 464:
					{
						bitField0_ |= 0x02000000;
						detContextPad_ = input.readUInt32();
						break;
					}
					case 474:
					{
						com.google.protobuf.ByteString bs = input.readBytes();
						bitField0_ |= 0x04000000;
						detCropMode_ = bs;
						break;
					}
					case 480:
					{
						bitField0_ |= 0x08000000;
						newNum_ = input.readInt32();
						break;
					}
					case 488:
					{
						bitField0_ |= 0x10000000;
						newChannels_ = input.readInt32();
						break;
					}
					case 496:
					{
						bitField0_ |= 0x20000000;
						newHeight_ = input.readInt32();
						break;
					}
					case 504:
					{
						bitField0_ |= 0x40000000;
						newWidth_ = input.readInt32();
						break;
					}
					case 512:
					{
						bitField0_ |= 0x80000000;
						shuffleImages_ = input.readBool();
						break;
					}
					case 520:
					{
						bitField1_ |= 0x00000001;
						concatDim_ = input.readUInt32();
						break;
					}
					case 8010:
					{
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder subBuilder = null;
						if (((bitField1_ & 0x00000002) == 0x00000002))
						{
							subBuilder = hdf5OutputParam_.toBuilder();
						}
						hdf5OutputParam_ = input.readMessage(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.PARSER, extensionRegistry);
						if (subBuilder != null)
						{
							subBuilder.mergeFrom(hdf5OutputParam_);
							hdf5OutputParam_ = subBuilder.buildPartial();
						}
						bitField1_ |= 0x00000002;
						break;
					}
					}
				}
			} catch (com.google.protobuf.InvalidProtocolBufferException e)
			{
				throw e.setUnfinishedMessage(this);
			} catch (java.io.IOException e)
			{
				throw new com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			} finally
			{
				if (((mutable_bitField0_ & 0x00200000) == 0x00200000))
				{
					blobs_ = java.util.Collections.unmodifiableList(blobs_);
				}
				if (((mutable_bitField0_ & 0x00400000) == 0x00400000))
				{
					blobsLr_ = java.util.Collections.unmodifiableList(blobsLr_);
				}
				if (((mutable_bitField0_ & 0x00800000) == 0x00800000))
				{
					weightDecay_ = java.util.Collections.unmodifiableList(weightDecay_);
				}
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final com.google.protobuf.Descriptors.Descriptor
				getDescriptor()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_V0LayerParameter_descriptor;
		}

		@Override
		protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
				internalGetFieldAccessorTable()
		{
			return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_V0LayerParameter_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder.class);
		}

		public static com.google.protobuf.Parser<V0LayerParameter> PARSER =
				new com.google.protobuf.AbstractParser<V0LayerParameter>()
				{
					@Override
					public V0LayerParameter parsePartialFrom(
							com.google.protobuf.CodedInputStream input,
							com.google.protobuf.ExtensionRegistryLite extensionRegistry)
							throws com.google.protobuf.InvalidProtocolBufferException
					{
						return new V0LayerParameter(input, extensionRegistry);
					}
				};

		@java.lang.Override
		public com.google.protobuf.Parser<V0LayerParameter> getParserForType()
		{
			return PARSER;
		}

		/**
		 * Protobuf enum {@code caffe.V0LayerParameter.PoolMethod}
		 */
		public enum PoolMethod
				implements com.google.protobuf.ProtocolMessageEnum
		{
			/**
			 * <code>MAX = 0;</code>
			 */
			MAX(0, 0),
			/**
			 * <code>AVE = 1;</code>
			 */
			AVE(1, 1),
			/**
			 * <code>STOCHASTIC = 2;</code>
			 */
			STOCHASTIC(2, 2), ;

			/**
			 * <code>MAX = 0;</code>
			 */
			public static final int MAX_VALUE = 0;
			/**
			 * <code>AVE = 1;</code>
			 */
			public static final int AVE_VALUE = 1;
			/**
			 * <code>STOCHASTIC = 2;</code>
			 */
			public static final int STOCHASTIC_VALUE = 2;


			@Override
			public final int getNumber()
			{
				return value;
			}

			public static PoolMethod valueOf(int value)
			{
				switch (value) {
				case 0:
					return MAX;
				case 1:
					return AVE;
				case 2:
					return STOCHASTIC;
				default:
					return null;
				}
			}

			public static com.google.protobuf.Internal.EnumLiteMap<PoolMethod>
					internalGetValueMap()
			{
				return internalValueMap;
			}

			private static com.google.protobuf.Internal.EnumLiteMap<PoolMethod> internalValueMap =
					new com.google.protobuf.Internal.EnumLiteMap<PoolMethod>()
					{
						@Override
						public PoolMethod findValueByNumber(int number)
						{
							return PoolMethod.valueOf(number);
						}
					};

			@Override
			public final com.google.protobuf.Descriptors.EnumValueDescriptor
					getValueDescriptor()
			{
				return getDescriptor().getValues().get(index);
			}

			@Override
			public final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptorForType()
			{
				return getDescriptor();
			}

			public static final com.google.protobuf.Descriptors.EnumDescriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDescriptor().getEnumTypes().get(0);
			}

			private static final PoolMethod[] VALUES = values();

			public static PoolMethod valueOf(
					com.google.protobuf.Descriptors.EnumValueDescriptor desc)
			{
				if (desc.getType() != getDescriptor())
				{
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private PoolMethod(int index, int value)
			{
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:caffe.V0LayerParameter.PoolMethod)
		}

		private int bitField0_;
		private int bitField1_;
		public static final int NAME_FIELD_NUMBER = 1;
		private java.lang.Object name_;

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		@Override
		public boolean hasName()
		{
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		@Override
		public java.lang.String getName()
		{
			java.lang.Object ref = name_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					name_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string name = 1;</code>
		 *
		 * <pre>
		 * the layer name
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getNameBytes()
		{
			java.lang.Object ref = name_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				name_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int TYPE_FIELD_NUMBER = 2;
		private java.lang.Object type_;

		/**
		 * <code>optional string type = 2;</code>
		 *
		 * <pre>
		 * the string to specify the layer type
		 * </pre>
		 */
		@Override
		public boolean hasType()
		{
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional string type = 2;</code>
		 *
		 * <pre>
		 * the string to specify the layer type
		 * </pre>
		 */
		@Override
		public java.lang.String getType()
		{
			java.lang.Object ref = type_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					type_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string type = 2;</code>
		 *
		 * <pre>
		 * the string to specify the layer type
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getTypeBytes()
		{
			java.lang.Object ref = type_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				type_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int NUM_OUTPUT_FIELD_NUMBER = 3;
		private int numOutput_;

		/**
		 * <code>optional uint32 num_output = 3;</code>
		 *
		 * <pre>
		 * Parameters to specify layers with inner products.
		 * </pre>
		 */
		@Override
		public boolean hasNumOutput()
		{
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional uint32 num_output = 3;</code>
		 *
		 * <pre>
		 * Parameters to specify layers with inner products.
		 * </pre>
		 */
		@Override
		public int getNumOutput()
		{
			return numOutput_;
		}

		public static final int BIASTERM_FIELD_NUMBER = 4;
		private boolean biasterm_;

		/**
		 * <code>optional bool biasterm = 4 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		@Override
		public boolean hasBiasterm()
		{
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional bool biasterm = 4 [default = true];</code>
		 *
		 * <pre>
		 * whether to have bias terms
		 * </pre>
		 */
		@Override
		public boolean getBiasterm()
		{
			return biasterm_;
		}

		public static final int WEIGHT_FILLER_FIELD_NUMBER = 5;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter weightFiller_;

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public boolean hasWeightFiller()
		{
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller()
		{
			return weightFiller_;
		}

		/**
		 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
		 *
		 * <pre>
		 * The filler for the weight
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder()
		{
			return weightFiller_;
		}

		public static final int BIAS_FILLER_FIELD_NUMBER = 6;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter biasFiller_;

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public boolean hasBiasFiller()
		{
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller()
		{
			return biasFiller_;
		}

		/**
		 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
		 *
		 * <pre>
		 * The filler for the bias
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder()
		{
			return biasFiller_;
		}

		public static final int PAD_FIELD_NUMBER = 7;
		private int pad_;

		/**
		 * <code>optional uint32 pad = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The padding size
		 * </pre>
		 */
		@Override
		public boolean hasPad()
		{
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional uint32 pad = 7 [default = 0];</code>
		 *
		 * <pre>
		 * The padding size
		 * </pre>
		 */
		@Override
		public int getPad()
		{
			return pad_;
		}

		public static final int KERNELSIZE_FIELD_NUMBER = 8;
		private int kernelsize_;

		/**
		 * <code>optional uint32 kernelsize = 8;</code>
		 *
		 * <pre>
		 * The kernel size
		 * </pre>
		 */
		@Override
		public boolean hasKernelsize()
		{
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional uint32 kernelsize = 8;</code>
		 *
		 * <pre>
		 * The kernel size
		 * </pre>
		 */
		@Override
		public int getKernelsize()
		{
			return kernelsize_;
		}

		public static final int GROUP_FIELD_NUMBER = 9;
		private int group_;

		/**
		 * <code>optional uint32 group = 9 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		@Override
		public boolean hasGroup()
		{
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>optional uint32 group = 9 [default = 1];</code>
		 *
		 * <pre>
		 * The group size for group conv
		 * </pre>
		 */
		@Override
		public int getGroup()
		{
			return group_;
		}

		public static final int STRIDE_FIELD_NUMBER = 10;
		private int stride_;

		/**
		 * <code>optional uint32 stride = 10 [default = 1];</code>
		 *
		 * <pre>
		 * The stride
		 * </pre>
		 */
		@Override
		public boolean hasStride()
		{
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional uint32 stride = 10 [default = 1];</code>
		 *
		 * <pre>
		 * The stride
		 * </pre>
		 */
		@Override
		public int getStride()
		{
			return stride_;
		}

		public static final int POOL_FIELD_NUMBER = 11;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod pool_;

		/**
		 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		@Override
		public boolean hasPool()
		{
			return ((bitField0_ & 0x00000400) == 0x00000400);
		}

		/**
		 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
		 *
		 * <pre>
		 * The pooling method
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod getPool()
		{
			return pool_;
		}

		public static final int DROPOUT_RATIO_FIELD_NUMBER = 12;
		private float dropoutRatio_;

		/**
		 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		@Override
		public boolean hasDropoutRatio()
		{
			return ((bitField0_ & 0x00000800) == 0x00000800);
		}

		/**
		 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
		 *
		 * <pre>
		 * dropout ratio
		 * </pre>
		 */
		@Override
		public float getDropoutRatio()
		{
			return dropoutRatio_;
		}

		public static final int LOCAL_SIZE_FIELD_NUMBER = 13;
		private int localSize_;

		/**
		 * <code>optional uint32 local_size = 13 [default = 5];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		@Override
		public boolean hasLocalSize()
		{
			return ((bitField0_ & 0x00001000) == 0x00001000);
		}

		/**
		 * <code>optional uint32 local_size = 13 [default = 5];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		@Override
		public int getLocalSize()
		{
			return localSize_;
		}

		public static final int ALPHA_FIELD_NUMBER = 14;
		private float alpha_;

		/**
		 * <code>optional float alpha = 14 [default = 1];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		@Override
		public boolean hasAlpha()
		{
			return ((bitField0_ & 0x00002000) == 0x00002000);
		}

		/**
		 * <code>optional float alpha = 14 [default = 1];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		@Override
		public float getAlpha()
		{
			return alpha_;
		}

		public static final int BETA_FIELD_NUMBER = 15;
		private float beta_;

		/**
		 * <code>optional float beta = 15 [default = 0.75];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		@Override
		public boolean hasBeta()
		{
			return ((bitField0_ & 0x00004000) == 0x00004000);
		}

		/**
		 * <code>optional float beta = 15 [default = 0.75];</code>
		 *
		 * <pre>
		 * for local response norm
		 * </pre>
		 */
		@Override
		public float getBeta()
		{
			return beta_;
		}

		public static final int SOURCE_FIELD_NUMBER = 16;
		private java.lang.Object source_;

		/**
		 * <code>optional string source = 16;</code>
		 *
		 * <pre>
		 * For data layers, specify the data source
		 * </pre>
		 */
		@Override
		public boolean hasSource()
		{
			return ((bitField0_ & 0x00008000) == 0x00008000);
		}

		/**
		 * <code>optional string source = 16;</code>
		 *
		 * <pre>
		 * For data layers, specify the data source
		 * </pre>
		 */
		@Override
		public java.lang.String getSource()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					source_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string source = 16;</code>
		 *
		 * <pre>
		 * For data layers, specify the data source
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getSourceBytes()
		{
			java.lang.Object ref = source_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				source_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int SCALE_FIELD_NUMBER = 17;
		private float scale_;

		/**
		 * <code>optional float scale = 17 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		@Override
		public boolean hasScale()
		{
			return ((bitField0_ & 0x00010000) == 0x00010000);
		}

		/**
		 * <code>optional float scale = 17 [default = 1];</code>
		 *
		 * <pre>
		 * For data pre-processing, we can do simple scaling and subtracting the
		 * data mean, if provided. Note that the mean subtraction is always carried
		 * out before scaling.
		 * </pre>
		 */
		@Override
		public float getScale()
		{
			return scale_;
		}

		public static final int MEANFILE_FIELD_NUMBER = 18;
		private java.lang.Object meanfile_;

		/**
		 * <code>optional string meanfile = 18;</code>
		 */
		@Override
		public boolean hasMeanfile()
		{
			return ((bitField0_ & 0x00020000) == 0x00020000);
		}

		/**
		 * <code>optional string meanfile = 18;</code>
		 */
		@Override
		public java.lang.String getMeanfile()
		{
			java.lang.Object ref = meanfile_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					meanfile_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string meanfile = 18;</code>
		 */
		@Override
		public com.google.protobuf.ByteString
				getMeanfileBytes()
		{
			java.lang.Object ref = meanfile_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				meanfile_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int BATCHSIZE_FIELD_NUMBER = 19;
		private int batchsize_;

		/**
		 * <code>optional uint32 batchsize = 19;</code>
		 *
		 * <pre>
		 * For data layers, specify the batch size.
		 * </pre>
		 */
		@Override
		public boolean hasBatchsize()
		{
			return ((bitField0_ & 0x00040000) == 0x00040000);
		}

		/**
		 * <code>optional uint32 batchsize = 19;</code>
		 *
		 * <pre>
		 * For data layers, specify the batch size.
		 * </pre>
		 */
		@Override
		public int getBatchsize()
		{
			return batchsize_;
		}

		public static final int CROPSIZE_FIELD_NUMBER = 20;
		private int cropsize_;

		/**
		 * <code>optional uint32 cropsize = 20 [default = 0];</code>
		 *
		 * <pre>
		 * For data layers, specify if we would like to randomly crop an image.
		 * </pre>
		 */
		@Override
		public boolean hasCropsize()
		{
			return ((bitField0_ & 0x00080000) == 0x00080000);
		}

		/**
		 * <code>optional uint32 cropsize = 20 [default = 0];</code>
		 *
		 * <pre>
		 * For data layers, specify if we would like to randomly crop an image.
		 * </pre>
		 */
		@Override
		public int getCropsize()
		{
			return cropsize_;
		}

		public static final int MIRROR_FIELD_NUMBER = 21;
		private boolean mirror_;

		/**
		 * <code>optional bool mirror = 21 [default = false];</code>
		 *
		 * <pre>
		 * For data layers, specify if we want to randomly mirror data.
		 * </pre>
		 */
		@Override
		public boolean hasMirror()
		{
			return ((bitField0_ & 0x00100000) == 0x00100000);
		}

		/**
		 * <code>optional bool mirror = 21 [default = false];</code>
		 *
		 * <pre>
		 * For data layers, specify if we want to randomly mirror data.
		 * </pre>
		 */
		@Override
		public boolean getMirror()
		{
			return mirror_;
		}

		public static final int BLOBS_FIELD_NUMBER = 50;
		private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> blobs_;

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getBlobsList()
		{
			return blobs_;
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
				getBlobsOrBuilderList()
		{
			return blobs_;
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public int getBlobsCount()
		{
			return blobs_.size();
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index)
		{
			return blobs_.get(index);
		}

		/**
		 * <code>repeated .caffe.BlobProto blobs = 50;</code>
		 *
		 * <pre>
		 * The blobs containing the numeric parameters of the layer
		 * </pre>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
				int index)
		{
			return blobs_.get(index);
		}

		public static final int BLOBS_LR_FIELD_NUMBER = 51;
		private java.util.List<java.lang.Float> blobsLr_;

		/**
		 * <code>repeated float blobs_lr = 51;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getBlobsLrList()
		{
			return blobsLr_;
		}

		/**
		 * <code>repeated float blobs_lr = 51;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		@Override
		public int getBlobsLrCount()
		{
			return blobsLr_.size();
		}

		/**
		 * <code>repeated float blobs_lr = 51;</code>
		 *
		 * <pre>
		 * The ratio that is multiplied on the global learning rate. If you want to
		 * set the learning ratio for one blob, you need to set it for all blobs.
		 * </pre>
		 */
		@Override
		public float getBlobsLr(int index)
		{
			return blobsLr_.get(index);
		}

		public static final int WEIGHT_DECAY_FIELD_NUMBER = 52;
		private java.util.List<java.lang.Float> weightDecay_;

		/**
		 * <code>repeated float weight_decay = 52;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		@Override
		public java.util.List<java.lang.Float>
				getWeightDecayList()
		{
			return weightDecay_;
		}

		/**
		 * <code>repeated float weight_decay = 52;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		@Override
		public int getWeightDecayCount()
		{
			return weightDecay_.size();
		}

		/**
		 * <code>repeated float weight_decay = 52;</code>
		 *
		 * <pre>
		 * The weight decay that is multiplied on the global weight decay.
		 * </pre>
		 */
		@Override
		public float getWeightDecay(int index)
		{
			return weightDecay_.get(index);
		}

		public static final int RAND_SKIP_FIELD_NUMBER = 53;
		private int randSkip_;

		/**
		 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		@Override
		public boolean hasRandSkip()
		{
			return ((bitField0_ & 0x00200000) == 0x00200000);
		}

		/**
		 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
		 *
		 * <pre>
		 * The rand_skip variable is for the data layer to skip a few data points
		 * to avoid all asynchronous sgd clients to start at the same point. The skip
		 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
		 * be larger than the number of keys in the leveldb.
		 * </pre>
		 */
		@Override
		public int getRandSkip()
		{
			return randSkip_;
		}

		public static final int DET_FG_THRESHOLD_FIELD_NUMBER = 54;
		private float detFgThreshold_;

		/**
		 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
		 *
		 * <pre>
		 * Fields related to detection (det_*)
		 * foreground (object) overlap threshold
		 * </pre>
		 */
		@Override
		public boolean hasDetFgThreshold()
		{
			return ((bitField0_ & 0x00400000) == 0x00400000);
		}

		/**
		 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
		 *
		 * <pre>
		 * Fields related to detection (det_*)
		 * foreground (object) overlap threshold
		 * </pre>
		 */
		@Override
		public float getDetFgThreshold()
		{
			return detFgThreshold_;
		}

		public static final int DET_BG_THRESHOLD_FIELD_NUMBER = 55;
		private float detBgThreshold_;

		/**
		 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
		 *
		 * <pre>
		 * background (non-object) overlap threshold
		 * </pre>
		 */
		@Override
		public boolean hasDetBgThreshold()
		{
			return ((bitField0_ & 0x00800000) == 0x00800000);
		}

		/**
		 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
		 *
		 * <pre>
		 * background (non-object) overlap threshold
		 * </pre>
		 */
		@Override
		public float getDetBgThreshold()
		{
			return detBgThreshold_;
		}

		public static final int DET_FG_FRACTION_FIELD_NUMBER = 56;
		private float detFgFraction_;

		/**
		 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		@Override
		public boolean hasDetFgFraction()
		{
			return ((bitField0_ & 0x01000000) == 0x01000000);
		}

		/**
		 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
		 *
		 * <pre>
		 * Fraction of batch that should be foreground objects
		 * </pre>
		 */
		@Override
		public float getDetFgFraction()
		{
			return detFgFraction_;
		}

		public static final int DET_CONTEXT_PAD_FIELD_NUMBER = 58;
		private int detContextPad_;

		/**
		 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		@Override
		public boolean hasDetContextPad()
		{
			return ((bitField0_ & 0x02000000) == 0x02000000);
		}

		/**
		 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
		 *
		 * <pre>
		 * Amount of contextual padding to add around a window
		 * (used only by the window_data_layer)
		 * </pre>
		 */
		@Override
		public int getDetContextPad()
		{
			return detContextPad_;
		}

		public static final int DET_CROP_MODE_FIELD_NUMBER = 59;
		private java.lang.Object detCropMode_;

		/**
		 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		@Override
		public boolean hasDetCropMode()
		{
			return ((bitField0_ & 0x04000000) == 0x04000000);
		}

		/**
		 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		@Override
		public java.lang.String getDetCropMode()
		{
			java.lang.Object ref = detCropMode_;
			if (ref instanceof java.lang.String)
			{
				return (java.lang.String) ref;
			} else
			{
				com.google.protobuf.ByteString bs =
						(com.google.protobuf.ByteString) ref;
				java.lang.String s = bs.toStringUtf8();
				if (bs.isValidUtf8())
				{
					detCropMode_ = s;
				}
				return s;
			}
		}

		/**
		 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
		 *
		 * <pre>
		 * Mode for cropping out a detection window
		 * warp: cropped window is warped to a fixed size and aspect ratio
		 * square: the tightest square around the window is cropped
		 * </pre>
		 */
		@Override
		public com.google.protobuf.ByteString
				getDetCropModeBytes()
		{
			java.lang.Object ref = detCropMode_;
			if (ref instanceof java.lang.String)
			{
				com.google.protobuf.ByteString b =
						com.google.protobuf.ByteString.copyFromUtf8(
								(java.lang.String) ref);
				detCropMode_ = b;
				return b;
			} else
			{
				return (com.google.protobuf.ByteString) ref;
			}
		}

		public static final int NEW_NUM_FIELD_NUMBER = 60;
		private int newNum_;

		/**
		 * <code>optional int32 new_num = 60 [default = 0];</code>
		 *
		 * <pre>
		 * For ReshapeLayer, one needs to specify the new dimensions.
		 * </pre>
		 */
		@Override
		public boolean hasNewNum()
		{
			return ((bitField0_ & 0x08000000) == 0x08000000);
		}

		/**
		 * <code>optional int32 new_num = 60 [default = 0];</code>
		 *
		 * <pre>
		 * For ReshapeLayer, one needs to specify the new dimensions.
		 * </pre>
		 */
		@Override
		public int getNewNum()
		{
			return newNum_;
		}

		public static final int NEW_CHANNELS_FIELD_NUMBER = 61;
		private int newChannels_;

		/**
		 * <code>optional int32 new_channels = 61 [default = 0];</code>
		 */
		@Override
		public boolean hasNewChannels()
		{
			return ((bitField0_ & 0x10000000) == 0x10000000);
		}

		/**
		 * <code>optional int32 new_channels = 61 [default = 0];</code>
		 */
		@Override
		public int getNewChannels()
		{
			return newChannels_;
		}

		public static final int NEW_HEIGHT_FIELD_NUMBER = 62;
		private int newHeight_;

		/**
		 * <code>optional int32 new_height = 62 [default = 0];</code>
		 */
		@Override
		public boolean hasNewHeight()
		{
			return ((bitField0_ & 0x20000000) == 0x20000000);
		}

		/**
		 * <code>optional int32 new_height = 62 [default = 0];</code>
		 */
		@Override
		public int getNewHeight()
		{
			return newHeight_;
		}

		public static final int NEW_WIDTH_FIELD_NUMBER = 63;
		private int newWidth_;

		/**
		 * <code>optional int32 new_width = 63 [default = 0];</code>
		 */
		@Override
		public boolean hasNewWidth()
		{
			return ((bitField0_ & 0x40000000) == 0x40000000);
		}

		/**
		 * <code>optional int32 new_width = 63 [default = 0];</code>
		 */
		@Override
		public int getNewWidth()
		{
			return newWidth_;
		}

		public static final int SHUFFLE_IMAGES_FIELD_NUMBER = 64;
		private boolean shuffleImages_;

		/**
		 * <code>optional bool shuffle_images = 64 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		@Override
		public boolean hasShuffleImages()
		{
			return ((bitField0_ & 0x80000000) == 0x80000000);
		}

		/**
		 * <code>optional bool shuffle_images = 64 [default = false];</code>
		 *
		 * <pre>
		 * Whether or not ImageLayer should shuffle the list of files at every epoch.
		 * It will also resize images if new_height or new_width are not zero.
		 * </pre>
		 */
		@Override
		public boolean getShuffleImages()
		{
			return shuffleImages_;
		}

		public static final int CONCAT_DIM_FIELD_NUMBER = 65;
		private int concatDim_;

		/**
		 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
		 *
		 * <pre>
		 * For ConcatLayer, one needs to specify the dimension for concatenation, and
		 * the other dimensions must be the same for all the bottom blobs.
		 * By default it will concatenate blobs along the channels dimension.
		 * </pre>
		 */
		@Override
		public boolean hasConcatDim()
		{
			return ((bitField1_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
		 *
		 * <pre>
		 * For ConcatLayer, one needs to specify the dimension for concatenation, and
		 * the other dimensions must be the same for all the bottom blobs.
		 * By default it will concatenate blobs along the channels dimension.
		 * </pre>
		 */
		@Override
		public int getConcatDim()
		{
			return concatDim_;
		}

		public static final int HDF5_OUTPUT_PARAM_FIELD_NUMBER = 1001;
		private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter hdf5OutputParam_;

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
		 */
		@Override
		public boolean hasHdf5OutputParam()
		{
			return ((bitField1_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getHdf5OutputParam()
		{
			return hdf5OutputParam_;
		}

		/**
		 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
		 */
		@Override
		public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder getHdf5OutputParamOrBuilder()
		{
			return hdf5OutputParam_;
		}

		private void initFields()
		{
			name_ = "";
			type_ = "";
			numOutput_ = 0;
			biasterm_ = true;
			weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
			biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
			pad_ = 0;
			kernelsize_ = 0;
			group_ = 1;
			stride_ = 1;
			pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod.MAX;
			dropoutRatio_ = 0.5F;
			localSize_ = 5;
			alpha_ = 1F;
			beta_ = 0.75F;
			source_ = "";
			scale_ = 1F;
			meanfile_ = "";
			batchsize_ = 0;
			cropsize_ = 0;
			mirror_ = false;
			blobs_ = java.util.Collections.emptyList();
			blobsLr_ = java.util.Collections.emptyList();
			weightDecay_ = java.util.Collections.emptyList();
			randSkip_ = 0;
			detFgThreshold_ = 0.5F;
			detBgThreshold_ = 0.5F;
			detFgFraction_ = 0.25F;
			detContextPad_ = 0;
			detCropMode_ = "warp";
			newNum_ = 0;
			newChannels_ = 0;
			newHeight_ = 0;
			newWidth_ = 0;
			shuffleImages_ = false;
			concatDim_ = 1;
			hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
		}

		private byte memoizedIsInitialized = -1;

		@Override
		public final boolean isInitialized()
		{
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized == 1)
				return true;
			if (isInitialized == 0)
				return false;

			memoizedIsInitialized = 1;
			return true;
		}

		@Override
		public void writeTo(com.google.protobuf.CodedOutputStream output)
				throws java.io.IOException
		{
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				output.writeBytes(1, getNameBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				output.writeBytes(2, getTypeBytes());
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				output.writeUInt32(3, numOutput_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				output.writeBool(4, biasterm_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				output.writeMessage(5, weightFiller_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				output.writeMessage(6, biasFiller_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				output.writeUInt32(7, pad_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				output.writeUInt32(8, kernelsize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				output.writeUInt32(9, group_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				output.writeUInt32(10, stride_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				output.writeEnum(11, pool_.getNumber());
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				output.writeFloat(12, dropoutRatio_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				output.writeUInt32(13, localSize_);
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				output.writeFloat(14, alpha_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				output.writeFloat(15, beta_);
			}
			if (((bitField0_ & 0x00008000) == 0x00008000))
			{
				output.writeBytes(16, getSourceBytes());
			}
			if (((bitField0_ & 0x00010000) == 0x00010000))
			{
				output.writeFloat(17, scale_);
			}
			if (((bitField0_ & 0x00020000) == 0x00020000))
			{
				output.writeBytes(18, getMeanfileBytes());
			}
			if (((bitField0_ & 0x00040000) == 0x00040000))
			{
				output.writeUInt32(19, batchsize_);
			}
			if (((bitField0_ & 0x00080000) == 0x00080000))
			{
				output.writeUInt32(20, cropsize_);
			}
			if (((bitField0_ & 0x00100000) == 0x00100000))
			{
				output.writeBool(21, mirror_);
			}
			for (int i = 0; i < blobs_.size(); i++)
			{
				output.writeMessage(50, blobs_.get(i));
			}
			for (int i = 0; i < blobsLr_.size(); i++)
			{
				output.writeFloat(51, blobsLr_.get(i));
			}
			for (int i = 0; i < weightDecay_.size(); i++)
			{
				output.writeFloat(52, weightDecay_.get(i));
			}
			if (((bitField0_ & 0x00200000) == 0x00200000))
			{
				output.writeUInt32(53, randSkip_);
			}
			if (((bitField0_ & 0x00400000) == 0x00400000))
			{
				output.writeFloat(54, detFgThreshold_);
			}
			if (((bitField0_ & 0x00800000) == 0x00800000))
			{
				output.writeFloat(55, detBgThreshold_);
			}
			if (((bitField0_ & 0x01000000) == 0x01000000))
			{
				output.writeFloat(56, detFgFraction_);
			}
			if (((bitField0_ & 0x02000000) == 0x02000000))
			{
				output.writeUInt32(58, detContextPad_);
			}
			if (((bitField0_ & 0x04000000) == 0x04000000))
			{
				output.writeBytes(59, getDetCropModeBytes());
			}
			if (((bitField0_ & 0x08000000) == 0x08000000))
			{
				output.writeInt32(60, newNum_);
			}
			if (((bitField0_ & 0x10000000) == 0x10000000))
			{
				output.writeInt32(61, newChannels_);
			}
			if (((bitField0_ & 0x20000000) == 0x20000000))
			{
				output.writeInt32(62, newHeight_);
			}
			if (((bitField0_ & 0x40000000) == 0x40000000))
			{
				output.writeInt32(63, newWidth_);
			}
			if (((bitField0_ & 0x80000000) == 0x80000000))
			{
				output.writeBool(64, shuffleImages_);
			}
			if (((bitField1_ & 0x00000001) == 0x00000001))
			{
				output.writeUInt32(65, concatDim_);
			}
			if (((bitField1_ & 0x00000002) == 0x00000002))
			{
				output.writeMessage(1001, hdf5OutputParam_);
			}
			getUnknownFields().writeTo(output);
		}

		private int memoizedSerializedSize = -1;

		@Override
		public int getSerializedSize()
		{
			int size = memoizedSerializedSize;
			if (size != -1)
				return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(1, getNameBytes());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(2, getTypeBytes());
			}
			if (((bitField0_ & 0x00000004) == 0x00000004))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(3, numOutput_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(4, biasterm_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(5, weightFiller_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(6, biasFiller_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(7, pad_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(8, kernelsize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(9, group_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(10, stride_);
			}
			if (((bitField0_ & 0x00000400) == 0x00000400))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeEnumSize(11, pool_.getNumber());
			}
			if (((bitField0_ & 0x00000800) == 0x00000800))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(12, dropoutRatio_);
			}
			if (((bitField0_ & 0x00001000) == 0x00001000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(13, localSize_);
			}
			if (((bitField0_ & 0x00002000) == 0x00002000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(14, alpha_);
			}
			if (((bitField0_ & 0x00004000) == 0x00004000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(15, beta_);
			}
			if (((bitField0_ & 0x00008000) == 0x00008000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(16, getSourceBytes());
			}
			if (((bitField0_ & 0x00010000) == 0x00010000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(17, scale_);
			}
			if (((bitField0_ & 0x00020000) == 0x00020000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(18, getMeanfileBytes());
			}
			if (((bitField0_ & 0x00040000) == 0x00040000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(19, batchsize_);
			}
			if (((bitField0_ & 0x00080000) == 0x00080000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(20, cropsize_);
			}
			if (((bitField0_ & 0x00100000) == 0x00100000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(21, mirror_);
			}
			for (int i = 0; i < blobs_.size(); i++)
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(50, blobs_.get(i));
			}
			{
				int dataSize = 0;
				dataSize = 4 * getBlobsLrList().size();
				size += dataSize;
				size += 2 * getBlobsLrList().size();
			}
			{
				int dataSize = 0;
				dataSize = 4 * getWeightDecayList().size();
				size += dataSize;
				size += 2 * getWeightDecayList().size();
			}
			if (((bitField0_ & 0x00200000) == 0x00200000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(53, randSkip_);
			}
			if (((bitField0_ & 0x00400000) == 0x00400000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(54, detFgThreshold_);
			}
			if (((bitField0_ & 0x00800000) == 0x00800000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(55, detBgThreshold_);
			}
			if (((bitField0_ & 0x01000000) == 0x01000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeFloatSize(56, detFgFraction_);
			}
			if (((bitField0_ & 0x02000000) == 0x02000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(58, detContextPad_);
			}
			if (((bitField0_ & 0x04000000) == 0x04000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBytesSize(59, getDetCropModeBytes());
			}
			if (((bitField0_ & 0x08000000) == 0x08000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(60, newNum_);
			}
			if (((bitField0_ & 0x10000000) == 0x10000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(61, newChannels_);
			}
			if (((bitField0_ & 0x20000000) == 0x20000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(62, newHeight_);
			}
			if (((bitField0_ & 0x40000000) == 0x40000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeInt32Size(63, newWidth_);
			}
			if (((bitField0_ & 0x80000000) == 0x80000000))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeBoolSize(64, shuffleImages_);
			}
			if (((bitField1_ & 0x00000001) == 0x00000001))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeUInt32Size(65, concatDim_);
			}
			if (((bitField1_ & 0x00000002) == 0x00000002))
			{
				size += com.google.protobuf.CodedOutputStream
						.computeMessageSize(1001, hdf5OutputParam_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException
		{
			return super.writeReplace();
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(
				com.google.protobuf.ByteString data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(
				com.google.protobuf.ByteString data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(byte[] data)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(
				byte[] data,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws com.google.protobuf.InvalidProtocolBufferException
		{
			return PARSER.parseFrom(data, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseDelimitedFrom(java.io.InputStream input)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseDelimitedFrom(
				java.io.InputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseDelimitedFrom(input, extensionRegistry);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(
				com.google.protobuf.CodedInputStream input)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input);
		}

		public static com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parseFrom(
				com.google.protobuf.CodedInputStream input,
				com.google.protobuf.ExtensionRegistryLite extensionRegistry)
				throws java.io.IOException
		{
			return PARSER.parseFrom(input, extensionRegistry);
		}

		public static Builder newBuilder()
		{
			return Builder.create();
		}

		@Override
		public Builder newBuilderForType()
		{
			return newBuilder();
		}

		public static Builder newBuilder(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter prototype)
		{
			return newBuilder().mergeFrom(prototype);
		}

		@Override
		public Builder toBuilder()
		{
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				com.google.protobuf.GeneratedMessage.BuilderParent parent)
		{
			Builder builder = new Builder(parent);
			return builder;
		}

		/**
		 * Protobuf type {@code caffe.V0LayerParameter}
		 *
		 * <pre>
		 * DEPRECATED: V0LayerParameter is the old way of specifying layer parameters
		 * in Caffe.  We keep this message type around for legacy support.
		 * </pre>
		 */
		public static final class Builder extends
				com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				// @@protoc_insertion_point(builder_implements:caffe.V0LayerParameter)
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameterOrBuilder
		{
			public static final com.google.protobuf.Descriptors.Descriptor
					getDescriptor()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_V0LayerParameter_descriptor;
			}

			@Override
			protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
					internalGetFieldAccessorTable()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_V0LayerParameter_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.class, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.Builder.class);
			}

			// Construct using de.exb.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.newBuilder()
			private Builder()
			{
				maybeForceBuilderInitialization();
			}

			private Builder(
					com.google.protobuf.GeneratedMessage.BuilderParent parent)
			{
				super(parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization()
			{
				if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
				{
					getWeightFillerFieldBuilder();
					getBiasFillerFieldBuilder();
					getBlobsFieldBuilder();
					getHdf5OutputParamFieldBuilder();
				}
			}

			private static Builder create()
			{
				return new Builder();
			}

			@Override
			public Builder clear()
			{
				super.clear();
				name_ = "";
				bitField0_ = (bitField0_ & ~0x00000001);
				type_ = "";
				bitField0_ = (bitField0_ & ~0x00000002);
				numOutput_ = 0;
				bitField0_ = (bitField0_ & ~0x00000004);
				biasterm_ = true;
				bitField0_ = (bitField0_ & ~0x00000008);
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
				} else
				{
					weightFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000010);
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
				} else
				{
					biasFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000020);
				pad_ = 0;
				bitField0_ = (bitField0_ & ~0x00000040);
				kernelsize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000080);
				group_ = 1;
				bitField0_ = (bitField0_ & ~0x00000100);
				stride_ = 1;
				bitField0_ = (bitField0_ & ~0x00000200);
				pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod.MAX;
				bitField0_ = (bitField0_ & ~0x00000400);
				dropoutRatio_ = 0.5F;
				bitField0_ = (bitField0_ & ~0x00000800);
				localSize_ = 5;
				bitField0_ = (bitField0_ & ~0x00001000);
				alpha_ = 1F;
				bitField0_ = (bitField0_ & ~0x00002000);
				beta_ = 0.75F;
				bitField0_ = (bitField0_ & ~0x00004000);
				source_ = "";
				bitField0_ = (bitField0_ & ~0x00008000);
				scale_ = 1F;
				bitField0_ = (bitField0_ & ~0x00010000);
				meanfile_ = "";
				bitField0_ = (bitField0_ & ~0x00020000);
				batchsize_ = 0;
				bitField0_ = (bitField0_ & ~0x00040000);
				cropsize_ = 0;
				bitField0_ = (bitField0_ & ~0x00080000);
				mirror_ = false;
				bitField0_ = (bitField0_ & ~0x00100000);
				if (blobsBuilder_ == null)
				{
					blobs_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00200000);
				} else
				{
					blobsBuilder_.clear();
				}
				blobsLr_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00400000);
				weightDecay_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00800000);
				randSkip_ = 0;
				bitField0_ = (bitField0_ & ~0x01000000);
				detFgThreshold_ = 0.5F;
				bitField0_ = (bitField0_ & ~0x02000000);
				detBgThreshold_ = 0.5F;
				bitField0_ = (bitField0_ & ~0x04000000);
				detFgFraction_ = 0.25F;
				bitField0_ = (bitField0_ & ~0x08000000);
				detContextPad_ = 0;
				bitField0_ = (bitField0_ & ~0x10000000);
				detCropMode_ = "warp";
				bitField0_ = (bitField0_ & ~0x20000000);
				newNum_ = 0;
				bitField0_ = (bitField0_ & ~0x40000000);
				newChannels_ = 0;
				bitField0_ = (bitField0_ & ~0x80000000);
				newHeight_ = 0;
				bitField1_ = (bitField1_ & ~0x00000001);
				newWidth_ = 0;
				bitField1_ = (bitField1_ & ~0x00000002);
				shuffleImages_ = false;
				bitField1_ = (bitField1_ & ~0x00000004);
				concatDim_ = 1;
				bitField1_ = (bitField1_ & ~0x00000008);
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
				} else
				{
					hdf5OutputParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000010);
				return this;
			}

			@Override
			public Builder clone()
			{
				return create().mergeFrom(buildPartial());
			}

			@Override
			public com.google.protobuf.Descriptors.Descriptor
					getDescriptorForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.internal_static_caffe_V0LayerParameter_descriptor;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter getDefaultInstanceForType()
			{
				return com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDefaultInstance();
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter build()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter result = buildPartial();
				if (!result.isInitialized())
				{
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter buildPartial()
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter result = new com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter(this);
				int from_bitField0_ = bitField0_;
				int from_bitField1_ = bitField1_;
				int to_bitField0_ = 0;
				int to_bitField1_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x00000001;
				}
				result.name_ = name_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x00000002;
				}
				result.type_ = type_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x00000004;
				}
				result.numOutput_ = numOutput_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008))
				{
					to_bitField0_ |= 0x00000008;
				}
				result.biasterm_ = biasterm_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010))
				{
					to_bitField0_ |= 0x00000010;
				}
				if (weightFillerBuilder_ == null)
				{
					result.weightFiller_ = weightFiller_;
				} else
				{
					result.weightFiller_ = weightFillerBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000020) == 0x00000020))
				{
					to_bitField0_ |= 0x00000020;
				}
				if (biasFillerBuilder_ == null)
				{
					result.biasFiller_ = biasFiller_;
				} else
				{
					result.biasFiller_ = biasFillerBuilder_.build();
				}
				if (((from_bitField0_ & 0x00000040) == 0x00000040))
				{
					to_bitField0_ |= 0x00000040;
				}
				result.pad_ = pad_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080))
				{
					to_bitField0_ |= 0x00000080;
				}
				result.kernelsize_ = kernelsize_;
				if (((from_bitField0_ & 0x00000100) == 0x00000100))
				{
					to_bitField0_ |= 0x00000100;
				}
				result.group_ = group_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200))
				{
					to_bitField0_ |= 0x00000200;
				}
				result.stride_ = stride_;
				if (((from_bitField0_ & 0x00000400) == 0x00000400))
				{
					to_bitField0_ |= 0x00000400;
				}
				result.pool_ = pool_;
				if (((from_bitField0_ & 0x00000800) == 0x00000800))
				{
					to_bitField0_ |= 0x00000800;
				}
				result.dropoutRatio_ = dropoutRatio_;
				if (((from_bitField0_ & 0x00001000) == 0x00001000))
				{
					to_bitField0_ |= 0x00001000;
				}
				result.localSize_ = localSize_;
				if (((from_bitField0_ & 0x00002000) == 0x00002000))
				{
					to_bitField0_ |= 0x00002000;
				}
				result.alpha_ = alpha_;
				if (((from_bitField0_ & 0x00004000) == 0x00004000))
				{
					to_bitField0_ |= 0x00004000;
				}
				result.beta_ = beta_;
				if (((from_bitField0_ & 0x00008000) == 0x00008000))
				{
					to_bitField0_ |= 0x00008000;
				}
				result.source_ = source_;
				if (((from_bitField0_ & 0x00010000) == 0x00010000))
				{
					to_bitField0_ |= 0x00010000;
				}
				result.scale_ = scale_;
				if (((from_bitField0_ & 0x00020000) == 0x00020000))
				{
					to_bitField0_ |= 0x00020000;
				}
				result.meanfile_ = meanfile_;
				if (((from_bitField0_ & 0x00040000) == 0x00040000))
				{
					to_bitField0_ |= 0x00040000;
				}
				result.batchsize_ = batchsize_;
				if (((from_bitField0_ & 0x00080000) == 0x00080000))
				{
					to_bitField0_ |= 0x00080000;
				}
				result.cropsize_ = cropsize_;
				if (((from_bitField0_ & 0x00100000) == 0x00100000))
				{
					to_bitField0_ |= 0x00100000;
				}
				result.mirror_ = mirror_;
				if (blobsBuilder_ == null)
				{
					if (((bitField0_ & 0x00200000) == 0x00200000))
					{
						blobs_ = java.util.Collections.unmodifiableList(blobs_);
						bitField0_ = (bitField0_ & ~0x00200000);
					}
					result.blobs_ = blobs_;
				} else
				{
					result.blobs_ = blobsBuilder_.build();
				}
				if (((bitField0_ & 0x00400000) == 0x00400000))
				{
					blobsLr_ = java.util.Collections.unmodifiableList(blobsLr_);
					bitField0_ = (bitField0_ & ~0x00400000);
				}
				result.blobsLr_ = blobsLr_;
				if (((bitField0_ & 0x00800000) == 0x00800000))
				{
					weightDecay_ = java.util.Collections.unmodifiableList(weightDecay_);
					bitField0_ = (bitField0_ & ~0x00800000);
				}
				result.weightDecay_ = weightDecay_;
				if (((from_bitField0_ & 0x01000000) == 0x01000000))
				{
					to_bitField0_ |= 0x00200000;
				}
				result.randSkip_ = randSkip_;
				if (((from_bitField0_ & 0x02000000) == 0x02000000))
				{
					to_bitField0_ |= 0x00400000;
				}
				result.detFgThreshold_ = detFgThreshold_;
				if (((from_bitField0_ & 0x04000000) == 0x04000000))
				{
					to_bitField0_ |= 0x00800000;
				}
				result.detBgThreshold_ = detBgThreshold_;
				if (((from_bitField0_ & 0x08000000) == 0x08000000))
				{
					to_bitField0_ |= 0x01000000;
				}
				result.detFgFraction_ = detFgFraction_;
				if (((from_bitField0_ & 0x10000000) == 0x10000000))
				{
					to_bitField0_ |= 0x02000000;
				}
				result.detContextPad_ = detContextPad_;
				if (((from_bitField0_ & 0x20000000) == 0x20000000))
				{
					to_bitField0_ |= 0x04000000;
				}
				result.detCropMode_ = detCropMode_;
				if (((from_bitField0_ & 0x40000000) == 0x40000000))
				{
					to_bitField0_ |= 0x08000000;
				}
				result.newNum_ = newNum_;
				if (((from_bitField0_ & 0x80000000) == 0x80000000))
				{
					to_bitField0_ |= 0x10000000;
				}
				result.newChannels_ = newChannels_;
				if (((from_bitField1_ & 0x00000001) == 0x00000001))
				{
					to_bitField0_ |= 0x20000000;
				}
				result.newHeight_ = newHeight_;
				if (((from_bitField1_ & 0x00000002) == 0x00000002))
				{
					to_bitField0_ |= 0x40000000;
				}
				result.newWidth_ = newWidth_;
				if (((from_bitField1_ & 0x00000004) == 0x00000004))
				{
					to_bitField0_ |= 0x80000000;
				}
				result.shuffleImages_ = shuffleImages_;
				if (((from_bitField1_ & 0x00000008) == 0x00000008))
				{
					to_bitField1_ |= 0x00000001;
				}
				result.concatDim_ = concatDim_;
				if (((from_bitField1_ & 0x00000010) == 0x00000010))
				{
					to_bitField1_ |= 0x00000002;
				}
				if (hdf5OutputParamBuilder_ == null)
				{
					result.hdf5OutputParam_ = hdf5OutputParam_;
				} else
				{
					result.hdf5OutputParam_ = hdf5OutputParamBuilder_.build();
				}
				result.bitField0_ = to_bitField0_;
				result.bitField1_ = to_bitField1_;
				onBuilt();
				return result;
			}

			@Override
			public Builder mergeFrom(com.google.protobuf.Message other)
			{
				if (other instanceof com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter)
				{
					return mergeFrom((com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter) other);
				} else
				{
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter other)
			{
				if (other == com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.getDefaultInstance())
					return this;
				if (other.hasName())
				{
					bitField0_ |= 0x00000001;
					name_ = other.name_;
					onChanged();
				}
				if (other.hasType())
				{
					bitField0_ |= 0x00000002;
					type_ = other.type_;
					onChanged();
				}
				if (other.hasNumOutput())
				{
					setNumOutput(other.getNumOutput());
				}
				if (other.hasBiasterm())
				{
					setBiasterm(other.getBiasterm());
				}
				if (other.hasWeightFiller())
				{
					mergeWeightFiller(other.getWeightFiller());
				}
				if (other.hasBiasFiller())
				{
					mergeBiasFiller(other.getBiasFiller());
				}
				if (other.hasPad())
				{
					setPad(other.getPad());
				}
				if (other.hasKernelsize())
				{
					setKernelsize(other.getKernelsize());
				}
				if (other.hasGroup())
				{
					setGroup(other.getGroup());
				}
				if (other.hasStride())
				{
					setStride(other.getStride());
				}
				if (other.hasPool())
				{
					setPool(other.getPool());
				}
				if (other.hasDropoutRatio())
				{
					setDropoutRatio(other.getDropoutRatio());
				}
				if (other.hasLocalSize())
				{
					setLocalSize(other.getLocalSize());
				}
				if (other.hasAlpha())
				{
					setAlpha(other.getAlpha());
				}
				if (other.hasBeta())
				{
					setBeta(other.getBeta());
				}
				if (other.hasSource())
				{
					bitField0_ |= 0x00008000;
					source_ = other.source_;
					onChanged();
				}
				if (other.hasScale())
				{
					setScale(other.getScale());
				}
				if (other.hasMeanfile())
				{
					bitField0_ |= 0x00020000;
					meanfile_ = other.meanfile_;
					onChanged();
				}
				if (other.hasBatchsize())
				{
					setBatchsize(other.getBatchsize());
				}
				if (other.hasCropsize())
				{
					setCropsize(other.getCropsize());
				}
				if (other.hasMirror())
				{
					setMirror(other.getMirror());
				}
				if (blobsBuilder_ == null)
				{
					if (!other.blobs_.isEmpty())
					{
						if (blobs_.isEmpty())
						{
							blobs_ = other.blobs_;
							bitField0_ = (bitField0_ & ~0x00200000);
						} else
						{
							ensureBlobsIsMutable();
							blobs_.addAll(other.blobs_);
						}
						onChanged();
					}
				} else
				{
					if (!other.blobs_.isEmpty())
					{
						if (blobsBuilder_.isEmpty())
						{
							blobsBuilder_.dispose();
							blobsBuilder_ = null;
							blobs_ = other.blobs_;
							bitField0_ = (bitField0_ & ~0x00200000);
							blobsBuilder_ =
									com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
											getBlobsFieldBuilder() : null;
						} else
						{
							blobsBuilder_.addAllMessages(other.blobs_);
						}
					}
				}
				if (!other.blobsLr_.isEmpty())
				{
					if (blobsLr_.isEmpty())
					{
						blobsLr_ = other.blobsLr_;
						bitField0_ = (bitField0_ & ~0x00400000);
					} else
					{
						ensureBlobsLrIsMutable();
						blobsLr_.addAll(other.blobsLr_);
					}
					onChanged();
				}
				if (!other.weightDecay_.isEmpty())
				{
					if (weightDecay_.isEmpty())
					{
						weightDecay_ = other.weightDecay_;
						bitField0_ = (bitField0_ & ~0x00800000);
					} else
					{
						ensureWeightDecayIsMutable();
						weightDecay_.addAll(other.weightDecay_);
					}
					onChanged();
				}
				if (other.hasRandSkip())
				{
					setRandSkip(other.getRandSkip());
				}
				if (other.hasDetFgThreshold())
				{
					setDetFgThreshold(other.getDetFgThreshold());
				}
				if (other.hasDetBgThreshold())
				{
					setDetBgThreshold(other.getDetBgThreshold());
				}
				if (other.hasDetFgFraction())
				{
					setDetFgFraction(other.getDetFgFraction());
				}
				if (other.hasDetContextPad())
				{
					setDetContextPad(other.getDetContextPad());
				}
				if (other.hasDetCropMode())
				{
					bitField0_ |= 0x20000000;
					detCropMode_ = other.detCropMode_;
					onChanged();
				}
				if (other.hasNewNum())
				{
					setNewNum(other.getNewNum());
				}
				if (other.hasNewChannels())
				{
					setNewChannels(other.getNewChannels());
				}
				if (other.hasNewHeight())
				{
					setNewHeight(other.getNewHeight());
				}
				if (other.hasNewWidth())
				{
					setNewWidth(other.getNewWidth());
				}
				if (other.hasShuffleImages())
				{
					setShuffleImages(other.getShuffleImages());
				}
				if (other.hasConcatDim())
				{
					setConcatDim(other.getConcatDim());
				}
				if (other.hasHdf5OutputParam())
				{
					mergeHdf5OutputParam(other.getHdf5OutputParam());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			@Override
			public final boolean isInitialized()
			{
				return true;
			}

			@Override
			public Builder mergeFrom(
					com.google.protobuf.CodedInputStream input,
					com.google.protobuf.ExtensionRegistryLite extensionRegistry)
					throws java.io.IOException
			{
				com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter parsedMessage = null;
				try
				{
					parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
				} catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					parsedMessage = (com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter) e.getUnfinishedMessage();
					throw e;
				} finally
				{
					if (parsedMessage != null)
					{
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;
			private int bitField1_;

			private java.lang.Object name_ = "";

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			@Override
			public boolean hasName()
			{
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			@Override
			public java.lang.String getName()
			{
				java.lang.Object ref = name_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						name_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getNameBytes()
			{
				java.lang.Object ref = name_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					name_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			public Builder setName(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				name_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			public Builder clearName()
			{
				bitField0_ = (bitField0_ & ~0x00000001);
				name_ = getDefaultInstance().getName();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string name = 1;</code>
			 *
			 * <pre>
			 * the layer name
			 * </pre>
			 */
			public Builder setNameBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				name_ = value;
				onChanged();
				return this;
			}

			private java.lang.Object type_ = "";

			/**
			 * <code>optional string type = 2;</code>
			 *
			 * <pre>
			 * the string to specify the layer type
			 * </pre>
			 */
			@Override
			public boolean hasType()
			{
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional string type = 2;</code>
			 *
			 * <pre>
			 * the string to specify the layer type
			 * </pre>
			 */
			@Override
			public java.lang.String getType()
			{
				java.lang.Object ref = type_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						type_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string type = 2;</code>
			 *
			 * <pre>
			 * the string to specify the layer type
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getTypeBytes()
			{
				java.lang.Object ref = type_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					type_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string type = 2;</code>
			 *
			 * <pre>
			 * the string to specify the layer type
			 * </pre>
			 */
			public Builder setType(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000002;
				type_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string type = 2;</code>
			 *
			 * <pre>
			 * the string to specify the layer type
			 * </pre>
			 */
			public Builder clearType()
			{
				bitField0_ = (bitField0_ & ~0x00000002);
				type_ = getDefaultInstance().getType();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string type = 2;</code>
			 *
			 * <pre>
			 * the string to specify the layer type
			 * </pre>
			 */
			public Builder setTypeBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000002;
				type_ = value;
				onChanged();
				return this;
			}

			private int numOutput_;

			/**
			 * <code>optional uint32 num_output = 3;</code>
			 *
			 * <pre>
			 * Parameters to specify layers with inner products.
			 * </pre>
			 */
			@Override
			public boolean hasNumOutput()
			{
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional uint32 num_output = 3;</code>
			 *
			 * <pre>
			 * Parameters to specify layers with inner products.
			 * </pre>
			 */
			@Override
			public int getNumOutput()
			{
				return numOutput_;
			}

			/**
			 * <code>optional uint32 num_output = 3;</code>
			 *
			 * <pre>
			 * Parameters to specify layers with inner products.
			 * </pre>
			 */
			public Builder setNumOutput(int value)
			{
				bitField0_ |= 0x00000004;
				numOutput_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 num_output = 3;</code>
			 *
			 * <pre>
			 * Parameters to specify layers with inner products.
			 * </pre>
			 */
			public Builder clearNumOutput()
			{
				bitField0_ = (bitField0_ & ~0x00000004);
				numOutput_ = 0;
				onChanged();
				return this;
			}

			private boolean biasterm_ = true;

			/**
			 * <code>optional bool biasterm = 4 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			@Override
			public boolean hasBiasterm()
			{
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional bool biasterm = 4 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			@Override
			public boolean getBiasterm()
			{
				return biasterm_;
			}

			/**
			 * <code>optional bool biasterm = 4 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			public Builder setBiasterm(boolean value)
			{
				bitField0_ |= 0x00000008;
				biasterm_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool biasterm = 4 [default = true];</code>
			 *
			 * <pre>
			 * whether to have bias terms
			 * </pre>
			 */
			public Builder clearBiasterm()
			{
				bitField0_ = (bitField0_ & ~0x00000008);
				biasterm_ = true;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> weightFillerBuilder_;

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public boolean hasWeightFiller()
			{
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getWeightFiller()
			{
				if (weightFillerBuilder_ == null)
				{
					return weightFiller_;
				} else
				{
					return weightFillerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder setWeightFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (weightFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					weightFiller_ = value;
					onChanged();
				} else
				{
					weightFillerBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder setWeightFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = builderForValue.build();
					onChanged();
				} else
				{
					weightFillerBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder mergeWeightFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (weightFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00000010) == 0x00000010) &&
							weightFiller_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					{
						weightFiller_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder(weightFiller_).mergeFrom(value).buildPartial();
					} else
					{
						weightFiller_ = value;
					}
					onChanged();
				} else
				{
					weightFillerBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public Builder clearWeightFiller()
			{
				if (weightFillerBuilder_ == null)
				{
					weightFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					weightFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000010);
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getWeightFillerBuilder()
			{
				bitField0_ |= 0x00000010;
				onChanged();
				return getWeightFillerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getWeightFillerOrBuilder()
			{
				if (weightFillerBuilder_ != null)
				{
					return weightFillerBuilder_.getMessageOrBuilder();
				} else
				{
					return weightFiller_;
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter weight_filler = 5;</code>
			 *
			 * <pre>
			 * The filler for the weight
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getWeightFillerFieldBuilder()
			{
				if (weightFillerBuilder_ == null)
				{
					weightFillerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									getWeightFiller(),
									getParentForChildren(),
									isClean());
					weightFiller_ = null;
				}
				return weightFillerBuilder_;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder> biasFillerBuilder_;

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public boolean hasBiasFiller()
			{
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter getBiasFiller()
			{
				if (biasFillerBuilder_ == null)
				{
					return biasFiller_;
				} else
				{
					return biasFillerBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder setBiasFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (biasFillerBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					biasFiller_ = value;
					onChanged();
				} else
				{
					biasFillerBuilder_.setMessage(value);
				}
				bitField0_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder setBiasFiller(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder builderForValue)
			{
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = builderForValue.build();
					onChanged();
				} else
				{
					biasFillerBuilder_.setMessage(builderForValue.build());
				}
				bitField0_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder mergeBiasFiller(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter value)
			{
				if (biasFillerBuilder_ == null)
				{
					if (((bitField0_ & 0x00000020) == 0x00000020) &&
							biasFiller_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance())
					{
						biasFiller_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.newBuilder(biasFiller_).mergeFrom(value).buildPartial();
					} else
					{
						biasFiller_ = value;
					}
					onChanged();
				} else
				{
					biasFillerBuilder_.mergeFrom(value);
				}
				bitField0_ |= 0x00000020;
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public Builder clearBiasFiller()
			{
				if (biasFillerBuilder_ == null)
				{
					biasFiller_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.getDefaultInstance();
					onChanged();
				} else
				{
					biasFillerBuilder_.clear();
				}
				bitField0_ = (bitField0_ & ~0x00000020);
				return this;
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder getBiasFillerBuilder()
			{
				bitField0_ |= 0x00000020;
				onChanged();
				return getBiasFillerFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder getBiasFillerOrBuilder()
			{
				if (biasFillerBuilder_ != null)
				{
					return biasFillerBuilder_.getMessageOrBuilder();
				} else
				{
					return biasFiller_;
				}
			}

			/**
			 * <code>optional .caffe.FillerParameter bias_filler = 6;</code>
			 *
			 * <pre>
			 * The filler for the bias
			 * </pre>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>
					getBiasFillerFieldBuilder()
			{
				if (biasFillerBuilder_ == null)
				{
					biasFillerBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.FillerParameterOrBuilder>(
									getBiasFiller(),
									getParentForChildren(),
									isClean());
					biasFiller_ = null;
				}
				return biasFillerBuilder_;
			}

			private int pad_;

			/**
			 * <code>optional uint32 pad = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The padding size
			 * </pre>
			 */
			@Override
			public boolean hasPad()
			{
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional uint32 pad = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The padding size
			 * </pre>
			 */
			@Override
			public int getPad()
			{
				return pad_;
			}

			/**
			 * <code>optional uint32 pad = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The padding size
			 * </pre>
			 */
			public Builder setPad(int value)
			{
				bitField0_ |= 0x00000040;
				pad_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 pad = 7 [default = 0];</code>
			 *
			 * <pre>
			 * The padding size
			 * </pre>
			 */
			public Builder clearPad()
			{
				bitField0_ = (bitField0_ & ~0x00000040);
				pad_ = 0;
				onChanged();
				return this;
			}

			private int kernelsize_;

			/**
			 * <code>optional uint32 kernelsize = 8;</code>
			 *
			 * <pre>
			 * The kernel size
			 * </pre>
			 */
			@Override
			public boolean hasKernelsize()
			{
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional uint32 kernelsize = 8;</code>
			 *
			 * <pre>
			 * The kernel size
			 * </pre>
			 */
			@Override
			public int getKernelsize()
			{
				return kernelsize_;
			}

			/**
			 * <code>optional uint32 kernelsize = 8;</code>
			 *
			 * <pre>
			 * The kernel size
			 * </pre>
			 */
			public Builder setKernelsize(int value)
			{
				bitField0_ |= 0x00000080;
				kernelsize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 kernelsize = 8;</code>
			 *
			 * <pre>
			 * The kernel size
			 * </pre>
			 */
			public Builder clearKernelsize()
			{
				bitField0_ = (bitField0_ & ~0x00000080);
				kernelsize_ = 0;
				onChanged();
				return this;
			}

			private int group_ = 1;

			/**
			 * <code>optional uint32 group = 9 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			@Override
			public boolean hasGroup()
			{
				return ((bitField0_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>optional uint32 group = 9 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			@Override
			public int getGroup()
			{
				return group_;
			}

			/**
			 * <code>optional uint32 group = 9 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			public Builder setGroup(int value)
			{
				bitField0_ |= 0x00000100;
				group_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 group = 9 [default = 1];</code>
			 *
			 * <pre>
			 * The group size for group conv
			 * </pre>
			 */
			public Builder clearGroup()
			{
				bitField0_ = (bitField0_ & ~0x00000100);
				group_ = 1;
				onChanged();
				return this;
			}

			private int stride_ = 1;

			/**
			 * <code>optional uint32 stride = 10 [default = 1];</code>
			 *
			 * <pre>
			 * The stride
			 * </pre>
			 */
			@Override
			public boolean hasStride()
			{
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional uint32 stride = 10 [default = 1];</code>
			 *
			 * <pre>
			 * The stride
			 * </pre>
			 */
			@Override
			public int getStride()
			{
				return stride_;
			}

			/**
			 * <code>optional uint32 stride = 10 [default = 1];</code>
			 *
			 * <pre>
			 * The stride
			 * </pre>
			 */
			public Builder setStride(int value)
			{
				bitField0_ |= 0x00000200;
				stride_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 stride = 10 [default = 1];</code>
			 *
			 * <pre>
			 * The stride
			 * </pre>
			 */
			public Builder clearStride()
			{
				bitField0_ = (bitField0_ & ~0x00000200);
				stride_ = 1;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod.MAX;

			/**
			 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			@Override
			public boolean hasPool()
			{
				return ((bitField0_ & 0x00000400) == 0x00000400);
			}

			/**
			 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod getPool()
			{
				return pool_;
			}

			/**
			 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			public Builder setPool(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000400;
				pool_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional .caffe.V0LayerParameter.PoolMethod pool = 11 [default = MAX];</code>
			 *
			 * <pre>
			 * The pooling method
			 * </pre>
			 */
			public Builder clearPool()
			{
				bitField0_ = (bitField0_ & ~0x00000400);
				pool_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.V0LayerParameter.PoolMethod.MAX;
				onChanged();
				return this;
			}

			private float dropoutRatio_ = 0.5F;

			/**
			 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			@Override
			public boolean hasDropoutRatio()
			{
				return ((bitField0_ & 0x00000800) == 0x00000800);
			}

			/**
			 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			@Override
			public float getDropoutRatio()
			{
				return dropoutRatio_;
			}

			/**
			 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			public Builder setDropoutRatio(float value)
			{
				bitField0_ |= 0x00000800;
				dropoutRatio_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float dropout_ratio = 12 [default = 0.5];</code>
			 *
			 * <pre>
			 * dropout ratio
			 * </pre>
			 */
			public Builder clearDropoutRatio()
			{
				bitField0_ = (bitField0_ & ~0x00000800);
				dropoutRatio_ = 0.5F;
				onChanged();
				return this;
			}

			private int localSize_ = 5;

			/**
			 * <code>optional uint32 local_size = 13 [default = 5];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			@Override
			public boolean hasLocalSize()
			{
				return ((bitField0_ & 0x00001000) == 0x00001000);
			}

			/**
			 * <code>optional uint32 local_size = 13 [default = 5];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			@Override
			public int getLocalSize()
			{
				return localSize_;
			}

			/**
			 * <code>optional uint32 local_size = 13 [default = 5];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			public Builder setLocalSize(int value)
			{
				bitField0_ |= 0x00001000;
				localSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 local_size = 13 [default = 5];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			public Builder clearLocalSize()
			{
				bitField0_ = (bitField0_ & ~0x00001000);
				localSize_ = 5;
				onChanged();
				return this;
			}

			private float alpha_ = 1F;

			/**
			 * <code>optional float alpha = 14 [default = 1];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			@Override
			public boolean hasAlpha()
			{
				return ((bitField0_ & 0x00002000) == 0x00002000);
			}

			/**
			 * <code>optional float alpha = 14 [default = 1];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			@Override
			public float getAlpha()
			{
				return alpha_;
			}

			/**
			 * <code>optional float alpha = 14 [default = 1];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			public Builder setAlpha(float value)
			{
				bitField0_ |= 0x00002000;
				alpha_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float alpha = 14 [default = 1];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			public Builder clearAlpha()
			{
				bitField0_ = (bitField0_ & ~0x00002000);
				alpha_ = 1F;
				onChanged();
				return this;
			}

			private float beta_ = 0.75F;

			/**
			 * <code>optional float beta = 15 [default = 0.75];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			@Override
			public boolean hasBeta()
			{
				return ((bitField0_ & 0x00004000) == 0x00004000);
			}

			/**
			 * <code>optional float beta = 15 [default = 0.75];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			@Override
			public float getBeta()
			{
				return beta_;
			}

			/**
			 * <code>optional float beta = 15 [default = 0.75];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			public Builder setBeta(float value)
			{
				bitField0_ |= 0x00004000;
				beta_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float beta = 15 [default = 0.75];</code>
			 *
			 * <pre>
			 * for local response norm
			 * </pre>
			 */
			public Builder clearBeta()
			{
				bitField0_ = (bitField0_ & ~0x00004000);
				beta_ = 0.75F;
				onChanged();
				return this;
			}

			private java.lang.Object source_ = "";

			/**
			 * <code>optional string source = 16;</code>
			 *
			 * <pre>
			 * For data layers, specify the data source
			 * </pre>
			 */
			@Override
			public boolean hasSource()
			{
				return ((bitField0_ & 0x00008000) == 0x00008000);
			}

			/**
			 * <code>optional string source = 16;</code>
			 *
			 * <pre>
			 * For data layers, specify the data source
			 * </pre>
			 */
			@Override
			public java.lang.String getSource()
			{
				java.lang.Object ref = source_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						source_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string source = 16;</code>
			 *
			 * <pre>
			 * For data layers, specify the data source
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getSourceBytes()
			{
				java.lang.Object ref = source_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					source_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string source = 16;</code>
			 *
			 * <pre>
			 * For data layers, specify the data source
			 * </pre>
			 */
			public Builder setSource(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00008000;
				source_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 16;</code>
			 *
			 * <pre>
			 * For data layers, specify the data source
			 * </pre>
			 */
			public Builder clearSource()
			{
				bitField0_ = (bitField0_ & ~0x00008000);
				source_ = getDefaultInstance().getSource();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string source = 16;</code>
			 *
			 * <pre>
			 * For data layers, specify the data source
			 * </pre>
			 */
			public Builder setSourceBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00008000;
				source_ = value;
				onChanged();
				return this;
			}

			private float scale_ = 1F;

			/**
			 * <code>optional float scale = 17 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			@Override
			public boolean hasScale()
			{
				return ((bitField0_ & 0x00010000) == 0x00010000);
			}

			/**
			 * <code>optional float scale = 17 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			@Override
			public float getScale()
			{
				return scale_;
			}

			/**
			 * <code>optional float scale = 17 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			public Builder setScale(float value)
			{
				bitField0_ |= 0x00010000;
				scale_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float scale = 17 [default = 1];</code>
			 *
			 * <pre>
			 * For data pre-processing, we can do simple scaling and subtracting the
			 * data mean, if provided. Note that the mean subtraction is always carried
			 * out before scaling.
			 * </pre>
			 */
			public Builder clearScale()
			{
				bitField0_ = (bitField0_ & ~0x00010000);
				scale_ = 1F;
				onChanged();
				return this;
			}

			private java.lang.Object meanfile_ = "";

			/**
			 * <code>optional string meanfile = 18;</code>
			 */
			@Override
			public boolean hasMeanfile()
			{
				return ((bitField0_ & 0x00020000) == 0x00020000);
			}

			/**
			 * <code>optional string meanfile = 18;</code>
			 */
			@Override
			public java.lang.String getMeanfile()
			{
				java.lang.Object ref = meanfile_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						meanfile_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string meanfile = 18;</code>
			 */
			@Override
			public com.google.protobuf.ByteString
					getMeanfileBytes()
			{
				java.lang.Object ref = meanfile_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					meanfile_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string meanfile = 18;</code>
			 */
			public Builder setMeanfile(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00020000;
				meanfile_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string meanfile = 18;</code>
			 */
			public Builder clearMeanfile()
			{
				bitField0_ = (bitField0_ & ~0x00020000);
				meanfile_ = getDefaultInstance().getMeanfile();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string meanfile = 18;</code>
			 */
			public Builder setMeanfileBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x00020000;
				meanfile_ = value;
				onChanged();
				return this;
			}

			private int batchsize_;

			/**
			 * <code>optional uint32 batchsize = 19;</code>
			 *
			 * <pre>
			 * For data layers, specify the batch size.
			 * </pre>
			 */
			@Override
			public boolean hasBatchsize()
			{
				return ((bitField0_ & 0x00040000) == 0x00040000);
			}

			/**
			 * <code>optional uint32 batchsize = 19;</code>
			 *
			 * <pre>
			 * For data layers, specify the batch size.
			 * </pre>
			 */
			@Override
			public int getBatchsize()
			{
				return batchsize_;
			}

			/**
			 * <code>optional uint32 batchsize = 19;</code>
			 *
			 * <pre>
			 * For data layers, specify the batch size.
			 * </pre>
			 */
			public Builder setBatchsize(int value)
			{
				bitField0_ |= 0x00040000;
				batchsize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 batchsize = 19;</code>
			 *
			 * <pre>
			 * For data layers, specify the batch size.
			 * </pre>
			 */
			public Builder clearBatchsize()
			{
				bitField0_ = (bitField0_ & ~0x00040000);
				batchsize_ = 0;
				onChanged();
				return this;
			}

			private int cropsize_;

			/**
			 * <code>optional uint32 cropsize = 20 [default = 0];</code>
			 *
			 * <pre>
			 * For data layers, specify if we would like to randomly crop an image.
			 * </pre>
			 */
			@Override
			public boolean hasCropsize()
			{
				return ((bitField0_ & 0x00080000) == 0x00080000);
			}

			/**
			 * <code>optional uint32 cropsize = 20 [default = 0];</code>
			 *
			 * <pre>
			 * For data layers, specify if we would like to randomly crop an image.
			 * </pre>
			 */
			@Override
			public int getCropsize()
			{
				return cropsize_;
			}

			/**
			 * <code>optional uint32 cropsize = 20 [default = 0];</code>
			 *
			 * <pre>
			 * For data layers, specify if we would like to randomly crop an image.
			 * </pre>
			 */
			public Builder setCropsize(int value)
			{
				bitField0_ |= 0x00080000;
				cropsize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 cropsize = 20 [default = 0];</code>
			 *
			 * <pre>
			 * For data layers, specify if we would like to randomly crop an image.
			 * </pre>
			 */
			public Builder clearCropsize()
			{
				bitField0_ = (bitField0_ & ~0x00080000);
				cropsize_ = 0;
				onChanged();
				return this;
			}

			private boolean mirror_;

			/**
			 * <code>optional bool mirror = 21 [default = false];</code>
			 *
			 * <pre>
			 * For data layers, specify if we want to randomly mirror data.
			 * </pre>
			 */
			@Override
			public boolean hasMirror()
			{
				return ((bitField0_ & 0x00100000) == 0x00100000);
			}

			/**
			 * <code>optional bool mirror = 21 [default = false];</code>
			 *
			 * <pre>
			 * For data layers, specify if we want to randomly mirror data.
			 * </pre>
			 */
			@Override
			public boolean getMirror()
			{
				return mirror_;
			}

			/**
			 * <code>optional bool mirror = 21 [default = false];</code>
			 *
			 * <pre>
			 * For data layers, specify if we want to randomly mirror data.
			 * </pre>
			 */
			public Builder setMirror(boolean value)
			{
				bitField0_ |= 0x00100000;
				mirror_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool mirror = 21 [default = false];</code>
			 *
			 * <pre>
			 * For data layers, specify if we want to randomly mirror data.
			 * </pre>
			 */
			public Builder clearMirror()
			{
				bitField0_ = (bitField0_ & ~0x00100000);
				mirror_ = false;
				onChanged();
				return this;
			}

			private java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> blobs_ =
					java.util.Collections.emptyList();

			private void ensureBlobsIsMutable()
			{
				if (!((bitField0_ & 0x00200000) == 0x00200000))
				{
					blobs_ = new java.util.ArrayList<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto>(blobs_);
					bitField0_ |= 0x00200000;
				}
			}

			private com.google.protobuf.RepeatedFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder> blobsBuilder_;

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> getBlobsList()
			{
				if (blobsBuilder_ == null)
				{
					return java.util.Collections.unmodifiableList(blobs_);
				} else
				{
					return blobsBuilder_.getMessageList();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public int getBlobsCount()
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.size();
				} else
				{
					return blobsBuilder_.getCount();
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto getBlobs(int index)
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.get(index);
				} else
				{
					return blobsBuilder_.getMessage(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder setBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.set(index, value);
					onChanged();
				} else
				{
					blobsBuilder_.setMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder setBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.set(index, builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.setMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.add(value);
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto value)
			{
				if (blobsBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					ensureBlobsIsMutable();
					blobs_.add(index, value);
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(index, value);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.add(builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addBlobs(
					int index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder builderForValue)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.add(index, builderForValue.build());
					onChanged();
				} else
				{
					blobsBuilder_.addMessage(index, builderForValue.build());
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder addAllBlobs(
					java.lang.Iterable<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto> values)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					com.google.protobuf.AbstractMessageLite.Builder.addAll(
							values, blobs_);
					onChanged();
				} else
				{
					blobsBuilder_.addAllMessages(values);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder clearBlobs()
			{
				if (blobsBuilder_ == null)
				{
					blobs_ = java.util.Collections.emptyList();
					bitField0_ = (bitField0_ & ~0x00200000);
					onChanged();
				} else
				{
					blobsBuilder_.clear();
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public Builder removeBlobs(int index)
			{
				if (blobsBuilder_ == null)
				{
					ensureBlobsIsMutable();
					blobs_.remove(index);
					onChanged();
				} else
				{
					blobsBuilder_.remove(index);
				}
				return this;
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder getBlobsBuilder(
					int index)
			{
				return getBlobsFieldBuilder().getBuilder(index);
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder getBlobsOrBuilder(
					int index)
			{
				if (blobsBuilder_ == null)
				{
					return blobs_.get(index);
				} else
				{
					return blobsBuilder_.getMessageOrBuilder(index);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			@Override
			public java.util.List<? extends com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getBlobsOrBuilderList()
			{
				if (blobsBuilder_ != null)
				{
					return blobsBuilder_.getMessageOrBuilderList();
				} else
				{
					return java.util.Collections.unmodifiableList(blobs_);
				}
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addBlobsBuilder()
			{
				return getBlobsFieldBuilder().addBuilder(
						com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder addBlobsBuilder(
					int index)
			{
				return getBlobsFieldBuilder().addBuilder(
						index, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.getDefaultInstance());
			}

			/**
			 * <code>repeated .caffe.BlobProto blobs = 50;</code>
			 *
			 * <pre>
			 * The blobs containing the numeric parameters of the layer
			 * </pre>
			 */
			public java.util.List<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder>
					getBlobsBuilderList()
			{
				return getBlobsFieldBuilder().getBuilderList();
			}

			private com.google.protobuf.RepeatedFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>
					getBlobsFieldBuilder()
			{
				if (blobsBuilder_ == null)
				{
					blobsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProto.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.BlobProtoOrBuilder>(
									blobs_,
									((bitField0_ & 0x00200000) == 0x00200000),
									getParentForChildren(),
									isClean());
					blobs_ = null;
				}
				return blobsBuilder_;
			}

			private java.util.List<java.lang.Float> blobsLr_ = java.util.Collections.emptyList();

			private void ensureBlobsLrIsMutable()
			{
				if (!((bitField0_ & 0x00400000) == 0x00400000))
				{
					blobsLr_ = new java.util.ArrayList<java.lang.Float>(blobsLr_);
					bitField0_ |= 0x00400000;
				}
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getBlobsLrList()
			{
				return java.util.Collections.unmodifiableList(blobsLr_);
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			@Override
			public int getBlobsLrCount()
			{
				return blobsLr_.size();
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			@Override
			public float getBlobsLr(int index)
			{
				return blobsLr_.get(index);
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder setBlobsLr(
					int index, float value)
			{
				ensureBlobsLrIsMutable();
				blobsLr_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder addBlobsLr(float value)
			{
				ensureBlobsLrIsMutable();
				blobsLr_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder addAllBlobsLr(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureBlobsLrIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, blobsLr_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float blobs_lr = 51;</code>
			 *
			 * <pre>
			 * The ratio that is multiplied on the global learning rate. If you want to
			 * set the learning ratio for one blob, you need to set it for all blobs.
			 * </pre>
			 */
			public Builder clearBlobsLr()
			{
				blobsLr_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00400000);
				onChanged();
				return this;
			}

			private java.util.List<java.lang.Float> weightDecay_ = java.util.Collections.emptyList();

			private void ensureWeightDecayIsMutable()
			{
				if (!((bitField0_ & 0x00800000) == 0x00800000))
				{
					weightDecay_ = new java.util.ArrayList<java.lang.Float>(weightDecay_);
					bitField0_ |= 0x00800000;
				}
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			@Override
			public java.util.List<java.lang.Float>
					getWeightDecayList()
			{
				return java.util.Collections.unmodifiableList(weightDecay_);
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			@Override
			public int getWeightDecayCount()
			{
				return weightDecay_.size();
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			@Override
			public float getWeightDecay(int index)
			{
				return weightDecay_.get(index);
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder setWeightDecay(
					int index, float value)
			{
				ensureWeightDecayIsMutable();
				weightDecay_.set(index, value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder addWeightDecay(float value)
			{
				ensureWeightDecayIsMutable();
				weightDecay_.add(value);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder addAllWeightDecay(
					java.lang.Iterable<? extends java.lang.Float> values)
			{
				ensureWeightDecayIsMutable();
				com.google.protobuf.AbstractMessageLite.Builder.addAll(
						values, weightDecay_);
				onChanged();
				return this;
			}

			/**
			 * <code>repeated float weight_decay = 52;</code>
			 *
			 * <pre>
			 * The weight decay that is multiplied on the global weight decay.
			 * </pre>
			 */
			public Builder clearWeightDecay()
			{
				weightDecay_ = java.util.Collections.emptyList();
				bitField0_ = (bitField0_ & ~0x00800000);
				onChanged();
				return this;
			}

			private int randSkip_;

			/**
			 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			@Override
			public boolean hasRandSkip()
			{
				return ((bitField0_ & 0x01000000) == 0x01000000);
			}

			/**
			 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			@Override
			public int getRandSkip()
			{
				return randSkip_;
			}

			/**
			 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			public Builder setRandSkip(int value)
			{
				bitField0_ |= 0x01000000;
				randSkip_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 rand_skip = 53 [default = 0];</code>
			 *
			 * <pre>
			 * The rand_skip variable is for the data layer to skip a few data points
			 * to avoid all asynchronous sgd clients to start at the same point. The skip
			 * point would be set as rand_skip * rand(0,1). Note that rand_skip should not
			 * be larger than the number of keys in the leveldb.
			 * </pre>
			 */
			public Builder clearRandSkip()
			{
				bitField0_ = (bitField0_ & ~0x01000000);
				randSkip_ = 0;
				onChanged();
				return this;
			}

			private float detFgThreshold_ = 0.5F;

			/**
			 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
			 *
			 * <pre>
			 * Fields related to detection (det_*)
			 * foreground (object) overlap threshold
			 * </pre>
			 */
			@Override
			public boolean hasDetFgThreshold()
			{
				return ((bitField0_ & 0x02000000) == 0x02000000);
			}

			/**
			 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
			 *
			 * <pre>
			 * Fields related to detection (det_*)
			 * foreground (object) overlap threshold
			 * </pre>
			 */
			@Override
			public float getDetFgThreshold()
			{
				return detFgThreshold_;
			}

			/**
			 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
			 *
			 * <pre>
			 * Fields related to detection (det_*)
			 * foreground (object) overlap threshold
			 * </pre>
			 */
			public Builder setDetFgThreshold(float value)
			{
				bitField0_ |= 0x02000000;
				detFgThreshold_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float det_fg_threshold = 54 [default = 0.5];</code>
			 *
			 * <pre>
			 * Fields related to detection (det_*)
			 * foreground (object) overlap threshold
			 * </pre>
			 */
			public Builder clearDetFgThreshold()
			{
				bitField0_ = (bitField0_ & ~0x02000000);
				detFgThreshold_ = 0.5F;
				onChanged();
				return this;
			}

			private float detBgThreshold_ = 0.5F;

			/**
			 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
			 *
			 * <pre>
			 * background (non-object) overlap threshold
			 * </pre>
			 */
			@Override
			public boolean hasDetBgThreshold()
			{
				return ((bitField0_ & 0x04000000) == 0x04000000);
			}

			/**
			 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
			 *
			 * <pre>
			 * background (non-object) overlap threshold
			 * </pre>
			 */
			@Override
			public float getDetBgThreshold()
			{
				return detBgThreshold_;
			}

			/**
			 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
			 *
			 * <pre>
			 * background (non-object) overlap threshold
			 * </pre>
			 */
			public Builder setDetBgThreshold(float value)
			{
				bitField0_ |= 0x04000000;
				detBgThreshold_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float det_bg_threshold = 55 [default = 0.5];</code>
			 *
			 * <pre>
			 * background (non-object) overlap threshold
			 * </pre>
			 */
			public Builder clearDetBgThreshold()
			{
				bitField0_ = (bitField0_ & ~0x04000000);
				detBgThreshold_ = 0.5F;
				onChanged();
				return this;
			}

			private float detFgFraction_ = 0.25F;

			/**
			 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			@Override
			public boolean hasDetFgFraction()
			{
				return ((bitField0_ & 0x08000000) == 0x08000000);
			}

			/**
			 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			@Override
			public float getDetFgFraction()
			{
				return detFgFraction_;
			}

			/**
			 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			public Builder setDetFgFraction(float value)
			{
				bitField0_ |= 0x08000000;
				detFgFraction_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional float det_fg_fraction = 56 [default = 0.25];</code>
			 *
			 * <pre>
			 * Fraction of batch that should be foreground objects
			 * </pre>
			 */
			public Builder clearDetFgFraction()
			{
				bitField0_ = (bitField0_ & ~0x08000000);
				detFgFraction_ = 0.25F;
				onChanged();
				return this;
			}

			private int detContextPad_;

			/**
			 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			@Override
			public boolean hasDetContextPad()
			{
				return ((bitField0_ & 0x10000000) == 0x10000000);
			}

			/**
			 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			@Override
			public int getDetContextPad()
			{
				return detContextPad_;
			}

			/**
			 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			public Builder setDetContextPad(int value)
			{
				bitField0_ |= 0x10000000;
				detContextPad_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 det_context_pad = 58 [default = 0];</code>
			 *
			 * <pre>
			 * Amount of contextual padding to add around a window
			 * (used only by the window_data_layer)
			 * </pre>
			 */
			public Builder clearDetContextPad()
			{
				bitField0_ = (bitField0_ & ~0x10000000);
				detContextPad_ = 0;
				onChanged();
				return this;
			}

			private java.lang.Object detCropMode_ = "warp";

			/**
			 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			@Override
			public boolean hasDetCropMode()
			{
				return ((bitField0_ & 0x20000000) == 0x20000000);
			}

			/**
			 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			@Override
			public java.lang.String getDetCropMode()
			{
				java.lang.Object ref = detCropMode_;
				if (!(ref instanceof java.lang.String))
				{
					com.google.protobuf.ByteString bs =
							(com.google.protobuf.ByteString) ref;
					java.lang.String s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						detCropMode_ = s;
					}
					return s;
				} else
				{
					return (java.lang.String) ref;
				}
			}

			/**
			 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			@Override
			public com.google.protobuf.ByteString
					getDetCropModeBytes()
			{
				java.lang.Object ref = detCropMode_;
				if (ref instanceof String)
				{
					com.google.protobuf.ByteString b =
							com.google.protobuf.ByteString.copyFromUtf8(
									(java.lang.String) ref);
					detCropMode_ = b;
					return b;
				} else
				{
					return (com.google.protobuf.ByteString) ref;
				}
			}

			/**
			 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			public Builder setDetCropMode(
					java.lang.String value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x20000000;
				detCropMode_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			public Builder clearDetCropMode()
			{
				bitField0_ = (bitField0_ & ~0x20000000);
				detCropMode_ = getDefaultInstance().getDetCropMode();
				onChanged();
				return this;
			}

			/**
			 * <code>optional string det_crop_mode = 59 [default = "warp"];</code>
			 *
			 * <pre>
			 * Mode for cropping out a detection window
			 * warp: cropped window is warped to a fixed size and aspect ratio
			 * square: the tightest square around the window is cropped
			 * </pre>
			 */
			public Builder setDetCropModeBytes(
					com.google.protobuf.ByteString value)
			{
				if (value == null)
				{
					throw new NullPointerException();
				}
				bitField0_ |= 0x20000000;
				detCropMode_ = value;
				onChanged();
				return this;
			}

			private int newNum_;

			/**
			 * <code>optional int32 new_num = 60 [default = 0];</code>
			 *
			 * <pre>
			 * For ReshapeLayer, one needs to specify the new dimensions.
			 * </pre>
			 */
			@Override
			public boolean hasNewNum()
			{
				return ((bitField0_ & 0x40000000) == 0x40000000);
			}

			/**
			 * <code>optional int32 new_num = 60 [default = 0];</code>
			 *
			 * <pre>
			 * For ReshapeLayer, one needs to specify the new dimensions.
			 * </pre>
			 */
			@Override
			public int getNewNum()
			{
				return newNum_;
			}

			/**
			 * <code>optional int32 new_num = 60 [default = 0];</code>
			 *
			 * <pre>
			 * For ReshapeLayer, one needs to specify the new dimensions.
			 * </pre>
			 */
			public Builder setNewNum(int value)
			{
				bitField0_ |= 0x40000000;
				newNum_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 new_num = 60 [default = 0];</code>
			 *
			 * <pre>
			 * For ReshapeLayer, one needs to specify the new dimensions.
			 * </pre>
			 */
			public Builder clearNewNum()
			{
				bitField0_ = (bitField0_ & ~0x40000000);
				newNum_ = 0;
				onChanged();
				return this;
			}

			private int newChannels_;

			/**
			 * <code>optional int32 new_channels = 61 [default = 0];</code>
			 */
			@Override
			public boolean hasNewChannels()
			{
				return ((bitField0_ & 0x80000000) == 0x80000000);
			}

			/**
			 * <code>optional int32 new_channels = 61 [default = 0];</code>
			 */
			@Override
			public int getNewChannels()
			{
				return newChannels_;
			}

			/**
			 * <code>optional int32 new_channels = 61 [default = 0];</code>
			 */
			public Builder setNewChannels(int value)
			{
				bitField0_ |= 0x80000000;
				newChannels_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 new_channels = 61 [default = 0];</code>
			 */
			public Builder clearNewChannels()
			{
				bitField0_ = (bitField0_ & ~0x80000000);
				newChannels_ = 0;
				onChanged();
				return this;
			}

			private int newHeight_;

			/**
			 * <code>optional int32 new_height = 62 [default = 0];</code>
			 */
			@Override
			public boolean hasNewHeight()
			{
				return ((bitField1_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>optional int32 new_height = 62 [default = 0];</code>
			 */
			@Override
			public int getNewHeight()
			{
				return newHeight_;
			}

			/**
			 * <code>optional int32 new_height = 62 [default = 0];</code>
			 */
			public Builder setNewHeight(int value)
			{
				bitField1_ |= 0x00000001;
				newHeight_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 new_height = 62 [default = 0];</code>
			 */
			public Builder clearNewHeight()
			{
				bitField1_ = (bitField1_ & ~0x00000001);
				newHeight_ = 0;
				onChanged();
				return this;
			}

			private int newWidth_;

			/**
			 * <code>optional int32 new_width = 63 [default = 0];</code>
			 */
			@Override
			public boolean hasNewWidth()
			{
				return ((bitField1_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional int32 new_width = 63 [default = 0];</code>
			 */
			@Override
			public int getNewWidth()
			{
				return newWidth_;
			}

			/**
			 * <code>optional int32 new_width = 63 [default = 0];</code>
			 */
			public Builder setNewWidth(int value)
			{
				bitField1_ |= 0x00000002;
				newWidth_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 new_width = 63 [default = 0];</code>
			 */
			public Builder clearNewWidth()
			{
				bitField1_ = (bitField1_ & ~0x00000002);
				newWidth_ = 0;
				onChanged();
				return this;
			}

			private boolean shuffleImages_;

			/**
			 * <code>optional bool shuffle_images = 64 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			@Override
			public boolean hasShuffleImages()
			{
				return ((bitField1_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional bool shuffle_images = 64 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			@Override
			public boolean getShuffleImages()
			{
				return shuffleImages_;
			}

			/**
			 * <code>optional bool shuffle_images = 64 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			public Builder setShuffleImages(boolean value)
			{
				bitField1_ |= 0x00000004;
				shuffleImages_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool shuffle_images = 64 [default = false];</code>
			 *
			 * <pre>
			 * Whether or not ImageLayer should shuffle the list of files at every epoch.
			 * It will also resize images if new_height or new_width are not zero.
			 * </pre>
			 */
			public Builder clearShuffleImages()
			{
				bitField1_ = (bitField1_ & ~0x00000004);
				shuffleImages_ = false;
				onChanged();
				return this;
			}

			private int concatDim_ = 1;

			/**
			 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
			 *
			 * <pre>
			 * For ConcatLayer, one needs to specify the dimension for concatenation, and
			 * the other dimensions must be the same for all the bottom blobs.
			 * By default it will concatenate blobs along the channels dimension.
			 * </pre>
			 */
			@Override
			public boolean hasConcatDim()
			{
				return ((bitField1_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
			 *
			 * <pre>
			 * For ConcatLayer, one needs to specify the dimension for concatenation, and
			 * the other dimensions must be the same for all the bottom blobs.
			 * By default it will concatenate blobs along the channels dimension.
			 * </pre>
			 */
			@Override
			public int getConcatDim()
			{
				return concatDim_;
			}

			/**
			 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
			 *
			 * <pre>
			 * For ConcatLayer, one needs to specify the dimension for concatenation, and
			 * the other dimensions must be the same for all the bottom blobs.
			 * By default it will concatenate blobs along the channels dimension.
			 * </pre>
			 */
			public Builder setConcatDim(int value)
			{
				bitField1_ |= 0x00000008;
				concatDim_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint32 concat_dim = 65 [default = 1];</code>
			 *
			 * <pre>
			 * For ConcatLayer, one needs to specify the dimension for concatenation, and
			 * the other dimensions must be the same for all the bottom blobs.
			 * By default it will concatenate blobs along the channels dimension.
			 * </pre>
			 */
			public Builder clearConcatDim()
			{
				bitField1_ = (bitField1_ & ~0x00000008);
				concatDim_ = 1;
				onChanged();
				return this;
			}

			private com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter
					.getDefaultInstance();
			private com.google.protobuf.SingleFieldBuilder<com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder> hdf5OutputParamBuilder_;

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			@Override
			public boolean hasHdf5OutputParam()
			{
				return ((bitField1_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter getHdf5OutputParam()
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					return hdf5OutputParam_;
				} else
				{
					return hdf5OutputParamBuilder_.getMessage();
				}
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			public Builder setHdf5OutputParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter value)
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					if (value == null)
					{
						throw new NullPointerException();
					}
					hdf5OutputParam_ = value;
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.setMessage(value);
				}
				bitField1_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			public Builder setHdf5OutputParam(
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder builderForValue)
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParam_ = builderForValue.build();
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.setMessage(builderForValue.build());
				}
				bitField1_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			public Builder mergeHdf5OutputParam(com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter value)
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					if (((bitField1_ & 0x00000010) == 0x00000010) &&
							hdf5OutputParam_ != com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance())
					{
						hdf5OutputParam_ =
								com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.newBuilder(hdf5OutputParam_).mergeFrom(value).buildPartial();
					} else
					{
						hdf5OutputParam_ = value;
					}
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.mergeFrom(value);
				}
				bitField1_ |= 0x00000010;
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			public Builder clearHdf5OutputParam()
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParam_ = com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.getDefaultInstance();
					onChanged();
				} else
				{
					hdf5OutputParamBuilder_.clear();
				}
				bitField1_ = (bitField1_ & ~0x00000010);
				return this;
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder getHdf5OutputParamBuilder()
			{
				bitField1_ |= 0x00000010;
				onChanged();
				return getHdf5OutputParamFieldBuilder().getBuilder();
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			@Override
			public com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder getHdf5OutputParamOrBuilder()
			{
				if (hdf5OutputParamBuilder_ != null)
				{
					return hdf5OutputParamBuilder_.getMessageOrBuilder();
				} else
				{
					return hdf5OutputParam_;
				}
			}

			/**
			 * <code>optional .caffe.HDF5OutputParameter hdf5_output_param = 1001;</code>
			 */
			private com.google.protobuf.SingleFieldBuilder<
					com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder>
					getHdf5OutputParamFieldBuilder()
			{
				if (hdf5OutputParamBuilder_ == null)
				{
					hdf5OutputParamBuilder_ = new com.google.protobuf.SingleFieldBuilder<
							com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameter.Builder, com.github.neuralnetworks.builder.designio.protobuf.ProtoBufWrapper.HDF5OutputParameterOrBuilder>(
									getHdf5OutputParam(),
									getParentForChildren(),
									isClean());
					hdf5OutputParam_ = null;
				}
				return hdf5OutputParamBuilder_;
			}

			// @@protoc_insertion_point(builder_scope:caffe.V0LayerParameter)
		}

		static
		{
			defaultInstance = new V0LayerParameter(true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)
	}

	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_BlobProto_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_BlobProto_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_BlobProtoVector_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_BlobProtoVector_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_Datum_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_Datum_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_FillerParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_FillerParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_NetParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_NetParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_SolverParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_SolverParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_SolverState_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_SolverState_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_NetState_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_NetState_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_NetStateRule_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_NetStateRule_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_LayerParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_LayerParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_TransformationParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_TransformationParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_AccuracyParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_AccuracyParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ArgMaxParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ArgMaxParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ConcatParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ConcatParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ContrastiveLossParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ContrastiveLossParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ConvolutionParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ConvolutionParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_DataParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_DataParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_DropoutParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_DropoutParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_DummyDataParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_DummyDataParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_EltwiseParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_EltwiseParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ThresholdParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ThresholdParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_HDF5DataParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_HDF5DataParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_HDF5OutputParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_HDF5OutputParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_HingeLossParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_HingeLossParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ImageDataParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ImageDataParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_InfogainLossParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_InfogainLossParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_InnerProductParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_InnerProductParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_LRNParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_LRNParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_MemoryDataParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_MemoryDataParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_MVNParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_MVNParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_PoolingParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_PoolingParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_PowerParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_PowerParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_ReLUParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_ReLUParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_SigmoidParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_SigmoidParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_SliceParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_SliceParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_SoftmaxParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_SoftmaxParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_TanHParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_TanHParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_WindowDataParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_WindowDataParameter_fieldAccessorTable;
	private static final com.google.protobuf.Descriptors.Descriptor internal_static_caffe_V0LayerParameter_descriptor;
	private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_caffe_V0LayerParameter_fieldAccessorTable;

	public static com.google.protobuf.Descriptors.FileDescriptor
			getDescriptor()
	{
		return descriptor;
	}

	private static com.google.protobuf.Descriptors.FileDescriptor descriptor;
	static
	{
		java.lang.String[] descriptorData = {
				"\n\014caffe2.proto\022\005caffe\"y\n\tBlobProto\022\016\n\003nu" +
						"m\030\001 \001(\005:\0010\022\023\n\010channels\030\002 \001(\005:\0010\022\021\n\006heigh" +
						"t\030\003 \001(\005:\0010\022\020\n\005width\030\004 \001(\005:\0010\022\020\n\004data\030\005 \003" +
						"(\002B\002\020\001\022\020\n\004diff\030\006 \003(\002B\002\020\001\"2\n\017BlobProtoVec" +
						"tor\022\037\n\005blobs\030\001 \003(\0132\020.caffe.BlobProto\"i\n\005" +
						"Datum\022\020\n\010channels\030\001 \001(\005\022\016\n\006height\030\002 \001(\005\022" +
						"\r\n\005width\030\003 \001(\005\022\014\n\004data\030\004 \001(\014\022\r\n\005label\030\005 " +
						"\001(\005\022\022\n\nfloat_data\030\006 \003(\002\"\220\001\n\017FillerParame" +
						"ter\022\026\n\004type\030\001 \001(\t:\010constant\022\020\n\005value\030\002 \001" +
						"(\002:\0010\022\016\n\003min\030\003 \001(\002:\0010\022\016\n\003max\030\004 \001(\002:\0011\022\017\n",
				"\004mean\030\005 \001(\002:\0010\022\016\n\003std\030\006 \001(\002:\0011\022\022\n\006sparse" +
						"\030\007 \001(\005:\002-1\"\244\001\n\014NetParameter\022\014\n\004name\030\001 \001(" +
						"\t\022%\n\006layers\030\002 \003(\0132\025.caffe.LayerParameter" +
						"\022\r\n\005input\030\003 \003(\t\022\021\n\tinput_dim\030\004 \003(\005\022\035\n\016fo" +
						"rce_backward\030\005 \001(\010:\005false\022\036\n\005state\030\006 \001(\013" +
						"2\017.caffe.NetState\"\214\010\n\017SolverParameter\022\013\n" +
						"\003net\030\030 \001(\t\022&\n\tnet_param\030\031 \001(\0132\023.caffe.Ne" +
						"tParameter\022\021\n\ttrain_net\030\001 \001(\t\022\020\n\010test_ne" +
						"t\030\002 \003(\t\022,\n\017train_net_param\030\025 \001(\0132\023.caffe" +
						".NetParameter\022+\n\016test_net_param\030\026 \003(\0132\023.",
				"caffe.NetParameter\022$\n\013train_state\030\032 \001(\0132" +
						"\017.caffe.NetState\022#\n\ntest_state\030\033 \003(\0132\017.c" +
						"affe.NetState\022\021\n\ttest_iter\030\003 \003(\005\022\030\n\rtest" +
						"_interval\030\004 \001(\005:\0010\022 \n\021test_compute_loss\030" +
						"\023 \001(\010:\005false\022!\n\023test_initialization\030  \001(" +
						"\010:\004true\022\017\n\007base_lr\030\005 \001(\002\022\017\n\007display\030\006 \001(" +
						"\005\022\027\n\014average_loss\030! \001(\005:\0011\022\020\n\010max_iter\030\007" +
						" \001(\005\022\021\n\tlr_policy\030\010 \001(\t\022\r\n\005gamma\030\t \001(\002\022\r" +
						"\n\005power\030\n \001(\002\022\020\n\010momentum\030\013 \001(\002\022\024\n\014weigh" +
						"t_decay\030\014 \001(\002\022\037\n\023regularization_type\030\035 \001",
				"(\t:\002L2\022\020\n\010stepsize\030\r \001(\005\022\021\n\tstepvalue\030\" " +
						"\003(\005\022\023\n\010snapshot\030\016 \001(\005:\0010\022\027\n\017snapshot_pre" +
						"fix\030\017 \001(\t\022\034\n\rsnapshot_diff\030\020 \001(\010:\005false\022" +
						";\n\013solver_mode\030\021 \001(\0162!.caffe.SolverParam" +
						"eter.SolverMode:\003GPU\022\024\n\tdevice_id\030\022 \001(\005:" +
						"\0010\022\027\n\013random_seed\030\024 \001(\003:\002-1\022;\n\013solver_ty" +
						"pe\030\036 \001(\0162!.caffe.SolverParameter.SolverT" +
						"ype:\003SGD\022\025\n\005delta\030\037 \001(\002:\0061e-008\022\031\n\ndebug" +
						"_info\030\027 \001(\010:\005false\022\"\n\024snapshot_after_tra" +
						"in\030\034 \001(\010:\004true\"\036\n\nSolverMode\022\007\n\003CPU\020\000\022\007\n",
				"\003GPU\020\001\"0\n\nSolverType\022\007\n\003SGD\020\000\022\014\n\010NESTERO" +
						"V\020\001\022\013\n\007ADAGRAD\020\002\"l\n\013SolverState\022\014\n\004iter\030" +
						"\001 \001(\005\022\023\n\013learned_net\030\002 \001(\t\022!\n\007history\030\003 " +
						"\003(\0132\020.caffe.BlobProto\022\027\n\014current_step\030\004 " +
						"\001(\005:\0010\"N\n\010NetState\022!\n\005phase\030\001 \001(\0162\014.caff" +
						"e.Phase:\004TEST\022\020\n\005level\030\002 \001(\005:\0010\022\r\n\005stage" +
						"\030\003 \003(\t\"s\n\014NetStateRule\022\033\n\005phase\030\001 \001(\0162\014." +
						"caffe.Phase\022\021\n\tmin_level\030\002 \001(\005\022\021\n\tmax_le" +
						"vel\030\003 \001(\005\022\r\n\005stage\030\004 \003(\t\022\021\n\tnot_stage\030\005 " +
						"\003(\t\"\354\022\n\016LayerParameter\022\016\n\006bottom\030\002 \003(\t\022\013",
				"\n\003top\030\003 \003(\t\022\014\n\004name\030\004 \001(\t\022$\n\007include\030  \003" +
						"(\0132\023.caffe.NetStateRule\022$\n\007exclude\030! \003(\013" +
						"2\023.caffe.NetStateRule\022-\n\004type\030\005 \001(\0162\037.ca" +
						"ffe.LayerParameter.LayerType\022\037\n\005blobs\030\006 " +
						"\003(\0132\020.caffe.BlobProto\022\016\n\005param\030\351\007 \003(\t\022<\n" +
						"\017blob_share_mode\030\352\007 \003(\0162\".caffe.LayerPar" +
						"ameter.DimCheckMode\022\020\n\010blobs_lr\030\007 \003(\002\022\024\n" +
						"\014weight_decay\030\010 \003(\002\022\023\n\013loss_weight\030# \003(\002" +
						"\0220\n\016accuracy_param\030\033 \001(\0132\030.caffe.Accurac" +
						"yParameter\022,\n\014argmax_param\030\027 \001(\0132\026.caffe",
				".ArgMaxParameter\022,\n\014concat_param\030\t \001(\0132\026" +
						".caffe.ConcatParameter\022?\n\026contrastive_lo" +
						"ss_param\030( \001(\0132\037.caffe.ContrastiveLossPa" +
						"rameter\0226\n\021convolution_param\030\n \001(\0132\033.caf" +
						"fe.ConvolutionParameter\022(\n\ndata_param\030\013 " +
						"\001(\0132\024.caffe.DataParameter\022.\n\rdropout_par" +
						"am\030\014 \001(\0132\027.caffe.DropoutParameter\0223\n\020dum" +
						"my_data_param\030\032 \001(\0132\031.caffe.DummyDataPar" +
						"ameter\022.\n\reltwise_param\030\030 \001(\0132\027.caffe.El" +
						"twiseParameter\0221\n\017hdf5_data_param\030\r \001(\0132",
				"\030.caffe.HDF5DataParameter\0225\n\021hdf5_output" +
						"_param\030\016 \001(\0132\032.caffe.HDF5OutputParameter" +
						"\0223\n\020hinge_loss_param\030\035 \001(\0132\031.caffe.Hinge" +
						"LossParameter\0223\n\020image_data_param\030\017 \001(\0132" +
						"\031.caffe.ImageDataParameter\0229\n\023infogain_l" +
						"oss_param\030\020 \001(\0132\034.caffe.InfogainLossPara" +
						"meter\0229\n\023inner_product_param\030\021 \001(\0132\034.caf" +
						"fe.InnerProductParameter\022&\n\tlrn_param\030\022 " +
						"\001(\0132\023.caffe.LRNParameter\0225\n\021memory_data_" +
						"param\030\026 \001(\0132\032.caffe.MemoryDataParameter\022",
				"&\n\tmvn_param\030\" \001(\0132\023.caffe.MVNParameter\022" +
						".\n\rpooling_param\030\023 \001(\0132\027.caffe.PoolingPa" +
						"rameter\022*\n\013power_param\030\025 \001(\0132\025.caffe.Pow" +
						"erParameter\022(\n\nrelu_param\030\036 \001(\0132\024.caffe." +
						"ReLUParameter\022.\n\rsigmoid_param\030& \001(\0132\027.c" +
						"affe.SigmoidParameter\022.\n\rsoftmax_param\030\'" +
						" \001(\0132\027.caffe.SoftmaxParameter\022*\n\013slice_p" +
						"aram\030\037 \001(\0132\025.caffe.SliceParameter\022(\n\ntan" +
						"h_param\030% \001(\0132\024.caffe.TanHParameter\0222\n\017t" +
						"hreshold_param\030\031 \001(\0132\031.caffe.ThresholdPa",
				"rameter\0225\n\021window_data_param\030\024 \001(\0132\032.caf" +
						"fe.WindowDataParameter\0227\n\017transform_para" +
						"m\030$ \001(\0132\036.caffe.TransformationParameter\022" +
						"&\n\005layer\030\001 \001(\0132\027.caffe.V0LayerParameter\"" +
						"\274\004\n\tLayerType\022\010\n\004NONE\020\000\022\n\n\006ABSVAL\020#\022\014\n\010A" +
						"CCURACY\020\001\022\n\n\006ARGMAX\020\036\022\010\n\004BNLL\020\002\022\n\n\006CONCA" +
						"T\020\003\022\024\n\020CONTRASTIVE_LOSS\020%\022\017\n\013CONVOLUTION" +
						"\020\004\022\010\n\004DATA\020\005\022\013\n\007DROPOUT\020\006\022\016\n\nDUMMY_DATA\020" +
						" \022\022\n\016EUCLIDEAN_LOSS\020\007\022\013\n\007ELTWISE\020\031\022\013\n\007FL" +
						"ATTEN\020\010\022\r\n\tHDF5_DATA\020\t\022\017\n\013HDF5_OUTPUT\020\n\022",
				"\016\n\nHINGE_LOSS\020\034\022\n\n\006IM2COL\020\013\022\016\n\nIMAGE_DAT" +
						"A\020\014\022\021\n\rINFOGAIN_LOSS\020\r\022\021\n\rINNER_PRODUCT\020" +
						"\016\022\007\n\003LRN\020\017\022\017\n\013MEMORY_DATA\020\035\022\035\n\031MULTINOMI" +
						"AL_LOGISTIC_LOSS\020\020\022\007\n\003MVN\020\"\022\013\n\007POOLING\020\021" +
						"\022\t\n\005POWER\020\032\022\010\n\004RELU\020\022\022\013\n\007SIGMOID\020\023\022\036\n\032SI" +
						"GMOID_CROSS_ENTROPY_LOSS\020\033\022\013\n\007SILENCE\020$\022" +
						"\013\n\007SOFTMAX\020\024\022\020\n\014SOFTMAX_LOSS\020\025\022\t\n\005SPLIT\020" +
						"\026\022\t\n\005SLICE\020!\022\010\n\004TANH\020\027\022\017\n\013WINDOW_DATA\020\030\022" +
						"\r\n\tTHRESHOLD\020\037\"*\n\014DimCheckMode\022\n\n\006STRICT" +
						"\020\000\022\016\n\nPERMISSIVE\020\001\"k\n\027TransformationPara",
				"meter\022\020\n\005scale\030\001 \001(\002:\0011\022\025\n\006mirror\030\002 \001(\010:" +
						"\005false\022\024\n\tcrop_size\030\003 \001(\r:\0010\022\021\n\tmean_fil" +
						"e\030\004 \001(\t\"%\n\021AccuracyParameter\022\020\n\005top_k\030\001 " +
						"\001(\r:\0011\"?\n\017ArgMaxParameter\022\032\n\013out_max_val" +
						"\030\001 \001(\010:\005false\022\020\n\005top_k\030\002 \001(\r:\0011\"(\n\017Conca" +
						"tParameter\022\025\n\nconcat_dim\030\001 \001(\r:\0011\"-\n\030Con" +
						"trastiveLossParameter\022\021\n\006margin\030\001 \001(\002:\0011" +
						"\"\277\003\n\024ConvolutionParameter\022\022\n\nnum_output\030" +
						"\001 \001(\r\022\027\n\tbias_term\030\002 \001(\010:\004true\022\016\n\003pad\030\003 " +
						"\001(\r:\0010\022\020\n\005pad_h\030\t \001(\r:\0010\022\020\n\005pad_w\030\n \001(\r:",
				"\0010\022\023\n\013kernel_size\030\004 \001(\r\022\020\n\010kernel_h\030\013 \001(" +
						"\r\022\020\n\010kernel_w\030\014 \001(\r\022\020\n\005group\030\005 \001(\r:\0011\022\021\n" +
						"\006stride\030\006 \001(\r:\0011\022\020\n\010stride_h\030\r \001(\r\022\020\n\010st" +
						"ride_w\030\016 \001(\r\022-\n\rweight_filler\030\007 \001(\0132\026.ca" +
						"ffe.FillerParameter\022+\n\013bias_filler\030\010 \001(\013" +
						"2\026.caffe.FillerParameter\022;\n\006engine\030\017 \001(\016" +
						"2\".caffe.ConvolutionParameter.Engine:\007DE" +
						"FAULT\"+\n\006Engine\022\013\n\007DEFAULT\020\000\022\t\n\005CAFFE\020\001\022" +
						"\t\n\005CUDNN\020\002\"\353\001\n\rDataParameter\022\016\n\006source\030\001" +
						" \001(\t\022\022\n\nbatch_size\030\004 \001(\r\022\024\n\trand_skip\030\007 ",
				"\001(\r:\0010\0221\n\007backend\030\010 \001(\0162\027.caffe.DataPara" +
						"meter.DB:\007LEVELDB\022\020\n\005scale\030\002 \001(\002:\0011\022\021\n\tm" +
						"ean_file\030\003 \001(\t\022\024\n\tcrop_size\030\005 \001(\r:\0010\022\025\n\006" +
						"mirror\030\006 \001(\010:\005false\"\033\n\002DB\022\013\n\007LEVELDB\020\000\022\010" +
						"\n\004LMDB\020\001\".\n\020DropoutParameter\022\032\n\rdropout_" +
						"ratio\030\001 \001(\002:\0030.5\"\177\n\022DummyDataParameter\022+" +
						"\n\013data_filler\030\001 \003(\0132\026.caffe.FillerParame" +
						"ter\022\013\n\003num\030\002 \003(\r\022\020\n\010channels\030\003 \003(\r\022\016\n\006he" +
						"ight\030\004 \003(\r\022\r\n\005width\030\005 \003(\r\"\245\001\n\020EltwisePar" +
						"ameter\0229\n\toperation\030\001 \001(\0162!.caffe.Eltwis",
				"eParameter.EltwiseOp:\003SUM\022\r\n\005coeff\030\002 \003(\002" +
						"\022\036\n\020stable_prod_grad\030\003 \001(\010:\004true\"\'\n\tEltw" +
						"iseOp\022\010\n\004PROD\020\000\022\007\n\003SUM\020\001\022\007\n\003MAX\020\002\"*\n\022Thr" +
						"esholdParameter\022\024\n\tthreshold\030\001 \001(\002:\0010\"7\n" +
						"\021HDF5DataParameter\022\016\n\006source\030\001 \001(\t\022\022\n\nba" +
						"tch_size\030\002 \001(\r\"(\n\023HDF5OutputParameter\022\021\n" +
						"\tfile_name\030\001 \001(\t\"^\n\022HingeLossParameter\0220" +
						"\n\004norm\030\001 \001(\0162\036.caffe.HingeLossParameter." +
						"Norm:\002L1\"\026\n\004Norm\022\006\n\002L1\020\001\022\006\n\002L2\020\002\"\345\001\n\022Ima" +
						"geDataParameter\022\016\n\006source\030\001 \001(\t\022\022\n\nbatch",
				"_size\030\004 \001(\r\022\024\n\trand_skip\030\007 \001(\r:\0010\022\026\n\007shu" +
						"ffle\030\010 \001(\010:\005false\022\025\n\nnew_height\030\t \001(\r:\0010" +
						"\022\024\n\tnew_width\030\n \001(\r:\0010\022\020\n\005scale\030\002 \001(\002:\0011" +
						"\022\021\n\tmean_file\030\003 \001(\t\022\024\n\tcrop_size\030\005 \001(\r:\001" +
						"0\022\025\n\006mirror\030\006 \001(\010:\005false\"\'\n\025InfogainLoss" +
						"Parameter\022\016\n\006source\030\001 \001(\t\"\240\001\n\025InnerProdu" +
						"ctParameter\022\022\n\nnum_output\030\001 \001(\r\022\027\n\tbias_" +
						"term\030\002 \001(\010:\004true\022-\n\rweight_filler\030\003 \001(\0132" +
						"\026.caffe.FillerParameter\022+\n\013bias_filler\030\004" +
						" \001(\0132\026.caffe.FillerParameter\"\310\001\n\014LRNPara",
				"meter\022\025\n\nlocal_size\030\001 \001(\r:\0015\022\020\n\005alpha\030\002 " +
						"\001(\002:\0011\022\022\n\004beta\030\003 \001(\002:\0040.75\022D\n\013norm_regio" +
						"n\030\004 \001(\0162\036.caffe.LRNParameter.NormRegion:" +
						"\017ACROSS_CHANNELS\"5\n\nNormRegion\022\023\n\017ACROSS" +
						"_CHANNELS\020\000\022\022\n\016WITHIN_CHANNEL\020\001\"Z\n\023Memor" +
						"yDataParameter\022\022\n\nbatch_size\030\001 \001(\r\022\020\n\010ch" +
						"annels\030\002 \001(\r\022\016\n\006height\030\003 \001(\r\022\r\n\005width\030\004 " +
						"\001(\r\"P\n\014MVNParameter\022 \n\022normalize_varianc" +
						"e\030\001 \001(\010:\004true\022\036\n\017across_channels\030\002 \001(\010:\005" +
						"false\"\203\003\n\020PoolingParameter\0225\n\004pool\030\001 \001(\016",
				"2\".caffe.PoolingParameter.PoolMethod:\003MA" +
						"X\022\016\n\003pad\030\004 \001(\r:\0010\022\020\n\005pad_h\030\t \001(\r:\0010\022\020\n\005p" +
						"ad_w\030\n \001(\r:\0010\022\023\n\013kernel_size\030\002 \001(\r\022\020\n\010ke" +
						"rnel_h\030\005 \001(\r\022\020\n\010kernel_w\030\006 \001(\r\022\021\n\006stride" +
						"\030\003 \001(\r:\0011\022\020\n\010stride_h\030\007 \001(\r\022\020\n\010stride_w\030" +
						"\010 \001(\r\0227\n\006engine\030\013 \001(\0162\036.caffe.PoolingPar" +
						"ameter.Engine:\007DEFAULT\".\n\nPoolMethod\022\007\n\003" +
						"MAX\020\000\022\007\n\003AVE\020\001\022\016\n\nSTOCHASTIC\020\002\"+\n\006Engine" +
						"\022\013\n\007DEFAULT\020\000\022\t\n\005CAFFE\020\001\022\t\n\005CUDNN\020\002\"F\n\016P" +
						"owerParameter\022\020\n\005power\030\001 \001(\002:\0011\022\020\n\005scale",
				"\030\002 \001(\002:\0011\022\020\n\005shift\030\003 \001(\002:\0010\"\215\001\n\rReLUPara" +
						"meter\022\031\n\016negative_slope\030\001 \001(\002:\0010\0224\n\006engi" +
						"ne\030\002 \001(\0162\033.caffe.ReLUParameter.Engine:\007D" +
						"EFAULT\"+\n\006Engine\022\013\n\007DEFAULT\020\000\022\t\n\005CAFFE\020\001" +
						"\022\t\n\005CUDNN\020\002\"x\n\020SigmoidParameter\0227\n\006engin" +
						"e\030\001 \001(\0162\036.caffe.SigmoidParameter.Engine:" +
						"\007DEFAULT\"+\n\006Engine\022\013\n\007DEFAULT\020\000\022\t\n\005CAFFE" +
						"\020\001\022\t\n\005CUDNN\020\002\";\n\016SliceParameter\022\024\n\tslice" +
						"_dim\030\001 \001(\r:\0011\022\023\n\013slice_point\030\002 \003(\r\"x\n\020So" +
						"ftmaxParameter\0227\n\006engine\030\001 \001(\0162\036.caffe.S",
				"oftmaxParameter.Engine:\007DEFAULT\"+\n\006Engin" +
						"e\022\013\n\007DEFAULT\020\000\022\t\n\005CAFFE\020\001\022\t\n\005CUDNN\020\002\"r\n\r" +
						"TanHParameter\0224\n\006engine\030\001 \001(\0162\033.caffe.Ta" +
						"nHParameter.Engine:\007DEFAULT\"+\n\006Engine\022\013\n" +
						"\007DEFAULT\020\000\022\t\n\005CAFFE\020\001\022\t\n\005CUDNN\020\002\"\215\002\n\023Win" +
						"dowDataParameter\022\016\n\006source\030\001 \001(\t\022\020\n\005scal" +
						"e\030\002 \001(\002:\0011\022\021\n\tmean_file\030\003 \001(\t\022\022\n\nbatch_s" +
						"ize\030\004 \001(\r\022\024\n\tcrop_size\030\005 \001(\r:\0010\022\025\n\006mirro" +
						"r\030\006 \001(\010:\005false\022\031\n\014fg_threshold\030\007 \001(\002:\0030." +
						"5\022\031\n\014bg_threshold\030\010 \001(\002:\0030.5\022\031\n\013fg_fract",
				"ion\030\t \001(\002:\0040.25\022\026\n\013context_pad\030\n \001(\r:\0010\022" +
						"\027\n\tcrop_mode\030\013 \001(\t:\004warp\"\357\007\n\020V0LayerPara" +
						"meter\022\014\n\004name\030\001 \001(\t\022\014\n\004type\030\002 \001(\t\022\022\n\nnum" +
						"_output\030\003 \001(\r\022\026\n\010biasterm\030\004 \001(\010:\004true\022-\n" +
						"\rweight_filler\030\005 \001(\0132\026.caffe.FillerParam" +
						"eter\022+\n\013bias_filler\030\006 \001(\0132\026.caffe.Filler" +
						"Parameter\022\016\n\003pad\030\007 \001(\r:\0010\022\022\n\nkernelsize\030" +
						"\010 \001(\r\022\020\n\005group\030\t \001(\r:\0011\022\021\n\006stride\030\n \001(\r:" +
						"\0011\0225\n\004pool\030\013 \001(\0162\".caffe.V0LayerParamete" +
						"r.PoolMethod:\003MAX\022\032\n\rdropout_ratio\030\014 \001(\002",
				":\0030.5\022\025\n\nlocal_size\030\r \001(\r:\0015\022\020\n\005alpha\030\016 " +
						"\001(\002:\0011\022\022\n\004beta\030\017 \001(\002:\0040.75\022\016\n\006source\030\020 \001" +
						"(\t\022\020\n\005scale\030\021 \001(\002:\0011\022\020\n\010meanfile\030\022 \001(\t\022\021" +
						"\n\tbatchsize\030\023 \001(\r\022\023\n\010cropsize\030\024 \001(\r:\0010\022\025" +
						"\n\006mirror\030\025 \001(\010:\005false\022\037\n\005blobs\0302 \003(\0132\020.c" +
						"affe.BlobProto\022\020\n\010blobs_lr\0303 \003(\002\022\024\n\014weig" +
						"ht_decay\0304 \003(\002\022\024\n\trand_skip\0305 \001(\r:\0010\022\035\n\020" +
						"det_fg_threshold\0306 \001(\002:\0030.5\022\035\n\020det_bg_th" +
						"reshold\0307 \001(\002:\0030.5\022\035\n\017det_fg_fraction\0308 " +
						"\001(\002:\0040.25\022\032\n\017det_context_pad\030: \001(\r:\0010\022\033\n",
				"\rdet_crop_mode\030; \001(\t:\004warp\022\022\n\007new_num\030< " +
						"\001(\005:\0010\022\027\n\014new_channels\030= \001(\005:\0010\022\025\n\nnew_h" +
						"eight\030> \001(\005:\0010\022\024\n\tnew_width\030? \001(\005:\0010\022\035\n\016" +
						"shuffle_images\030@ \001(\010:\005false\022\025\n\nconcat_di" +
						"m\030A \001(\r:\0011\0226\n\021hdf5_output_param\030\351\007 \001(\0132\032" +
						".caffe.HDF5OutputParameter\".\n\nPoolMethod" +
						"\022\007\n\003MAX\020\000\022\007\n\003AVE\020\001\022\016\n\nSTOCHASTIC\020\002*\034\n\005Ph" +
						"ase\022\t\n\005TRAIN\020\000\022\010\n\004TEST\020\001BB\n/de.exb.neura" +
						"lnetworks.builder.designio.protobufB\017Pro" +
						"toBufWrapper"
		};
		com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
				new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner()
				{
					@Override
					public com.google.protobuf.ExtensionRegistry assignDescriptors(
							com.google.protobuf.Descriptors.FileDescriptor root)
					{
						descriptor = root;
						return null;
					}
				};
		com.google.protobuf.Descriptors.FileDescriptor
				.internalBuildGeneratedFileFrom(descriptorData,
						new com.google.protobuf.Descriptors.FileDescriptor[] {
						}, assigner);
		internal_static_caffe_BlobProto_descriptor =
				getDescriptor().getMessageTypes().get(0);
		internal_static_caffe_BlobProto_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_BlobProto_descriptor,
						new java.lang.String[] { "Num", "Channels", "Height", "Width", "Data", "Diff", });
		internal_static_caffe_BlobProtoVector_descriptor =
				getDescriptor().getMessageTypes().get(1);
		internal_static_caffe_BlobProtoVector_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_BlobProtoVector_descriptor,
						new java.lang.String[] { "Blobs", });
		internal_static_caffe_Datum_descriptor =
				getDescriptor().getMessageTypes().get(2);
		internal_static_caffe_Datum_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_Datum_descriptor,
						new java.lang.String[] { "Channels", "Height", "Width", "Data", "Label", "FloatData", });
		internal_static_caffe_FillerParameter_descriptor =
				getDescriptor().getMessageTypes().get(3);
		internal_static_caffe_FillerParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_FillerParameter_descriptor,
						new java.lang.String[] { "Type", "Value", "Min", "Max", "Mean", "Std", "Sparse", });
		internal_static_caffe_NetParameter_descriptor =
				getDescriptor().getMessageTypes().get(4);
		internal_static_caffe_NetParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_NetParameter_descriptor,
						new java.lang.String[] { "Name", "Layers", "Input", "InputDim", "ForceBackward", "State", });
		internal_static_caffe_SolverParameter_descriptor =
				getDescriptor().getMessageTypes().get(5);
		internal_static_caffe_SolverParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_SolverParameter_descriptor,
						new java.lang.String[] { "Net", "NetParam", "TrainNet", "TestNet", "TrainNetParam", "TestNetParam", "TrainState", "TestState", "TestIter", "TestInterval", "TestComputeLoss",
								"TestInitialization", "BaseLr", "Display", "AverageLoss", "MaxIter", "LrPolicy", "Gamma", "Power", "Momentum", "WeightDecay", "RegularizationType", "Stepsize", "Stepvalue",
								"Snapshot", "SnapshotPrefix", "SnapshotDiff", "SolverMode", "DeviceId", "RandomSeed", "SolverType", "Delta", "DebugInfo", "SnapshotAfterTrain", });
		internal_static_caffe_SolverState_descriptor =
				getDescriptor().getMessageTypes().get(6);
		internal_static_caffe_SolverState_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_SolverState_descriptor,
						new java.lang.String[] { "Iter", "LearnedNet", "History", "CurrentStep", });
		internal_static_caffe_NetState_descriptor =
				getDescriptor().getMessageTypes().get(7);
		internal_static_caffe_NetState_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_NetState_descriptor,
						new java.lang.String[] { "Phase", "Level", "Stage", });
		internal_static_caffe_NetStateRule_descriptor =
				getDescriptor().getMessageTypes().get(8);
		internal_static_caffe_NetStateRule_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_NetStateRule_descriptor,
						new java.lang.String[] { "Phase", "MinLevel", "MaxLevel", "Stage", "NotStage", });
		internal_static_caffe_LayerParameter_descriptor =
				getDescriptor().getMessageTypes().get(9);
		internal_static_caffe_LayerParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_LayerParameter_descriptor,
						new java.lang.String[] { "Bottom", "Top", "Name", "Include", "Exclude", "Type", "Blobs", "Param", "BlobShareMode", "BlobsLr", "WeightDecay", "LossWeight", "AccuracyParam", "ArgmaxParam",
								"ConcatParam", "ContrastiveLossParam", "ConvolutionParam", "DataParam", "DropoutParam", "DummyDataParam", "EltwiseParam", "Hdf5DataParam", "Hdf5OutputParam", "HingeLossParam",
								"ImageDataParam", "InfogainLossParam", "InnerProductParam", "LrnParam", "MemoryDataParam", "MvnParam", "PoolingParam", "PowerParam", "ReluParam", "SigmoidParam", "SoftmaxParam",
								"SliceParam", "TanhParam", "ThresholdParam", "WindowDataParam", "TransformParam", "Layer", });
		internal_static_caffe_TransformationParameter_descriptor =
				getDescriptor().getMessageTypes().get(10);
		internal_static_caffe_TransformationParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_TransformationParameter_descriptor,
						new java.lang.String[] { "Scale", "Mirror", "CropSize", "MeanFile", });
		internal_static_caffe_AccuracyParameter_descriptor =
				getDescriptor().getMessageTypes().get(11);
		internal_static_caffe_AccuracyParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_AccuracyParameter_descriptor,
						new java.lang.String[] { "TopK", });
		internal_static_caffe_ArgMaxParameter_descriptor =
				getDescriptor().getMessageTypes().get(12);
		internal_static_caffe_ArgMaxParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ArgMaxParameter_descriptor,
						new java.lang.String[] { "OutMaxVal", "TopK", });
		internal_static_caffe_ConcatParameter_descriptor =
				getDescriptor().getMessageTypes().get(13);
		internal_static_caffe_ConcatParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ConcatParameter_descriptor,
						new java.lang.String[] { "ConcatDim", });
		internal_static_caffe_ContrastiveLossParameter_descriptor =
				getDescriptor().getMessageTypes().get(14);
		internal_static_caffe_ContrastiveLossParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ContrastiveLossParameter_descriptor,
						new java.lang.String[] { "Margin", });
		internal_static_caffe_ConvolutionParameter_descriptor =
				getDescriptor().getMessageTypes().get(15);
		internal_static_caffe_ConvolutionParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ConvolutionParameter_descriptor,
						new java.lang.String[] { "NumOutput", "BiasTerm", "Pad", "PadH", "PadW", "KernelSize", "KernelH", "KernelW", "Group", "Stride", "StrideH", "StrideW", "WeightFiller", "BiasFiller",
								"Engine", });
		internal_static_caffe_DataParameter_descriptor =
				getDescriptor().getMessageTypes().get(16);
		internal_static_caffe_DataParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_DataParameter_descriptor,
						new java.lang.String[] { "Source", "BatchSize", "RandSkip", "Backend", "Scale", "MeanFile", "CropSize", "Mirror", });
		internal_static_caffe_DropoutParameter_descriptor =
				getDescriptor().getMessageTypes().get(17);
		internal_static_caffe_DropoutParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_DropoutParameter_descriptor,
						new java.lang.String[] { "DropoutRatio", });
		internal_static_caffe_DummyDataParameter_descriptor =
				getDescriptor().getMessageTypes().get(18);
		internal_static_caffe_DummyDataParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_DummyDataParameter_descriptor,
						new java.lang.String[] { "DataFiller", "Num", "Channels", "Height", "Width", });
		internal_static_caffe_EltwiseParameter_descriptor =
				getDescriptor().getMessageTypes().get(19);
		internal_static_caffe_EltwiseParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_EltwiseParameter_descriptor,
						new java.lang.String[] { "Operation", "Coeff", "StableProdGrad", });
		internal_static_caffe_ThresholdParameter_descriptor =
				getDescriptor().getMessageTypes().get(20);
		internal_static_caffe_ThresholdParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ThresholdParameter_descriptor,
						new java.lang.String[] { "Threshold", });
		internal_static_caffe_HDF5DataParameter_descriptor =
				getDescriptor().getMessageTypes().get(21);
		internal_static_caffe_HDF5DataParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_HDF5DataParameter_descriptor,
						new java.lang.String[] { "Source", "BatchSize", });
		internal_static_caffe_HDF5OutputParameter_descriptor =
				getDescriptor().getMessageTypes().get(22);
		internal_static_caffe_HDF5OutputParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_HDF5OutputParameter_descriptor,
						new java.lang.String[] { "FileName", });
		internal_static_caffe_HingeLossParameter_descriptor =
				getDescriptor().getMessageTypes().get(23);
		internal_static_caffe_HingeLossParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_HingeLossParameter_descriptor,
						new java.lang.String[] { "Norm", });
		internal_static_caffe_ImageDataParameter_descriptor =
				getDescriptor().getMessageTypes().get(24);
		internal_static_caffe_ImageDataParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ImageDataParameter_descriptor,
						new java.lang.String[] { "Source", "BatchSize", "RandSkip", "Shuffle", "NewHeight", "NewWidth", "Scale", "MeanFile", "CropSize", "Mirror", });
		internal_static_caffe_InfogainLossParameter_descriptor =
				getDescriptor().getMessageTypes().get(25);
		internal_static_caffe_InfogainLossParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_InfogainLossParameter_descriptor,
						new java.lang.String[] { "Source", });
		internal_static_caffe_InnerProductParameter_descriptor =
				getDescriptor().getMessageTypes().get(26);
		internal_static_caffe_InnerProductParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_InnerProductParameter_descriptor,
						new java.lang.String[] { "NumOutput", "BiasTerm", "WeightFiller", "BiasFiller", });
		internal_static_caffe_LRNParameter_descriptor =
				getDescriptor().getMessageTypes().get(27);
		internal_static_caffe_LRNParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_LRNParameter_descriptor,
						new java.lang.String[] { "LocalSize", "Alpha", "Beta", "NormRegion", });
		internal_static_caffe_MemoryDataParameter_descriptor =
				getDescriptor().getMessageTypes().get(28);
		internal_static_caffe_MemoryDataParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_MemoryDataParameter_descriptor,
						new java.lang.String[] { "BatchSize", "Channels", "Height", "Width", });
		internal_static_caffe_MVNParameter_descriptor =
				getDescriptor().getMessageTypes().get(29);
		internal_static_caffe_MVNParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_MVNParameter_descriptor,
						new java.lang.String[] { "NormalizeVariance", "AcrossChannels", });
		internal_static_caffe_PoolingParameter_descriptor =
				getDescriptor().getMessageTypes().get(30);
		internal_static_caffe_PoolingParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_PoolingParameter_descriptor,
						new java.lang.String[] { "Pool", "Pad", "PadH", "PadW", "KernelSize", "KernelH", "KernelW", "Stride", "StrideH", "StrideW", "Engine", });
		internal_static_caffe_PowerParameter_descriptor =
				getDescriptor().getMessageTypes().get(31);
		internal_static_caffe_PowerParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_PowerParameter_descriptor,
						new java.lang.String[] { "Power", "Scale", "Shift", });
		internal_static_caffe_ReLUParameter_descriptor =
				getDescriptor().getMessageTypes().get(32);
		internal_static_caffe_ReLUParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_ReLUParameter_descriptor,
						new java.lang.String[] { "NegativeSlope", "Engine", });
		internal_static_caffe_SigmoidParameter_descriptor =
				getDescriptor().getMessageTypes().get(33);
		internal_static_caffe_SigmoidParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_SigmoidParameter_descriptor,
						new java.lang.String[] { "Engine", });
		internal_static_caffe_SliceParameter_descriptor =
				getDescriptor().getMessageTypes().get(34);
		internal_static_caffe_SliceParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_SliceParameter_descriptor,
						new java.lang.String[] { "SliceDim", "SlicePoint", });
		internal_static_caffe_SoftmaxParameter_descriptor =
				getDescriptor().getMessageTypes().get(35);
		internal_static_caffe_SoftmaxParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_SoftmaxParameter_descriptor,
						new java.lang.String[] { "Engine", });
		internal_static_caffe_TanHParameter_descriptor =
				getDescriptor().getMessageTypes().get(36);
		internal_static_caffe_TanHParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_TanHParameter_descriptor,
						new java.lang.String[] { "Engine", });
		internal_static_caffe_WindowDataParameter_descriptor =
				getDescriptor().getMessageTypes().get(37);
		internal_static_caffe_WindowDataParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_WindowDataParameter_descriptor,
						new java.lang.String[] { "Source", "Scale", "MeanFile", "BatchSize", "CropSize", "Mirror", "FgThreshold", "BgThreshold", "FgFraction", "ContextPad", "CropMode", });
		internal_static_caffe_V0LayerParameter_descriptor =
				getDescriptor().getMessageTypes().get(38);
		internal_static_caffe_V0LayerParameter_fieldAccessorTable = new
				com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_caffe_V0LayerParameter_descriptor,
						new java.lang.String[] { "Name", "Type", "NumOutput", "Biasterm", "WeightFiller", "BiasFiller", "Pad", "Kernelsize", "Group", "Stride", "Pool", "DropoutRatio", "LocalSize", "Alpha",
								"Beta", "Source", "Scale", "Meanfile", "Batchsize", "Cropsize", "Mirror", "Blobs", "BlobsLr", "WeightDecay", "RandSkip", "DetFgThreshold", "DetBgThreshold", "DetFgFraction",
								"DetContextPad", "DetCropMode", "NewNum", "NewChannels", "NewHeight", "NewWidth", "ShuffleImages", "ConcatDim", "Hdf5OutputParam", });
	}

	// @@protoc_insertion_point(outer_class_scope)
}
